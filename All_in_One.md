# c++/c

## c++三大特性

**封装**

最开始接触代码是C语言，那么开始写一些逻辑代码的时候会很麻烦，因为你要在函数中定义变量，然后按顺序写对应的逻辑，接着可以将逻辑封装成函数。当时会感觉很麻烦，因为很散装，知道后面学了struct结构体，把对应逻辑需要的数据可以放到一个结构体里面，这样就会比较好看。接着出现的问题就是数据封装到了一起，但是处理数据对应的逻辑即函数却还是在外面。因此就有了将数据和对应逻辑进行封装的类的出现。

封装就是将抽象得到的数据和行为相结合，形成一个有机的整体，也就是将数据与操作数据的源代码进行有机的结合，形成类，其中数据和函数都是类的成员，目的在于将对象的使用者和设计者分开，可以隐藏实现细节包括包含私有成员，使得代码模块增加安全指数，同时提高软件的可维护性和可修改性。

所以总结来说封装这个特性包含两三特点：

1. 结合性，即是将属性和方法结合 
2. 信息隐蔽性，利用接口机制隐蔽内部实现细节，只留下接口给外界调用   
3. 实现代码重用

**继承**

类的派生指的是从已有类产生新类的过程。原有的类成为基类或父类，产生的新类称为派生类或子类，子类继承基类后，可以创建子类对象来调用基类的函数，变量等。

一般来说有如下三种继承方式：

1. 单一继承：继承一个父类，这种继承称为单一继承，这也是我们用的做多的继承方式。
2. 多重继承：一个派生类继承多个基类，类与类之间要用逗号隔开，类名之前要有继承权限，假使两个或两个基类都有某变量或函数，在子类中调用时需要加**类名限定符**如obj.classA::i = 1；
3. 菱形继承：多重继承掺杂隔代继承1-n-1模式，此时需要用到虚继承，例如 B，C虚拟继承于A，D再多重继承B，C，否则会出错。后面有将具体虚继承怎么做。

此外还有继承权限的问题，如下图：

<img src="https://images2015.cnblogs.com/blog/1048430/201611/1048430-20161107095657280-1519112029.png" alt="img" style="float: left;" />

**多态**

可以简单概括为“一个接口，多种方法”，即用的是同一个接口，但是效果各不相同，多态有两种形式的多态，一种是静态多态，一种是动态多态。

静态多态。静态多态的设计思想：对于相关的对象类型，直接实现它们各自的定义，不需要共有基类，甚至可以没有任何关系。只需要各个具体类的实现中要求相同的接口声明，静态多态本质上就是模板的具现化。

动态多态。对于相关的对象类型，确定它们之间的一个共同功能集，然后在基类中，把这些共同的功能声明为多个公共的虚函数接口。各个子类重写这些虚函数，以完成具体的功能。具体实现就是c++的虚函数。

多态是以封装和继承为基础实现的性质，一个形态的多种表现方式。硬要解释的话可以说是一个接口，多个功能，在用父类指针调用函数时，实际调用的是指针指向的实际类型（子类）的成员函数。

c++多态有以下几种：

1. 重载。函数重载和运算符重载，编译期。

2. 虚函数。子类的多态性，运行期。

   在继承关系中，对于父类的方法我们也同样使用。但是正常来说，我们希望方法的行为取决于调用方法的对象，而不是指针或引用指向的对象有关。

3. 模板，类模板，函数模板。编译期

> 比如你家有亲属结婚了，让你们家派个人来参加婚礼，邀请函写的是让你爸来，但是实际上你去了，或者你妹妹去了，这都是可以的，因为你们代表的是你爸，但是在你们去之前他们也不知道谁会去，只知道是你们家的人。可能是你爸爸，可能是你们家的其他人代表你爸参加。这就是多态。





## 面向对象和面向过程语言的区别

首要要知道这两个都是一种编程思想

**面向过程**就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了。

**面向对象**是把构成问题事务分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个事物在整个解决问题的步骤中的行为。

**举一个例子：**

例如五子棋，面向过程的设计思路就是首先分析问题的步骤：1、开始游戏，2、黑子先走，3、绘制画面，4、判断输赢，5、轮到白子，6、绘制画面，7、判断输赢，8、返回步骤2，9、输出最后结果。把上面每个步骤用分别的函数来实现，问题就解决了。

而面向对象的设计则是从另外的思路来解决问题。整个五子棋可以分为 1、黑白双方，这两方的行为是一模一样的，2、棋盘系统，负责绘制画面，3、规则系统，负责判定诸如犯规、输赢等。第一类对象（玩家对象）负责接受用户输入，并告知第二类对象（棋盘对象）棋子布局的变化，棋盘对象接收到了棋子的i变化就要负责在屏幕上面显示出这种变化，同时利用第三类对象（规则系统）来对棋局进行判定。

可以明显地看出，面向对象是以功能来划分问题，而不是步骤。同样是绘制棋局，这样的行为在面向过程的设计中分散在了总多步骤中，很可能出现不同的绘制版本，因为通常设计人员会考虑到实际情况进行各种各样的简化。而面向对象的设计中，绘图只可能在棋盘对象中出现，从而保证了绘图的统一。功能上的统一保证了面向对象设计的可扩展性。

**面向过程**

优点：性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;比如单片机、嵌入式开发、 Linux/Unix等一般采用面向过程开发，性能是最重要的因素。

缺点：没有面向对象易维护、易复用、易扩展

**面向对象**

优点：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统 更加灵活、更加易于维护

缺点：性能比面向过程低



## 结构体(struct)和共同体(union)的区别

结构体struct：把不同类型的数据组合成一个整体。struct里每个成员都有自己独立的地址。sizeof(struct)是内存对齐后所有成员长度的加和。（引申出[内存对齐](#说一说内存对齐)的问题）

共同体union：各成员共享一段内存空间, 一个union变量的长度等于各成员中最长的长度，以达到节省空间的目的。所谓的共享不是指把多个成员同时装入一个union变量内, 而是指该union变量可被赋予任一成员值,但每次只能赋一种值, 赋入新值则冲去旧值。 sizeof(union)是最长的数据成员的长度。

> 总结： struct和union都是由多个不同的数据类型成员组成, 但在任何同一时刻, union中只存放了一个被选中的成员, 而struct的所有成员都存在。在struct中，各成员都占有自己的内存空间，它们是同时存在的。一个struct变量的总长度等于所有成员长度之和。**在Union中，所有成员不能同时占用它的内存空间，它们不能同时存在。**Union变量的长度等于最长的成员的长度。对于union的不同成员赋值, 将会对其它成员重写, 原来成员的值就不存在了, 而对于struct的不同成员赋值是互不影响的。



## struct的内存对齐规则

**为什么要字节对齐？**

需要字节对齐的根本原因在于CPU访问数据的效率问题。假如没有字节对齐，那么一个double类型的变量会存储在4-11上（正常是0-7）这样计算机取这个数据的会会取两次，降低效率。而如果变量在自然对齐位置上，则只要一次就可以取出数据。一些系统对对齐要求非常严格，比如sparc系统，如果取未对齐的数据会发生错误。

**对齐规则**

由于在x86下，GCC默认按4字节对齐，但是可以使用`__attribute__`选项改变对齐规则， vs studio上用`#pragma pack (n)`方式改变

举例子：

```c++
//sizeof stu = 4 +4 + 12 = 20
struct stu{
    char sex;			//4
    int length;			//4
    char name[10];		//12
};

// size of str1 = 1 + 1+(2)+4 = 8
//两个char后需要再补充两个字节凑够4字节
struct node1  
{
    char c1;
    char c2;
    int a;
}str1 ;

// 5+2+1+4 = 12
//char前4个元素占4字节，第5个元素和short一共3字节，需要补1个字节
struct str4  {
    char c1[5];
    short c;
    int b;
}str4 ;

// 1+(7)+8+1+(7) = 24
struct str6 {
    char c1;
    double a;
    char c2;
}str6 ;
```

**易错点**

```c++
//sizeof = 8
struct str{
    char p;
    int a;
    int b[0];
}

//sizeof = 4
struct str{
    int b[0];
}

//sizeof = 1
struct str{
    
}
```

上面三个结构体都包含空数组，空数组指的是长度为0的数组`int[]`或`int[0]`

这种定义只能在类或者结构体中定义，在外部是非法定义。空数组不占空间，也无需初始化

空数组名是一个指针，（但是又不占空间）指向一个位置；对于结构体，空数组名这个指针指向了前面一个成员结束的第一个空间。

> 不能再函数中定义Int a[0] 或int a[];这种



## arr和&arr[0]和&arr的不同

首先如果打印的话，三个打印的完全一样，都是数组首元素的地址。

首先&arr应该是整个元素的地址，但是打印出来却是首元素的地址，不同之处在于对地址做加法运算后有不同，如下：

```c++
int arr[10]={0};
printf("%p\n",arr);//首元素的地址
printf("%p\n",arr+1);

printf("%p\n",&arr[0]);//首元素的地址
printf("%p\n",&arr[0]+1);

printf("%p\n",&arr);//整个数组元素的地址
printf("%p\n",&arr+1); 
```

输出首元素地址都是相同的，arr+1和&arr[0]+1都是只移动了4个字节，但是&arr+1移动了40个字节

**结论：&arr代表的是整个数组的地址，虽然它具体表现为首个元素的地址，但是在对其进行操作时，是以整个数组为单位的。**

补充

arr 本身是左值（但不可仅凭此表达式修改），指代数组对象。不过 arr 会在大多数场合隐式转换成右值表达式 &(arr[0]) ，为指针类型，指向 arr[0] 。&arr 是右值表达式，为指针类型，指向 arr 本身。简单来说就是 arr 本身不是地址而是指代整个数组，只不过会隐式转成指针罢了。



## char a,char a[],char *a,char *[],char * *a 之间的区别

1. char a

   定义了一个存储空间，存储的是char类型的变量

2. char a[]

   是一个字符数组，数组中的每一个元素是一个char类型的数据

3. char *a

   **字符串的本质（在计算机眼中）是其第一个字符的地址，c和c++中操作字符串是通过内存中其存储的首地址来完成的**
   
   对于char a[]来说a代表的是数组的首地址，那么对char *a来说a代表的也是字符串的首地址
   
   因此char a[]和char *a可以放到一块看，这两个没有本质区别。
   
   但是要注意对于char s[]和char* a我们可以有`a=s`，但不能有`s=a`，因为创建数组的时候s的地址不为空已经确定，但是a是一个空指针，不能将非空的地址指向空指针

4. char *a[]

   `*`的优先级是低于`[]`的，因此要先看`a[]`再看 `*`
   
   因此这是一个char数组，数组中的每一个元素都是指针，这些指针指向char类型
   
   `char *a[ ] = {"China","French","America","German"}`

5. char **a

   两个**代表相同的优先级，因此从右往左看，即`char*(*a)`
   
   char *a不就是一个字符串数组，a代表首地址。那么char * (*a)就是和char *a[]一样的数据结构





## 一维数组名和二维数组名的区别

不管是一维还是多维数组，都是内存中一块线性连续空间，因此在内存级别上，其实都只是一维。

所以一维数组名是指向该数组的指针，二维数组名也是指向该数组的指针，但是+1之后，跳过的是一行。

问：二维数组名为什么不能直接赋值给二级指针？

答：一句话来说就是二维数组名是行指针，也就是指向数组的指针。而二级指针是指向指针的指针，它们不是同一类型。

> 定义一维数组 `int a[i]` 和二维数组` int b[i][j]`，a相当于`int (*)`，而b相当于`int (*)[j]`。想要获得 a[i] 中第 x 个元素，可以直接使用 `*(a+x)`。而想要获得 `b[i][j] `中第 x 行第 y 个元素，则需用 `*(*(b+x)+y)`，因为 b 相当于数组指针，(b+x) 则是指向第 x 个数组的指针，注意，是指向数组，而不是数组元素！所以` *(b+x)` 获得的是第 x 个数组的数组名，即该数组的首元素地址，这时再结合偏移量 y 就可以取得该元素。



## 数组指针和指针数组

其实就是数组的指针和指针的数组

数组的指针：指向一个数组的指针就是数组指针

指针的数组：一个数组的每一个元素都是指针



## C++内存布局/程序分段

也可以叫做进程逻辑地址空间

内存从上到下分别是：

- 栈stack				   |高地址|
- 堆heap                                         
- bss段
- data段
- 代码段text              |低地址|

栈：保存函数的局部变量，参数以及返回值。在函数调用后，系统会清楚栈上保存的栈帧和局部变量，函数参数等信息。栈是从高到低增长的。

堆：动态内存分配的都放在堆上。堆是从低到高的。

bss段：（Block Started by Symbol）存放程序中未初始化的全局变量的一块内存区域，在程序载入时由内核置为0。

data段：static变量和所有初始化的全局变量都在data段中。

> bss段和data段都是静态内存分配，也就是说在编译的时候自动分配的。
>
> bss和data段也有一种说法合起来叫数据段，有三种类型：
>
> 1. 只读数据段，常量与const修饰的全局变量
> 2. 可读可写数据段，存放初始化的全局变量和static变量
> 3. bss段，存放未初始化的全局变量

text段：代码段，text段在内存中被映射为只读，但.data和.bss是可写的。由编译器在编译连接时自动计算的，当你在链接定位文件中将该符号放置在代码段后，那么该符号表示的值就是代码段大小，编译连接时，该符号所代表的值会自动代入到源程序中。



## **static 和const分别怎么用，类里面static和const可以同时修饰成员函数吗**

- **static**

  - static对于变量

    1. 局部变量

       在局部变量之前加上关键字static，局部变量就被定义成为一个局部静态变量。

       内存中的位置：data段

       初始化：局部的静态变量只能被初始化一次

       作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域随之结束。

       > 当static用来修饰局部变量的时候，它就**改变了局部变量的存储位置（从原来的栈中存放改为静态存储区）及其生命周期（局部静态变量在离开作用域之后，并没有被销毁，而是仍然驻留在内存当中，直到程序结束，只不过我们不能再对他进行访问），但未改变其作用域。**

    2. 全局变量

       在全局变量之前加上关键字static，全局变量就被定义成为一个全局静态变量。

       内存中的位置：静态存储区（静态存储区在整个程序运行期间都存在）

       初始化：未经初始化的全局静态变量会被程序自动初始化为0

       作用域：全局静态变量在声明他的文件之外是不可见的。准确地讲从定义之处开始到文件结尾。(只能在本文件中存在和使用)

       >  全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。两者的区别在于非静态全局变量的作用域是整个源程序， 当一个源程序由多个源文件组成时，非静态的全局变量在各个源文件中都是有效的（在其他源文件中使用时加上extern关键字重新声明即可）。 而**静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它**。
       

  - static对于函数

       修饰普通函数，表明函数的作用范围，仅在定义该函数的文件内才能使用。在多人开发项目时，为了防止与他人命名空间里的函数重名，可以将函数定位为 static。（和全局变量一样限制了作用域而已）

  - static对于类

    1. 成员变量

       用static修饰类的数据成员实际使其成为类的全局变量，会被类的所有对象共享，包括派生类的对象。

       因此，**static成员必须在类外进行初始化，而不能在构造函数内进行初始化。不过也可以用const修饰static数据成员在类内初始化 。**

    2. 成员函数

       用static修饰成员函数，使这个类只存在这一份函数，所有对象共享该函数，不含this指针。

       静态成员是可以独立访问的，也就是说，无须创建任何对象实例就可以访问。

       **不可以同时用const和static修饰成员函数。**

- **const**

  1. const修饰变量：限定变量为不可修改。

  2. const修饰指针：指针常量和指向常量的指针

  3. const和函数：有以下几种形式

     ```c++
     const int& fun(int& a); //修饰返回值
     int& fun(const int& a); //修饰形参
     int& fun(int& a) const{} //const成员函数
     ```

  4. const和类：①const修饰成员变量，在某个对象的声明周期内是常量，但是对于整个类而言是可以改变的。因为类可以创建多个对象，不同的对象其const成员变量的值是不同的。切记，**不能在类内初始化const成员变量**，因为类的对象没创建前，编译器并不知道const成员变量是什么，因此const数据成员只能在初始化列表中初始化。②const修饰成员函数，主要目的是防止成员函数修改成员变量的值，即该成员函数并不能修改成员变量。③const对象，常对象，常对象只能调用常函数。

  1. 限定成员函数不可以修改任何数据成员

- static和const可以同时修饰成员函数吗?

  答：不可以。C++编译器在实现const的成员函数的时候为了确保该函数不能修改类的实例的状态，会在函数中添加一个隐式的参数const this*。但当一个成员为static的时候，该函数是没有this指针的。也就是说此时const的用法和static是冲突的。两者的语意是矛盾的。**static的作用是表示该函数只作用在类型的静态变量上，与类的实例没有关系；而const的作用是确保函数不能修改类的实例的状态**，与类型的静态变量没有关系。因此不能同时用它们。



## static初始化时机和线程安全问题

**先说在C语言中：**

静态局部变量和全局变量一样，数据都存放在全局区域，所以在主程序之前，编译器已经为其分配好了内存，在编译阶段分配好了内存之后就进行初始化，在程序运行结束时变量所处的全局内存会被回收。所以在c语言中无法使用变量对静态局部变量进行初始化。

**再说C++和C语言的区别：**

c++主要引入了类这种东西，要进行初始化必须考虑到相应的构造函数和析构函数，而且很多时候构造或者析构函数中会指定我们定义的操作，并非简单的分配内存。因此为了造成不必要的影响（一些我不需要的东西被提前构造出来）所以c++规定全局或者静态对象在首次用到的时候才会初始化。

所以c++整了两种初始化的情况，我理解就是编译初始化和运行初始化。

编译初始化也叫静态初始化。对全局变量和const类型的初始化主要是，叫做zero initialization 和 const initialization，静态初始化在程序加载的过程中完成。从具体实现上看，zero initialization 的变量会被保存在 bss 段，const initialization 的变量则放在 data 段内，程序加载即可完成初始化，这和 c 语言里的全局变量静态变量初始化基本是一致的。其次全局类对象也是在编译器初始化。

动态初始化也叫运行时初始化。主要是指需要经过函数调用才能完成的初始化或者是类的初始化，一般来说是局部静态类对象的初始化和局部静态变量的初始化。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20190424220313563.png" alt="在这里插入图片描述" style="zoom: 60%; float: left;" />

下面是我自己的实验的一段代码：

```c++
#include<stdio.h>
static int a;
int main()
{
	int b = 5;
	{	
        //g++编译报错
	 	static int c = b;
        //gcc编译不报错
        static int c = b;	
	}
	return 0;
}
```

如果在c语言中有局部静态变量赋值操作的话会报错：`undefined reference to ' __cxa_guard_acquire'和 '__cxa_guard_release'`。而这两个API接口恰恰是c++中保证局部静态变量运行时初始化的关键，具体参考[c++局部静态变量和线程安全具体实现参考](https://www.cnblogs.com/william-cheung/p/4831085.html)

**线程安全问题：**

C语言中非局部静态变量一般在main执行之前的静态初始化过程中分配内存并初始化，可以认为是线程安全的；C++11标准针规定了局部静态变量初始化是线程安全的。这里的线程安全指的是：一个线程在初始化 m 的时候，其他线程执行到 m 的初始化这一行的时候，就会挂起而不是跳过。

具体实现如下：局部静态变量在编译时，编译器的实现是和全局变量类似的，均存储在bss段中。然后编译器会生成一个`guard_for_bar` 用来保证线程安全和一次性初始化的整型变量，是编译器生成的，存储在 bss 段。它的最低的一个字节被用作相应静态变量是否已被初始化的标志， 若为 0 表示还未被初始化，否则表示已被初始化(` if ((guard_for_bar & 0xff) == 0)`判断)。 `__cxa_guard_acquire` 实际上是一个加锁的过程， 相应的 `__cxa_guard_abort` 和` __cxa_guard_release` 释放锁。

```c++
void foo() {
    static Bar bar;
}

//gcc 4.8.3 编译器生成的汇编代码
void foo() {
    if ((guard_for_bar & 0xff) == 0) {
        if (__cxa_guard_acquire(&guard_for_bar)) {
            try {
                Bar::Bar(&bar);
            } catch (...) {
                __cxa_guard_abort(&guard_for_bar);
                throw;
            }
            __cxa_guard_release(&guard_for_bar);
            __cxa_atexit(Bar::~Bar, &bar, &__dso_handle);
        }
    }
    // ...
}
```



## C++中局部静态变量的问题

### **首先说一下局部静态变量的理解**

局部静态变量位于内存中的静态存储区，未经初始化的局部静态变量会自动初始化为0。但是局部静态变量的作用于还是还是局部作用于，定义它的函数或者代码块结束的时候，作用于也随之结束。但是该变量值不会被销毁，而是在内存中驻留下来，知道程序全部结束，这个驻留的值我们不能访问她。

### **静态局部变量的构造和析构**

对于全局变量的构造和析构，肯定是排在首位的。

而对于局部静态变量，程序首次执行到局部静态变量的定义处时才发出构造，其构造和析构都取决于程序的执行顺序。很显然，对于分布在程序各处的静态局部变量，其构造顺序取决于它们在程序的实际执行路径上的先后顺序，而析构顺序则正好与之相反。这就有两个问题：

1. 一方面是因为程序的实际执行路径有多个决定因素（例如基于消息驱动模型的程序和多线程程序），有时是不可预知的；
2. 另一方面是因为局部静态变量分布在程序代码各处，彼此直接没有明显的关联，很容易让开发者忽略它们之间的这种关系（这是最坑的地方）。

所以我们应该尽量少使用静态变量。

### 函数局部静态变量的返回

```c++
int tmp(){
    static int b = 5;
    return b;
}
int main(){
    static int a = 0;
    int c = tmp();
    std::cout<<"a:"<<a<<std::endl;
    std::cout<<"c:"<<c<<std::endl;
}
```

对于g++编译器来说，可以返回哦



## **Const与指针**

只有两种情况：**指向常量的指针**和**常量指针**

**指向常量的指针**表明不能通过解除引用运算符去改变其值，指向的变量是常量

**常量指针**表明初始化后的指针指向的地址是不能改变的，但这块地址上的存储的值可以改变，地址跟随一生。所以`p2= &a是错误的，而*p2 = a 是正确的。`

```c++
const int p     //p为常量，初始化后不能更改
const int *p	//*p为常量，不能通过*p改变其内容
int const *p	//同上
int *const p	//常量指针
```



## **指针和引用的区别**

[关于引用的本质可以看这个](https://blog.csdn.net/K346K346/article/details/46805159)

**引用的底层本质：**

从高级语言层面的概念来说：引用是变量的别名，它不能脱离被引用对象独立存在。接下来看一下底层引用到底是什么？

```c++
//一段引用的代码
int i=5;
int &ri=i;
ri=8;

//上述代码对应的汇编代码
int i=5;
00A013DE  mov        dword ptr [i],5    	//将文字常量5送入变量i

//这一步是引用的初始化过程，对于引用十分重要
int &ri=i;
00A013E5  lea        eax,[i]  	 	    	//将变量i的地址送入寄存器eax
00A013E8  mov        dword ptr [ri],eax  	//将寄存器的内容（也就是变量i的地址）送入变量ri

ri=8;
00A013EB  mov        eax,dword ptr [ri]  	//将变量ri的值送入寄存器eax
00A013EE  mov        dword ptr [eax],8   	//将数值8送入以eax的内容为地址的单元中
return 0;
00A013F4  xor        eax,eax
```

可以看到在汇编代码中ri这个引用的数据类型是dword(double word-4字节)。所以ri确实是一个变量，存放的是被引用的对象的地址。指针和引用的区别要看下一段代码：

```c++
//一段常量指针的代码
int i=5;
int* const pi=&i;
*pi=8;

//上述代码对应的汇编代码
int i=5;
011F13DE  mov         dword ptr [i],5  

int * const pi=&i;
011F13E5  lea         eax,[i]  
011F13E8  mov         dword ptr [pi],eax  

*pi=8;
011F13EB  mov         eax,dword ptr [pi]  
011F13EE  mov         dword ptr [eax],8  
```

可以看到引用和常量指针的汇编代码是一模一样的，所以可以得出在底层，引用就是一个常量指针。

**高级语言层面引用与指针常量的关系**

1. 相同点：指针和引用在内存中都占用4个或者8个字节的存储空间，都必须在定义的时候给初始化。

2. 指针常量本身（以p为例）允许寻址，即&p返回指针常量本身的地址，*p表示被指向的对象

   引用变量本身（以r为例）不允许寻址，&r返回的是被引用对象的地址，而不是变量r的地址(r的地址由编译器掌握，程序员无法直接对它进行存取)

3. 引用不能为空，指针可以为空；

4. 指针数组这一块。数组元素允许是指针但不允许是引用，主要是为了避免二义性。假如定义一个“引用的数组”，那么array[0]=8;这条语句该如何理解？是将数组元素array[0]本身的值变成8呢，还是将array[0]所引用的对象的值变成8呢?

5. 在C++中，指针和引用经常用于函数的参数传递，然而，指针传递参数和引用传递参数是有本质上的不同的：**指针传递**参数本质上是**值传递**的方式，它所传递的是一个地址值。值传递的特点是被调函数对形式参数的任何操作都是作为局部变量进行，不会影响主调函数的实参变量的值。而在**引用传递**过程中， 被调函数的形参虽然也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数放进来的实参变量的地址（指针放的是实参变量地址的副本）。

6. "sizeof引用"得到的是所指向的变量(对象)的大小，而"sizeof指针"得到的是指针本身的大小；



## 用const和#define定义常量哪个更好？

## #define宏常量和const常量的区别

**类型和安全检查不同**

宏定义是字符替换，没有数据类型的区别，同时这种替换没有类型安全检查，可能产生边际效应等错误；

const常量是常量的声明，有类型区别，需要在编译阶段进行类型检查

**编译器处理不同**

宏定义是一个"编译时"概念，在预处理阶段展开，不能对宏定义进行调试，生命周期结束与编译时期；

const常量是一个"运行时"概念，在程序运行使用，放在内存中的data段中。

**存储方式不同**

宏定义是直接替换，不会分配内存，存储于程序的代码段中；

const常量需要进行内存分配，存储于程序的数据段中

**是否可以做函数参数**

宏定义和const常量可以在函数的参数列表中出现





## typedef与#define的区别

**typedef**

typedef故名思意就是类型定义的意思，但是它**并不是定义一个新的类型而是给已有的类型起一个别名**。主要有两个作用，第一个是给一些复杂的变量类型起别名，起到简化的作用。第二个是定义与平台无关的类型，屏蔽不同平台之间的差异。在跨平台或操作系统的时候，只需要改typedef本身就可以

**#define**

#define为一宏定义语句，本质就是文本替换

**区别**

1. 关键字typedef在编译阶段有效，由于是在编译阶段，因此typedef有类型检查的功能。\#define则是宏定义，发生在预处理阶段，也就是编译之前，它只进行简单而机械的字符串替换，而不进行任何检查。

2. #define没有作用域的限制，只要是之前预定义过的宏，在以后的程序中都可以使用。而typedef有自己的作用域。

3. 对指针操作不同。见下面代码

```c++
typedef int * pint;
#define PINT int *
 
int i1 = 1, i2 = 2;

const pint p1 = &i1;	//p不可更改，p指向的内容可以更改，相当于 int * const p;
const PINT p2 = &i2;	//p可以更改，p指向的内容不能更改，相当于 const int *p；或 int const *p；
```



## #include<>和#include“ ”的区别

**#include<>**

一般用来查找标准库文件所在目录，在编译器设置的include路径内搜索；

**#include""**

 \#include "" 的查找位置是当前源文件所在目录

> 要注意的一点就是，如果我们自己写的头文件，而不是标准库函数中的，那么引用这个头文件要使用`#include""`，而不能使用`#include<>`，因为我们自己写的头文件并不在编译器设置的路径内，使用`#include<>`会提示无法找到。
>
> 若 #include "" 查找成功，则遮蔽 #include <> 所能找到的同名文件；否则再按照 #include <> 的方式查找文件。



## 左值和右值

[对于左值和右值写的很详细](https://mp.weixin.qq.com/s/_9-0iNUw6KHTF3a-vSMCmg)

### 历史

C语言中的表达式被分为`左值`和其它(函数和非对象值)，其中左值被定义为标识一个对象的表达式，在C语言中lvalue是`locator value`的简写，因此lvalue对应了一块内存地址。

C++出来后，C++11之前，左值遵循了C语言的分类法，但与C不同的是，其将非左值表达式统称为右值，函数为左值，因为c++有引用这个东西 。并添加了引用能绑定到左值但唯有const的引用能绑定到右值的规则。

自C++11开始，对值类别又进行了详细分类，在原有左值的基础上增加了纯右值和消亡值，并对以上三种类型通过是否具名(identity)和可移动(moveable)，又增加了glvalue和rvalue两种组合类型。

c++11后的值类别

自C++11开始，表达式的值分为`左值(lvalue, left value)`、`将亡值(xvalue, expiring value)`、`纯右值(pvalue, pure ravlue)`以及两种混合类别`泛左值(glvalue, generalized lvalue)`和`右值(rvalue, right value)`五种。我们只需要关注左值，纯右值和将亡值这三种即可。

### 左值

lvalue 是“**loactor value**”的缩写，可意为存储在内存中、有明确存储地址（可寻址）的数据

左值是**可以取地址、位于赋值符号左边**的值，就记住，左值是表达式结束（不一定是赋值表达式）后依然存在的对象。

左值也是一个关联了名称的内存位置，允许程序的其他部分来访问它的值。

有以下特征：

1. 可通过取地址运算符获取其地址
2. 可修改的左值可用来赋值
3. 可以用来初始化左值引用

那些是左值？

1. 变量名、函数名以及数据成员名
2. 返回左值引用的函数调用
3. 由赋值运算符或复合赋值运算符连接的表达式，如(a=b, a-=b等)
4. 解引用表达式*ptr
5. **前置自增和自减表达式(++a, ++b)**
6. 成员访问（点）运算符的结果
7. 由指针访问成员（ `->` ）运算符的结果
8. 下标运算符的结果(`[]`)
9. 字符串字面值("abc")

### 右值

rvalue 译为 "**read value**"，指那些可以提供数据值的表达式（不一定可以寻址，例如存储于寄存器中的数据）。右值有可能在内存中也有可能在寄存器中。一般来说就是活不过一行就会消失的值。

那些是右值？

1. 字面值(字符串字面值除外)，例如1，'a', true等
2. 返回值为非引用的函数调用或操作符重载，例如：str.substr(1, 2), str1 + str2, or it++
3. 后置自增和自减表达式(a++, a--)
4. 算术表达式（x + y;）
5. 逻辑表达式
6. 比较表达式
7. 取地址表达式
8. lambda表达式`auto f = []{return 5;};`

左值和右值区分的一个点

从本质上理解，右值的创建和销毁由编译器幕后控制，程序员只能确保在本行代码有效的，就是右值(包括立即数)；而用户创建的，通过作用域规则可知其生存期的，就是左值(包括函数返回的局部变量的引用以及const对象)。

右值又有纯右值和将亡值的说法。非引用返回的临时变量、运算表达式产生的临时变量、原始字面量和lambda表达式等都是纯右值。而将亡值是与右值引用相关的表达式，比如，将要被移动的对象、T&&函数返回值、std::move返回值和转换为T&&的类型的转换函数的返回值等。



## 左值引用和右值引用

### **左值引用**

左值引用分为：左值引用和常量左值引用(不希望被修改)

观察下列代码：

```c++
//左值引用
int a = 10;
int &b = a;  // 定义一个左值引用变量
b = 20;      // 通过左值引用修改引用内存的值

//常量左值引用
const int temp = 10; 
const int &var = temp;
```

### **右值引用**

[贴一个超级详细的连接](https://www.cnblogs.com/qicosmos/p/4283455.html)

右值引用是C++11中新增加的一个很重要的特性，他主是要用来解决C++98/03中遇到的两个问题，第一个问题就是临时对象非必要的昂贵的拷贝操作，第二个问题是在模板函数中如何按照参数的实际类型进行转发。通过引入右值引用，很好的解决了这两个问题，改进了程序性能。我从以下四行代码来理解右值引用：

**第一行代码：**

```c++
int i = getVar();
auto f = []{return 5;};
```

对于第一个代码，会产生两种类型的值。等号左边是一个左值，可以取地址，我们可以管控i的生命周期。等号右边会得到一个临时值，这个临时值在表达式结束之后就销毁了，这个临时值就是右值，或者叫做纯右值。

**第二行代码：**

```
T&& k = getVar();
```

此时的k就是右值引用，由于右值是匿名变量，我们也只能通过引用的方式来获取右值。在这里getVar()产生的临时值不会像第一行代码那样，在表达式结束之后就销毁了，而是会被“续命”，他的生命周期将会通过右值引用得以延续，和变量k的声明周期一样长。

**第三行代码：**

```
T(T&& a){
	m_val = a.m_val; 
	a.m_val=nullptr; 
}
```

从类的移动构造开始说。由于一个带有堆内存的类必须提供一个深拷贝拷贝构造函数，因为默认的拷贝构造函数是浅拷贝，会发生“指针悬挂”的问题。如果不提供深拷贝的拷贝构造函数，上面的测试代码将会发生错误。内部的m_ptr将会被删除两次，一次是临时右值析构的时候删除一次，第二次外面构造的a对象释放时删除一次，而这两个对象的m_ptr是同一个指针，这就是所谓的指针悬挂问题。提供深拷贝的拷贝构造函数虽然可以保证正确，但是在有些时候会造成额外的性能损耗，因为有时候这种深拷贝是不必要的。这个构造函数并没有做深拷贝，仅仅是将指针的所有者转移到了另外一个对象，同时，将参数对象a的指针置为空，这里仅仅是做了浅拷贝，因此，这个构造函数避免了临时变量的深拷贝问题。

**进而引出了移动语义的概念(std::move)。**

当编译器看到&&的时候会判定为右值引用，对编译器来说这是一个临时变量的标识，对于临时变量来说我们仅仅做一次浅拷贝就行，不需要深拷贝，从而解决了前面提到的临时变量拷贝构造产生的性能损失的问题。这就是所谓的移动语义，右值引用的一个重要作用是用来支持移动语义的。那我们知道了移动语义是通过右值来匹配临时值的，那么很自然会想到，普通的左值是否也能借助移动语义来优化性能呢？C++11为了解决这个问题，提供了std::move方法来将左值转换为右值，从而方便应用移动语义。move是将对象资源的所有权从一个对象转移到另一个对象，只是转移，没有内存的拷贝，这就是所谓的move语义。

move实际上它并不能移动任何东西，它唯一的功能是将一个左值强制转换为一个右值引用。如果是一些基本类型比如int和char[10]定长数组等类型，使用move的话仍然会发生拷贝（因为没有对应的移动构造函数）。所以，move对于含资源（堆内存或句柄）的对象来说更有意义。

<img src="https://s2.loli.net/2022/08/16/XBnWOEMSLg7AdsU.jpg" alt="img" style="zoom: 67%;float:left" /><img src="https://s2.loli.net/2022/08/16/UgBS4WOh61dTDEq.jpg" alt="img" style="zoom: 67%;" />

**第四行代码：**

```
template <typename T>
void f(T&& val){ 
	foo(std::forward<T>(val)); 
}

//模板类会出现的问题
template <typename T>
void forwardValue(T& val)
{
    processValue(val); //右值参数会变成左值 
}
template <typename T>
void forwardValue(const T& val)
{
    processValue(val); //参数都变成常量左值引用了 
}
```

在模板函数中传入的是有个右值，但是第一个函数中变成了左值，第二个函数中变成了常量左值引用。

**引入完美转发的概念。**

C++11引入了完美转发解决这个问题：在函数模板中，完全依照模板的参数的类型（即保持参数的左值、右值特征），将参数传递给函数模板中调用的另外一个函数。C++11中的std::forward正是做这个事情的，他会按照参数的实际类型进行转发。



## 深拷贝和浅拷贝

在未定义显示拷贝构造函数的情况下，系统会调用默认的拷贝函数——即浅拷贝，它能够完成成员的一一复制。

当数据成员中没有指针时，浅拷贝是可行的；

**但当数据成员中有指针时，会出问题。如果没有自定义拷贝构造函数，会调用默认拷贝构造函数，这样就会调用两次析构函数。**第一次析构函数delete了内存，第二次的就指针悬挂了。所以，此时，必须采用深拷贝。

深拷贝与浅拷贝的区别就在于深拷贝会在堆内存中另外申请空间来储存数据，从而也就解决了指针悬挂的问题。简而言之，当数据成员中有指针时，必须要用深拷贝。



## O0、O1、O2、O3优化

**-O0**

不做任何优化，这是默认的编译选项。 

**-O1**

主要对代码的分支、常量以及表达式进行优化。会减小代码的尺寸，缩短执行周期啥的

 -floop-optimize：执行循环优化,将常量表达式从循环中移除，简化判断循环的条件，并且optionally do strength-reduction，或者将循环打开等。在大型复杂的循环中，这种优化比较显著。 

**-O2**

O2优化再打开O1优化的前提下，尝试更多的寄存器级的优化以及指令级的优化，它会在编译期间占用更多的内存和编译时间。

所以一般来说可以直接开-O2的优化等级，

**-O3**

 在O2的基础上进行更多的优化，例如使用伪寄存器网络，普通函数的内联，以及针对循环的更多优化。

这个好像不推荐，因为会增加编译失败和程序不可预知的一些行为，不建议使用




## c++中四种变量存储类型总结

在C++语言中，变量的存储类共有如下四种： 

（1）auto存储类（自动存储类）

（2）static存储类 （静态存储类）

（3）extern存储类  (外部存储类)

（4）register存储类（寄存器存储类）

- **自动存储类**

  auto存储类，即自动存储类。在函数内部定义的变量，如果不指定其存储类，那么它就是auto类变量。这个是最常见的，所以我们不加关键字auto

  这是我们经常见到的一种变量存储类型。见如下代码：

  ```c++
  void func( ) { int a; auto int b; … }
  //a和b都是auto存储类变量
  ```

  > 自动存储类在在进入代码块（函数）之前生成，在函数体内部存活，出了函数体（函数返回）后就消失。
  >
  > 自动变量默认初始值是不确定的、
  >
  > 自动存储类每调用一次函数时都要赋一次初始值

- **静态存储类**

  static关键字在c和c++中是不同的，这个在上面说过了，具体的话可以去看上面。

- **extern存储类**

  如果在一个文件中要引用另一个文件中定义的外部变量，则在此文件中应用extern关键字把此变量说明为外部的。例如：

  ```c++
  extern int a; //a为别的文件中定义的外部变量
  int mydata; //外部变量的定义 
  extern int mydata;  //外部变量的说明 
  ```
  
  > 大型程序为了易于维护和理解，通常需要把程序划分为多个文件来保存，每个文件都可以单独编译，最后再把多个文件的编译结果（即目标文件）连接到一起来生成一个可执行程序。这种情况下，如果在一个文件中需要引用另一个文件中的外部变量，就需要利用extern说明。
  
- **register存储类**

  为了提高某些自动类变量或函数参数的处理速度，可以在定义这些变量的类型说明符的前面加上register关键字，以通知编译系统为这些变量分配寄存器来存放其值。若使用register（而非auto）存储类标识代码块内的变量，编译器就会将变量缓存于处理器内的寄存器中，此种情况下不能对该变量或其成员变量使用引用操作符&以获取其地址，因为&只能获取内存空间中的地址



## C++中this指针相关问题

### This指针的来源

通过转化成c语言好理解一点。早期还没有针对特定c++的编译器，因此编译c++的时候都先翻译成c语言，再进行编译。

对于class结构来说，c语言中与之对应的就是结构体。

类中的成员变量可以翻译成结构体域中的变量，但是结构体中没有成员函数这个概念，因此成员函数就翻译成为全局函数。

那么如果函数内部想使用成员数据，可以使用该对象指针的方式，指向成员变量。

**其作用就是指向非静态成员函数所作用的对象。**

1. `this` 指针是一个隐含于每一个非静态成员函数中的特殊指针。它指向**调用该非静态成员函数的那个对象。**
2. 当对一个对象调用成员函数时，编译程序先将对象的地址赋给 `this` 指针，然后调用成员函数，每次成员函数存取数据成员时，都隐式使用 `this` 指针。
3. `this` 并不是一个常规变量，而是个右值，所以不能取得 `this` 的地址（不能 `&this`）。

### this指针是什么时候创建的？

this在成员函数的开始执行前构造，在成员的执行结束后清除。

但是如果class里面没有方法的话，它们是没有构造函数的，只能当做C的struct使用。采用TYPE xx的方式定义的话，在栈里分配内存，这时候this指针的值就是这块内存的地址。采用new的方式创建对象的话，在堆里分配内存，new操作符通过eax（累加寄存器）返回分配的地址，然后设置给指针变量。之后去调用构造函数（如果有构造函数的话），这时将这个内存块的地址传给ecx

### this指针存放在何处？堆、栈、全局变量，还是其他？

this指针会因编译器不同而有不同的放置位置。可能是栈，也可能是寄存器，甚至全局变量。在汇编级别里面，一个值只会以3种形式出现：立即数、寄存器值和内存变量值。不是存放在寄存器就是存放在内存中，它们并不是和高级语言变量对应的。

### 如果我们知道一个对象this指针的位置，可以直接使用吗？

**this指针只有在成员函数中才有定义。**

因此，你获得一个对象后，也不能通过对象使用this指针。所以，我们无法知道一个对象的this指针的位置（只有在成员函数里才有this指针的位置）。当然，在成员函数里，你是可以知道this指针的位置的（可以通过&this获得），也可以直接使用它。

### 在成员函数中调用delete this会出现什么问题？

在类对象的内存空间中，只有数据成员和虚函数表指针，类的成员函数单独放在代码段中。在调用成员函数时，隐含传递一个this指针，让成员函数知道当前是哪个对象在调用它。

当调用delete this时，类对象的内存空间被释放。在delete this之后进行的其他任何函数调用，只要不涉及到this指针的内容，都能够正常运行。一旦涉及到this指针，如操作数据成员，调用虚函数等，就会出现不可预期的问题。

### 如果在类的析构函数中调用delete this，会发生什么？

会导致堆栈溢出。原因很简单，delete的本质是“为将被释放的内存调用一个或多个析构函数，然后，释放内存”。显然，delete this会去调用本对象的析构函数，而析构函数中又调用delete this，形成无限递归，造成堆栈溢出，系统崩溃。



##  inline 内联函数与宏定义

首先分析一下C宏定义的好处：首先C语言是一个效率很高的语言，使用预处理器实现，没有参数压栈，函数返回等操作，效率很高。

1. 相当于把内联函数里面的代码写在调用内联函数处。不用执行进入函数的步骤，直接执行函数体。

2. 从上面那一条的角度说，内联函数更像是宏，但却比宏多了类型检查，真正具有函数特性。

3. 在类声明中定义的函数，除了虚函数的其他函数都会自动隐式地当成内联函数。

4.  编译器会为所用 inline 函数中的局部变量分配内存空间

5. 会将 inline 函数的的输入参数和返回值映射到调用方法的局部变量空间中；

- 优点
  - 内联函数同宏函数一样将在被调用处进行代码展开，省去了参数压栈、栈帧开辟与回收，结果返回等，从而提高程序运行速度。
  - 内联函数相比宏函数来说，在代码展开时，会做安全检查或自动类型转换（同普通函数），而宏定义则不会。
  - 内联函数在运行时可调试，而宏定义不可以。
  - 可以说inline函数不仅吸收了了C宏定义的，同时消除宏定义的缺点。
- 缺点
  - 代码膨胀。内联是以代码膨胀（复制）为代价，消除函数调用带来的开销。
  - inline 函数无法随着函数库升级而升级。inline函数的改变需要重新编译。
  - 万一又递归调用，代码量很大。
  
-  虚函数（virtual）可以是内联函数（inline）吗？
  - 首先要明白，内联函数是编译器做出的选择，是否内联决定权在编译器，程序员不可控。同时，虚函数是多态性的一种体现，多态性表现在函数的运行阶段而不是函数的编译阶段。因此，**虚函数表现为多态性时（运行期）不可以内联。**
  - 唯一可以内联的时候是：编译器知道所调用的对象是哪个类。**只有在编译器具有实际对象而不是对象的指针或引用时才会发生。**

> inline说明对编译器来说只是一种建议，编译器可以忽略这个建议的，比如，你将一个长达100多行的函数指定为inline，编译器就会自动忽略这个inline，将这个函数还原成普通函数。在调用内联函数时，要保证内联函数的定义让编译器看到，也就是说，内联函数inline必须要定义在头文件中，这与通常的函数定义是不一样的。



##  struct 和 typedef struct

```c
/代码1（c语言）
typedef struct test3{
	int a;
	int b;
	int c;
}test4;
//代码2（c++）
struct test3{
	int a;
	int b;
	int c;
}test4;
```

- **在c语言中**

  对于代码1。**test3**相当于标识符，而**test4**相当于变量类型.定义一个结构体变量为`test4 t`，即`struct test3 = test4`

  对于代码2。要定义结构体变量必须写成`struct test3 t `

- **在c++中**

  对于代码1。不要这样写，基本上是代码二的类型。test4变成了变量名

  对于代码2 。这是c++的写法，test4相当于一个结构体变量。



## explicit 关键字

explicit关键字主要是用来修饰类中的构造函数的，对于仅有一个参数或除第一个参数外其余参数均有默认值的类构造函数，尽可能使用explicit关键字修饰。因为只有一个参数或者出了第一个参数其他参数是默认参数的构造函数来说，他还有另一个名字叫做转换构造函数。

**所以explicit主要用来防止隐式转换。**因为仅含一个参数的构造函数和除了第一个参数外其余参数都有默认值的多参构造函数承担了两个角色。 第一个是成为带参数的构造函数，第二个是一个默认且隐含的类型转换操作符（就是单参数的构造函数是一种隐含的类型转换符）

额外说一下隐式类型转换：

> c++隐式类型转换是指c++自动将一种类型转换成另一种类型，是编译器的一种自主行为。

举一些类型转换的例子：

```c++
int i=3;
double j = 3.1;
i+j;//i会被转换成double类型，然后才做加法运算。

class A{};
class B: public A
{};//B是子类
void Fun(A& a);
B b;
Fun(b);//使用子类对象代替父类对象是可以的，也是因为隐式类型转换。

class Test
{
	public:
		Test(int i);
};

Test t1 = 1;//正确，由于强制类型转换，1先被Test构造函数构造成Test对象，然后才被赋值给t1
Test t2(1);//正确
```



## friend友元类和友元函数

[看这里](https://blog.csdn.net/adriano119/article/details/5914443?utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control)

采用类的机制后实现了数据的隐藏与封装，类的数据成员一般定义为私有成员，成员函数一般定义为公有的，依此提供类与外界间的通信接口。有时需要定义一些函数，这些函数不是类的一部分，但又需要频繁地访问类的数据成员，这时可以将这些函数定义为该函数的友元函数。如果不用友元你可以使用成员函数来set这些数据成员。

除了友元函数外，还有友元类，两者统称为友元。

**友元函数**能够使得普通函数直接访问类的保护数据和私有数据成员，避免了类成员函数的频繁调用，可以节约处理器开销，提高程序的效率，但所矛盾的是，即使是最大限度大保护，同样也破坏了类的封装特性，这即是友元的缺点，在现在cpu速度越来越快的今天我们并不推荐使用它。

**友元类**友元类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的隐藏信息（包括私有成员和保护成员）。    

友元的作用是提高了程序的运行效率（即减少了类型检查和安全性检查等都需要时间开销），但它破坏了类的封装性和隐藏性，使得非成员函数可以访问类的私有成员。

> 我碰到了一种必须使用友元的情况。如下图
>
> <img src="https://s2.loli.net/2022/08/16/7vWarITSkPYHOdK.png" alt="image-20220816221227150" style="zoom:50%;float:left" />
>
> 上述代码由于使用了priority_queue，而且每个成员是一个结构体，所以需要重新定义std::less的比较方式，所以在结构体重重载了`<`号，这个时候重载运算符需要用到友元。因为std::less类中的比较运算符需要调用struct中的，因此需要把结构体中的设置为友元。



## c++虚函数

### 前瞻

虚函数是实现多态的一个技术之一。在c++中，动态联编通过指针和引用来实现。但是，想一想，正常来说我们不允许程序将一种类型的指针指向另外一种类型的地址。但是在类中却可以这样做，派生类的指针指向基类对象的地址（派生类对象的地址赋给基类指针），而且不用进行显式转换，如下：

```c++
BrassPlus dilly;
Brass *pb = &dilly;
Brass &pb = dilly;
```

派生类的指针指向基类对象的地址（派生类对象的地址赋给基类指针）称为向上转型，c++允许隐式向上转型。将子类指向父类，向下转换则必须强制类型转换。

然后我们就可以用父类的指针指向其子类的对象，然后通过父类的指针调用实际子类的成员函数。如果子类重写了该成员函数就会调用子类的成员函数，没有声明重写就调用基类的成员函数。这种技术可以让父类的指针有“多种形态”。

> 用到的情形举例：比如你有个游戏，游戏里有个虚基类叫「怪物」，有纯虚函数 「攻击」。然后派生出了三个子类「狼」「蜘蛛」「蟒蛇」，都实现了自己不同的「攻击」函数，比如狼是咬人，蜘蛛是吐丝，蟒蛇把你缠起来～～。然后出现好多怪物的时候就可以定义一个 虚基类指针数组，把各种怪物的指针给它，然后迭代循环的时候直接 monster[i]->attack() 攻击玩家就行了，如下图：
>
> <img src="https://pic1.zhimg.com/80/27e97e90be9ac729167740ee5c66a8ea_720w.jpg?source=1940ef5c" alt="img" style="float: left;" />

### 虚函数工作原理

c++没有强制规定虚函数的实现方式。**编译器中主要用虚表指针（vptr）和虚函数表（vtbl）来实现的**

先直接上图，然后再看一下虚函数的执行过程：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202201211638057.png" alt="img" style="float: left;" />

当调用一个对象对应的函数时，通过对象内存中的vptr找到一个虚函数表（注意这虚函数表既不在堆上，也不再栈上）。虚函数表内部是一个函数指针数组，记录的是该类各个虚函数的首地址。然后调用对象所拥有的函数。

### 继承情况下的虚函数表

- 原始基类的虚函数表

  <img src="https://images2015.cnblogs.com/blog/364303/201608/364303-20160815123956531-397793609.png" alt="img" style="float: left;" />

- 单继承时的虚函数（**无重写基类虚函数**）

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/364303-20160815124419156-189096231.png" alt="img" style="float: left;" />

- 单继承时的虚函数（**重写基类虚函数**）

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/364303-20160815124615562-420906064.png" alt="img" style="float: left;" />

- 多重继承时的虚函数（Derived ::public Base1,public Base2）

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/364303-20160815125139921-1422683315.png" alt="img" style="float: left;" />

这样就会有内存和执行速度方面的成本：

1. 每个对象都会增大，因为在对象最前面的位置加入了指针
2. 对于每个类，编译器都会创建虚函数地址表
3. 对于每个函数调用，都要查找表中地址

### 虚函数的性能分析

第一步是通过对象的vptr找到该类的vtbl，因为虚函数表指针是编译器加上去的，通过vptr找到vtbl就是指针的寻址而已。

第二部就是找到对应vtbl中虚函数的指针，因为vtbl大部分是指针数组的形式实现的

在单继承的情况下调用虚函数所需的代价基本上和非虚函数效率一样，在大多数计算机上它多执行了很少的一些指令

在多继承的情况由于会根据多个父类生成多个vptr，在对象里为寻找 vptr 而进行的偏移量计算会变得复杂一些

空间层面为了实现运行时多态机制，编译器会给每一个包含虚函数或继承了虚函数的类自动建立一个虚函数表，所以虚函数的一个代价就是会增加类的体积。在虚函数接口较少的类中这个代价并不明显，虚函数表vtbl的体积相当于几个函数指针的体积，如果你有大量的类或者在每个类中有大量的虚函数,你会发现 vtbl 会占用大量的地址空间。但这并不是最主要的代价，主要的代价是发生在类的继承过程中，在上面的分析中，可以看到，当子类继承父类的虚函数时，子类会有自己的vtbl，如果子类只覆盖父类的一两个虚函数接口，子类vtbl的其余部分内容会与父类重复。**如果存在大量的子类继承，且重写父类的虚函数接口只占总数的一小部分的情况下，会造成大量地址空间浪费**。同时由于虚函数指针vptr的存在，虚函数也会增加该类的每个对象的体积。在单继承或没有继承的情况下，类的每个对象只会多一个vptr指针的体积，也就是4个字节；在多继承的情况下，类的每个对象会多N个（N＝包含虚函数的父类个数）vptr的体积，也就是4N个字节。当一个类的对象体积较大时，这个代价不是很明显，但当一个类的对象很轻量的时候，如成员变量只有4个字节，那么再加上4（或4N）个字节的vptr，对象的体积相当于翻了1（或N）倍，这个代价是非常大的。

### 虚函数的一些问题

- **构造函数可以设置为虚的吗？**

  答：不能。因为虚函数的调用是需要通过“虚函数表”来进行的，而虚函数表也需要在对象实例化之后才能够进行调用。在构造对象的过程中，还没有为“虚函数表”分配内存。所以，这个调用也是违背先实例化后调用的准则。

  子类的默认构造函数总要执行的操作：执行基类的代码后调用父类的构造函数。


- **c++虚析构函数**

  如果类是父类，则必须声明为虚析构函数。基类声明一个虚析构函数，为了确保释放派生对象时，按照正确的顺序调用析构函数。

  如果析构函数不是虚的，那么编译器只会调用对应指针类型的虚构函数。切记，是指针类型的，不是指针指向类型的！而其他类的析构函数就不会被调用。例如如下代码：	

  ```c++
  Employee* pe = new Singer;
  delete pe;
  ```

  只会调用Employee的析构函数而不会调用Singer类的析构函数。如果这个类不是父类也可以定义虚析构函数，只是效率方面问题罢了

- **那些函数不能是虚函数？**

  除了上面说的构造和析构函数往外。

  ①**友元函数**不是虚函数，因为友元函数不是类成员，只有类成员才能使虚函数。

  ②**静态成员函数**不能是虚。在C++中，静态成员函数不能被声明为virtual函数。首先会编译失败，也就是不能同过编译。

  原因如下：

  1. static成员不属于任何类对象或类实例，所以即使给此函数加上virtual也是没有任何意义的。
  2.  静态与非静态成员函数之间有一个主要的区别。那就是静态成员函数没有隐藏的this指针。对于虚函数，它的调用恰恰需要this指针。在有虚函数的类实例中，this指针调用vptr指针，vptr找到vtable(虚函数列表)，通过虚函数列表找到需要调用的虚函数的地址。总体来说虚函数的调用关系是：this指针->vptr->vtable ->virtual虚函数。所以说，static静态函数没有this指针，也就无法找到虚函数了

  ③**内联函数**也不能是虚的，因为要在编译的时候展开，而虚函数要求动态绑定。另外就是虚函数的类对象必须包含vptr，但是内联函数是没有地址的，编译的时候直接展开了所以不行。

  ④**构造函数**也不行。

  ⑤**成员函数模板不能是虚函数**。因为c++ 编译器在解析一个类的时候就要确定虚函数表的大小，如果允许一个虚函数是模板函数，那么compiler就需要在parse这个类之前扫描所有的代码，找出这个模板成员函数的调用（实例化），然后才能确定vtable的大小，而显然这是不可行的，除非改变当前compiler的工作机制。因为类模板中的成员函数在调用的时候才会创建

- **虚函数表是共享还是独有的？**

  答：虚函数表是针对类的，一个类的所有对象的虚函数表都一样。在gcc编译器的实现中虚函数表vtable存放在可执行文件的只读数据段.rodata中。是编译器在编译器为我们处理好的。

- **虚函数表和虚函数指针的位置？**

  答：既不在堆上，也不在栈上。虚函数表（vtable）的表项在编译期已经确定，也就是一组常量函数指针。跟代码一样，在程序编译好的时候就保存在**可执行文件里面**。程序运行前直接加载到内存中即可。而堆和栈都是在运行时分配的。而跟虚函数表对应的，是虚函数表指针（vptr），作为对象的一个（隐藏的）成员，总是跟对象的其他成员一起。如果对象分配在堆上，vptr也跟着在堆上；如果对象分配在栈上，vptr也在栈上……

- **编译器如何处理虚函数表**

  对于派生类来说，编译器简历虚表的过程有三步：

  1. 拷贝基类的虚函数表，如果是多继承，就拷贝每个基类的虚函数表
  2. 查看派生类中是否有重写基类的虚函数，如果有，就替换成已经重写后的虚函数地址
  3. 查看派生类中是否有新添加的虚函数，如果有，就加入到自身的虚函数表中

- **构造函数或析构函数中调用虚函数会怎样？**

  首先不应该在构造函数和析构函数中调用虚函数。

  在构造函数中调用虚函数。假如有一个动物基类，这个基类定义了一个虚函数来表示动物的行为，叫做action。我们在基类的构造函数中调用这个虚函数。然后有一个派生类重写了该虚函数。当我们创建一个派生类对象的时候，首先会执行基类部分，因此执行基类的构造函数，然后才会执行子类的构造函数。编译器在执行基类构造函数中的虚函数时，会认为这是一个基类的对象，因为派生类还并没有构造出来。因此达不到动态绑定的效果，父类构造函数中调用的仍然是父类版本的函数，子类中调用的仍然是子类版本的函数

  在析构函数中调用虚函数。析构函数也是一样，派生类先进行析构，如果有父类的析构函数中有virtual函数的话，派生类的内容已经被析构了，C++会视其基类，执行基类的virtual函数。
  
- **如何获取 虚表地址和虚函数地址？**

  ```c++
  //该类如下：
  class Base {
  public:
      virtual void f() { cout << "Base::f" << endl; }
      virtual void g() { cout << "Base::g" << endl; }
      void h() { cout << "Base::h" << endl; }
  };
  
  Base b;
  //  1.&b代表对象b的起始地址
  //  2.(int *)&b 强转成int *类型,为了后面取b对象的前4个字节,前四个字节是虚表指针
  //  3.*(int *)&b 取前四个字节,即vptr虚表地址
  printf("虚表地址:%p\n", *(int *)&b);
  //  根据上面的解析我们知道*(int *)&b是vptr,即虚表指针.并且虚表是存放虚函数指针的
  //  所以虚表中每个元素(虚函数指针)在32位编译器下是4个字节,因此(int *)*(int *)&b
  //  这样强转后为了后面的取四个字节.所以*(int *)*(int *)&b就是虚表的第一个元素.
  printf("第一个虚函数地址:%p\n", *(int *)*(int *)&b);
  printf("第二个虚函数地址:%p\n", *((int *)*(int *)(&b) + 1));
  //始终记着vptr指向的是一块内存,
  //  这块内存存放着虚函数地址,这块内存就是我们所说的虚表.
  //64位下把int换成longlong就好了
  ```

  

## C语言怎么实现多态

c++的多态分为两种：

1. 编译时多态：重载

2. 运行时多态：重写即虚函数。虚函数本身其实就是回调函数

思路就是使用函数指针来实现多态。

**编译时多态：**

先说一个c中的宏，`__V_ARGS__`，是c99引入进来的可变参宏，一般是用来输出debug信息。可以用这个宏实现一个简单的多态机制。代码举例：

```c
#define Check(...) printf(__VA_ARGS__);
int main(int argc, char *argv[])
{
    int i = 1, j = 2;
    char *Error = "error!!";
    Check("i = %d\n", j);
    Check("i = %d, j = %d\n", i, j);
    Check("i = %d, j = %d, Error:%s\n", i, j, Error);
	return 0;
}
/*********************关于结构体的*****************************/
#define func(...) myfunc((struct mystru) { __VA_ARGS__})

struct mystru
{
    const char *name;
    double d;
    int number;
};
 
void myfunc(struct mystru ms)
{
    printf("%s, %lf, %d\n", ms.name, ms.d, ms.number);
}
 
int main(int argc, char *argv[])
{
    func();
    func("hello", 1.1);
    func("hello");
    func("hello", 1.1, 100);
    func(.name = "hello");
    func(.d = 1.1);
    func(.number = 100);
    func(.d = 1.1, .name = "hello");
	return 0;
}
```

注意：一般我们在使用结构体的时候都是先赋值在传参数，这里实际上是用"..."可变参数替换为了`__VA_ARGS__`这个宏，然后转化为`(struct mystru){ __VA_ARGS__ }`，其实就是`
(struct mystru){ ... }` 。 通过（struct mystru）把参数转化结构体，这也是为什么如果我们不指定.name或者是.number时，必须按顺序传递参数，否则报错，因为在内存中结构体布局是确定的。不明确指定哪个参数只能按顺序传递。

**运行时多态：**

在c中sizeof(struct)是0,从内存上来看，c++的class和struct不仅仅有数据还有成员函数，这些成员函数如果是non-inline的，那么只会在内存中产生一份实例供所有对象使用，如果是inline的，会为每一个使用着产生一个实例。而c的struct就简单多了，它不占用内存空间，每一个实例按照struct分配一份就好，但这也是问题所在，它在内存中没实例啊。那么用c的struct实现时，我们就要想办法让它在内存中存在一份，大家都能找到它。

所以主要关键点就是在于函数指针的使用

```c++
//虚函数表结构
struct base_vtbl
{
	void(*dance)(void *);
	void(*jump)(void *);
};

//基类
struct base
{
    /*virtual table*/
	struct base_vtbl *vptr;
};
//基类的构造函数
struct base * new_base()
{
    struct base *temp = (struct base *)malloc(sizeof(struct base));
    //基类虚表结构中函数指针具体关联的函数名
	temp->vptr->dance = base_dance;
    temp->vptr->jump = base_jump;
	return temp;
}
//基类的成员函数
void base_dance()
{
	printf("base dance\n");
}
void base_jump()
{
	printf("base jump\n");
}


//派生类
struct derived1
{
	struct base super;
	int high;
};
//派生类的构造函数
struct derived1 * new_derived1(int h)
{
    struct derived1 * temp= (struct derived1 *)malloc(sizeof(struct derived1));
    //派生类虚表结构中函数指针具体关联的函数名
	temp->super->vptr->dance = derived1_table;
    temp->super->vptr->jump = derived1_jump;
	temp->high = h;
	return temp;
}
//派生类对象成员函数
void derived1_dance()
{
	printf("derived1 dance\n");
}
void derived1_jump(void * this)
{
	struct derived1* temp = (struct derived1 *)this;
	printf("derived1 jump:%d\n", temp->high);
}

/*******实际调用***********/
 struct base * bas = new_base();
//这里调用的是基类的成员函数
bas->vptr->dance();
bas->vptr->jump();

struct derived1 * child = new_derived1(100);
//基类指针指向派生类
bas  = (struct base *)child;

//这里调用的其实是派生类的成员函数
bas->vptr->dance();
bas->vptr->jump((void *)bas);
```



## 抽象基类-纯虚函数

定义纯虚函数是为了实现一个接口，起到一个规范的作用，规范继承这个类的程序员必须实现这个函数。

有纯虚函数的类叫做抽象基类，对于抽象类来说，C++是不允许它去实例化对象的。也就是说，抽象类无法实例化对象



## C++ 纯虚基类函数=0

“=0”这个操作在虚函数中有2层意思，即告诉编译器：

1. 有的朋友误解这是返回值为0的意思，但是它并不是，它仅表示的是这个是个纯虚函数，是个抽象函数，没有实现
2. 这个类的继承类里面必须要实现这个函数。



## 如何定义一个只能在堆上（栈上）生成对象的类?

综述：在c++中，建立对象有两种方式，分为静态建立和动态建立，如代码所示：

```
//静态建立
A a;
//动态建立
A *a = new A; 
```

静态建立对象时，由编译器自动为对象在栈中分配内存，是直接移动栈顶指针，腾出适当的空间，然后再这片空间上调用构造函数生成对象，这种静态建立是直接调用类的构造函数。

动态建立对象时，程序员使用new 运算符在堆中建立。这个过程分为两步，第一部是调用operator new()函数在堆空间中搜索出来适当的内存并进行分配，第二步是调用构造函数生成对象，初始化这片内存空间，间接调用构造函数。

- 只能在堆上生成对象的类。

  只能在堆上也就意味着不能再栈上，在栈上是编译器分配内存空间，构造函数来构造栈对象。在栈上当对象周期完成，编译器会调用析构函数来释放栈对象所占的空间，也就是说编译器管理了对象的整个生命周期。**编译器在调用构造函数为类的对象分配空间时，会先检查析构函数的访问性**，不光是析构函数，编译器会检查所有非静态函数的访问性。因此，如果类的析构函数是私有的，编译器不会为对象在栈上分配内存空间。

  扩展一下，如果把析构函数写在private中的话，不能用A a这种静态方式建立对象。但也会有其他问题，如果这个类是父类的话，通常要将析构函数加上virtual关键字，然后再子类重写，实现多态性。但是子类不能访问private成员，可以使用protected，子类可以访问父类的protected成员，但不能访问private。

  另一个问题，当用new建立后，无法delete。因为delete会调用对象的析构函数，但是析构函数在类外无法访问。可以这样写：

  ```c++
  class  A  
  {  
  protected :  
      A(){}  
      ~A(){}  
  public :  
      static  A* create()  
      {  
          return  new  A();  
      }  
      void  destory()  
      {  
          delete  this ;  
      }  
  };  
  ```

- 只能在栈上生成对象的类。

  只有使用new运算符才会在堆上创建对象。设为私有即可。

  动态建立类对象，是使用new运算符将对象建立在堆空间中。这个过程分为两步，第一步是执行operator new()函数，在堆空间中搜索合适的内存并进行分配；第二步是调用构造函数构造对象，初始化这片内存空间（这种方法，间接调用类的构造函数），但是operator new()函数用于分配内存，无法提供构造功能，**所以不能将构造函数设为私有**；
  
  ```c++
  class  A  
  {  
  private :  
      void * operator  new ( size_t  t){}      // 注意函数的第一个参数和返回值都是固定的   
      void  operator  delete ( void * ptr){}  // 重载了new就需要重载delete   
  public :  
      A(){}  
      ~A(){}  
  }; 
  ```
  



## C++如何阻止类被实例化？

> 为什么要组织实例化？
>
> 一个类不想被实例化通常有两种情况：一种是抽象类，一种是工具类。

**抽象类**

比如现在需要计算图形的面积，可以是正方形、长方形、圆形等等。于是抽象出了基类，叫图形。这部分抽象的没办法实例化，如：

```c++
class Sharp{};

class Circle : public Sharp{};

class Rectangle : public Sharp{};
```

**工具类**

我们需要一个类来封装加、减、乘、除。这个类就是一个典型的工具类，用它创建对象没有意义，可以直接通过类名调用静态成员函数。

```c++
class Calculate
{
public:
    static int add(int x, int y);
    static int sub(int x, int y);
    static int mul(int x, int y);
    static int div(int x, int y);
};
```

### 如何阻止？

**方法一：类中包含纯虚函数。**

```c++
class Sharp
{
public:
    virtual void get_s() = 0;    //纯虚函数
};
```

纯虚函数没有函数体。含有纯虚函数的类叫抽象类。抽象类不好创建对象，因为就算是创建了对象，调用纯虚函数的时候，也不知道如何执行。

**方法二：构造函数私有**

把构造函数设置成私有，就不能在类的外部创建对象，相当于间接的阻止了该类实例化对象。

```c++
class Calculate
{
private:
    Calculate();
public:
    static int add(int x, int y);
    static int sub(int x, int y);
    static int mul(int x, int y);
    static int div(int x, int y);
};
```



## C++所有构造函数

类对象被创建时，编译器为对象分配内存空间，并自动调用构造函数，由构造函数完成成员的初始化工作。

因此构造函数的的作用是初始化对象的成员函数。

**默认构造函数：**如果没有人为构造函数，则编译器会自动默认生成一个无参构造函数。

**一般构造函数：**包含各种参数，一个类可以有多个一般构造函数，前提是参数的个数和类型和传入参数的顺序都不相同，根据传入参数调用对应的构造函数。

**拷贝构造函数：**拷⻉构造函数的函数参数为对象本身的引用，用于根据⼀个已存在的对象复制出⼀个新的该类的对象，⼀般在函数中会将已存在的对象的数据成员的值⼀⼀复制到新创建的对象中。如果没有显示的写拷⻉构造函数，则系统会默认创建⼀个拷⻉构造函数，但当类中有指针成员时，最好不要使⽤编译器提供的默认的拷⻉构造函 数，最好⾃⼰定义并且在函数中执⾏深拷⻉。

**移动构造函数：**有时候我们会遇到这样一种情况，我们用对象a初始化对象b后对象a我们就不在使用了，但是对象a的空间还在呀（在析构之前），既然拷贝构造函数，实际上就是把a对象的内容复制一份到b中，那么为什么我们不能直接使用a的空间呢？这样就避免了新的空间的分配，大大降低了构造的成本。这就是移动构造函数设计的初衷。拷贝构造函数中，对于指针，我们一定要采用深层复制，而移动构造函数中，对于指针，我们采用浅层复制。

> 但是指针的浅层复制是非常危险的。浅层复制之所以危险，是因为两个指针共同指向一片内存空间，若第一个指针将其释放，另一个指针的指向就不合法了（pointer dangling）。所以我们只要避免第一个指针释放空间就可以了。避免的方法就是将第一个指针（比如a->value）置为NULL，这样在调用析构函数的时候，由于有判断是否为NULL的语句，所以析构a的时候并不会回收a->value指向的空间（同时也是b->value指向的空间）

**赋值构造函数：**=运算符的重载，类似拷贝构造函数，将=右边的类对象赋值给类对象左边的对象，不属于构造函数，=两边的对象必须都要被创建。

**类型转换构造函数：**有时候不想要隐式转换，用explict关键字修饰。一般来说带一个参数的构造函数，或者其他参数是默认的构造函数      



## 什么情况下会调用拷贝构造函数？

1. 对象以值传递的方式进入函数体
2. 对象以值传递的方式从函数返回
3. 一个对象需要另外一个对象初始化



## 为什么拷贝构造函数必须是引用？

**为了防止递归调用。**

如果不用引用，就会是值传递的方式，但是值传递会调用拷贝构造函数生成临时对象，从而又调用一次拷贝构造函数。就这样无穷的递归下去。

**如果是指针类型**

就变成了一个带参数的构造函数了。。。

比如`A(A* test)`



## 构造函数析构函数是否能抛出异常

**构造函数可以抛出异常**

对象只有在构造函数执行完成之后才算构造妥当，c++只会析构已经完成的对象。因此如果构造函数中发生异常，控制权就需要转移出构造函数，执行异常处理函数。在这个过程中系统会认为对象没有构造成功，导致不会调用析构函数。在构造函数中抛出异常会导致当前函数执行流程终止，在构造函数流程前构造的成员对象会被释放，但是如果在构造函数中申请了内存操作，则会造成内存泄漏。另外，如果有继承关系，派生类中的构造函数抛出异常，那么基类的构造函数和析构函数可以照常执行的。

解决办法：用智能指针来管理内存就可以

**C++标准指明析构函数不能、也不应该抛出异常**

C++异常处理模型最大的特点和优势就是对C++中的面向对象提供了最强大的无缝支持。那么如果对象在运行期间出现了异常，C++异常处理模型有责任清除那些由于出现异常所导致的已经失效了的对象(也即对象超出了它原来的作用域)，并释放对象原来所分配的资源， 这就是调用这些对象的析构函数来完成释放资源的任务，所以从这个意义上说，析构函数已经变成了异常处理的一部分。

析构函数不能抛出异常原因有两个：

1. 如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会执行，会造成诸如资源泄漏的问题。
2. 异常发生时，c++的异常处理机制在异常的传播过程中会进行栈展开（stack-unwinding）。在栈展开的过程中就会调用已经在栈构造好的对象的析构函数来释放资源，此时若其他析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃。

解决办法：把异常完全封装在析构函数内部，决不让异常抛出函数之外，代码如下：

```c++
DBConn::~DBconn()
{
    try
    {
	    db.close(); 
    }
    catch(...)
    {
        abort();
    }
}
//如果close抛出异常就结束程序，通常调用abort完成：
```



## 创建派生类对象，构造函数的执行顺序是什么？析构函数的执行顺序？

首先要知道类的构造函数不能被继承，构造函数不能被继承是有道理的，因为即使继承了，它的名字和派生类的名字也不一样（构造函数名字和类名一样），不能成为派生类的构造函数，当然更不能成为普通的成员函数。在设计派生类时，对继承过来的成员变量的初始化工作也要由派生类的构造函数完成，但是大部分基类都有private属性的成员变量，它们在派生类中无法访问，更不能使用派生类的构造函数来初始化。这种矛盾在C++继承中是普遍存在的，解决这个问题的思路是：**在派生类的构造函数中调用基类的构造函数**。

对象创建时候执行顺序是：**静态代码 --> 非静态代码 --> 构造函数。**静态代码包括（静态方法，静态变量，静态代码块等），非静态代码即（成员方法，成员变量，成员代码块等）。代码块中或者成员变量中如果有类对象的话，肯定要先将类对象创建出来。所以说先执行代码块再执行构造函数，而且如果代码块中有多个成员变量，则按照成员变量的声明顺序进行构造。初始化列表的顺序, 不影响成员变量构造顺序

因为静态变量等这些在内存中属于全局变量，所以要先创建。然后类会查看成员函数的相关信息，为该类的对象中的每个成员变量分配相应的存储空间，然后再执行构造函数创建对象，如果构造函数有初始化，则将值放到准备好的内存空间中。

**构造函数执行顺序**

1. 基类构造函数。如果有多个基类，则构造函数的调用顺序是该基类在派生类中出现的顺序，而不是他们在成员初始化列表中的顺序。
2. 成员类对象构造函数。如果有多个成员类构造函数调用顺序是对象在类中被声明的顺序，而不是他们在成员初始化列表中的顺序
3. 派生类构造函数

**析构函数顺序**

1. 派生类析构函数
2. 成员类对象的析构函数
3. 调用基类的析构函数



## C++成员变量的初始化顺序问题

```c++
class A
{
private:
    int n1;
    int n2;
public:
    A():n2(0),n1(n2+2){}
    void Print(){
        cout << "n1:" << n1 << ", n2: " << n2 <<endl;
    }
};

int main()
{
    A a;
    a.Print();
    return 1;
}

//输出：n1: 是一个随机数；n2: 0
//有的编译器是n1:2, n2=0
```

1. 成员变量在使用初始化列表初始化时，只与定义成员变量的顺序有关，与构造函数中初始化成员列表的顺序无关。因为成员变量的初始化次序是根据变量在内存中次序有关，而内存中的排列顺序早在编译期就根据变量的定义次序决定了。
2. 如果不使用初始化列表初始化，在构造函数内初始化时，此时与成员变量在构造函数中的位置有关。
3. 类成员在定义时，是不能初始化的
4. 类中const成员常量必须在构造函数初始化列表中初始化。
5. 类中static成员变量，必须在类外初始化。

**变量的初始化顺序：**

1. 初始化基类中的静态成员变量和静态代码块，按照在程序中出现的顺序初始化；
2. 初始化派生类中的静态成员变量和静态代码块，按照在程序中出现的顺序初始化；
3. 初始化基类的普通成员变量和代码块，再执行父类的构造方法；
4. 初始化派生的普通成员变量和代码块，在执行子类的构造方法；





## c++的public、private、protected继承特点

### c++默认是什么继承？

c++类中默认是私有继承

c++结构体中默认是public继承。

### 什么不能被继承？

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202201221602391.png" alt="在这里插入图片描述" style="zoom:80%;float:left" />

**1、构造函数**

构造函数不能被继承第一个原因：在创建派生类对象时必须调用派生类的构造函数。派生类构造函数通常使用成员列表初始化来调用基类构造函数以创建派生类中的基类部分。如果派生类没有使用成员列表初始化语法，则将使用默认的基类构造函数，如果基类没有默认的构造函数就会报错。第二个原因：因为即使继承了，它的名字和派生类的名字也不一样（构造函数名字和类名一样），不能成为派生类的构造函数，当然更不能成为普通的成员函数。在设计派生类时，对继承过来的成员变量的初始化工作也要由派生类的构造函数完成，但是大部分基类都有private属性的成员变量，它们在派生类中无法访问，更不能使用派生类的构造函数来初始化。这种矛盾在C++继承中是普遍存在的，解决这个问题的思路是：**在派生类的构造函数中调用基类的构造函数**。

**2、析构函数**

析构函数不能被继承，释放对象的时候需要先调用派生类析构函数然后调用基类析构函数。

**3、赋值运算符=**

这里面说一下为什么赋值运算符不能被继承，其实不应该说不能被继承，而是被覆盖了。第一点是在c++的编译器中如果没有定义赋值运算符，会自动加上一个默认的。所以如果赋值运算符可以被继承，则会导致派生类也会有这个赋值运算符。第二就是在如果派生类的成员和基类的成员有相同的声明，那么派生类会覆盖基类的成员，哪怕参数和数据类型都不相同，也会被覆盖。显然，B1中的赋值运算符函数名operator =和基类A1中的operator =同名，所以，A1中的赋值运算符函数int perator=(int a);被B1中的隐含的赋值运算符函数B1& perator =(const B1& robj);所覆盖。所以赋值运算符会被覆盖，不能被继承，那么派生类就不能使用基类中的赋值运算符做一些事情，就像图上说的特征标随类而异。举个例子就是基类A中赋值运算符参数是int，但是派生类赋值运算符参数是类类型，导致编译出错。

```c++
class A1
{
public:
    int perator=(int a)
    {
        return 8;
    }
};


class B1 : public A1
{
public:
     B1& operator =(const B1& robj); // 注意这一行是编译器添加的，派生类和基类参数都不一样，肯定会报错。
};
B1 b;
int a= 8
b=a//报错。
```

除了如上面的三个函数不能被继承外还有一些，如：

**c++11的final关键字**

**将自身的构造函数与析构函数放在private作用域内**

**友元+虚继承**

解释一下这个，首先要明白什么是友元和虚继承。

友元：友元的本质就是想在类外不通过成员函数访问类的私有成员，分为友元函数和友元类。友元函数内部可以直接访问私有成员。一个类A可以将另一个类B声明为自己的友元，类B的所有成员函数就都可以访问类 A 对象的私有成员。

虚继承：虚拟继承是多重继承中特有的概念。虚拟基类是为解决多重继承而出现的。如:类D继承自类B1、B2，而类B1、B2都继承自类A，因此在类D中两次出现类A中的变量和函数。为了节省内存空间，可以将B1、B2对A的继承定义为虚拟继承，而A就成了虚拟基类。虚拟继承在一般的应用中很少用到，所以也往往被忽视，这也主要是因为在C++中，多重继承是不推荐的，也并不常用，而一旦离开了多重继承，虚拟继承就完全失去了存在的必要因为这样只会降低效率和占用更多的空间。

```c++
class CFinalClassMixin {//从这个类中继承的类都不能再被继承
  friend class Cparent;
private:
  CFinalClassMixin() {}
  ~CFinalClassMixin(){}
};
class Cparent: virtual public CFinalClassMixin, public CXXX {
public:
  Cparent() {}
  ~Cparent(){}
};
class CChild : public Cparent {
public:
  CChild() {};//编译错误
  ~CChild() {};//编译错误
};
```

如果不是虚继承，那么CChild直接调用Cparent的构造函数，这是成立的，而且CChild是不需要调用CFinalClassMixin的构造函数。若把它声明为虚继承（派生类对象一定会调用基类的构造函数），那么CChild就必须负责CFinalClassMixin构造函数的调用，这样又因为不能继承friend类，所以不能调用，造成了错误。



## 成员初始化列表

**c++11新特性里面说的有，很详细**



## 谈一谈new/delete和malloc/free的区别和联系（c++管理内存的方式）

- **相同点**

  都是用来申请动态内存和释放动态内存的

- **区别（主要是new和malloc的却别）**

  - 概念上的区别

    malloc/free是C++/C语言的标准**库函数**，而new/delete是C++的**运算符**。因此malloc仅仅只分配内存，而不会进行初始化类成员的工作，new不止分配内存，而且还是调用类的构造函数。

  - 返回类型的安全性

    new操作符内存分配成功时候，返回的是对象类型的指针，不需要进行类型转换，从这个角度来说比较安全

    malloc内存分配成功则返回`void*`类型（泛型指针），必须通过强制类型转换将`void* `转换成需要的类型。

  - 分配失败后返回值也不同
  
    malloc失败，会返回空指针。
  
    new失败，默认是抛出异常，要捕获异常`bad_alloc`
  
    ```c++
    try
    {
        int *a = new int();
    }
    catch (bad_alloc)
    {
        ...
    }
    ```
  
  - 是否需要指定内存大小
  
    new操作符申请内存的时候不需要指定内存块的大小，编译器会自动根据类型信息来计算
  
    malloc需要显示的指出内存的大小
  
  - new的内部
  
    调用new 操作符分配对象时会经历三个步骤：
  
    1. 调用operator new函数分配一块足够大的，原始的空间
    2. 编译器运行相应的构造函数以构造对象，并传入初值
    3. 构造完对象后，就返回一个指向该对象的指针。
  
  - 后续内存的分配

    当malloc分配内存后，发现后续内存分配不足的时候，可以使用realloc函数进行内存重载实现内存的扩充。realloc会先判断当前指针所指向的内存是否有足够的连续空间，如果有则可以原地扩大内存地址，并返回原来地址空间指针。如果空间不够，就从新分配一个空间，将原来的数据拷贝到新分配的内存区域，释放原来的内存区域。

    new没有这样的配套设施



## 有了malloc/free为什么还要new/delete？

对于一些非内部数据类型(eg:类对象)来说，光用maloc/free无法满足要求。对象在创建的同时要自动执行构造函数，对象在消亡的时候要自动执行析构函数，而由于malloc/free是库函数而不是运算符，不在编译器的控制权限内（库函数是编译好的代码由链接器链接到为我们的代码中），也就不能自动执行构造函数和析构函数。所以，在c++中需要一个能完成动态内存分配和初始化工作的运算符new，以及一个能完成清理和释放内存工作的运算符delete。

比如有一个类，你用malloc后，可以看到该对象的成员变量并没有被初始化，因此自定义类型的用malloc不合适。

既然new/delete 的功能完全覆盖了malloc/free，为什么C++不把malloc/free 淘
汰出局呢？这是因为C++程序经常要调用C 函数，而C 程序只能用malloc/free 管理动
态内存。
如果用free 释放“new 创建的动态对象”，那么该对象因无法执行析构函数而可能
导致程序出错。如果用delete 释放“malloc 申请的动态内存”，理论上讲程序不会出错，
但是该程序的可读性很差。所以new/delete 必须配对使用，malloc/free 也一样。



## new delete，new[] delete[]一定要配对使用吗？为什么？

首先可以明确一点：配套使用是肯定没有错的。

- **new和delete**

  new和delete主要是为了为那些自定义类型的对象开辟空间，因为这些对象在创建的时候要自动执行构造函数，消亡的时候要执行析构函数，对于自定义类型对象如果不配对使用的话，可能会出现没有析构干净的情况

- **new[]和delete[]**

  我们再用new[]创建数组的时候，比如一个对象大小为N，则K个数组需要K*N个空间来构造。那当delete的时候如何知道这个数组空间的大小呢？我们会在new出来的这个空间的头部申请一个int类型的字节，4字节用来存储数组的长度，这样调用delete[]的时候就知道数组的大小，才会调用K次析构函数，释放K * N + 4字节大小的内存。

  下面针对自定义类型变量：

  如果new和delete[]使用，delete的时候会找前4个字节，看要释放的内存有多大。但是使用new导致没有设备区部分4个字节用来存放数组长度，这样会导致这4个字节是未定义的，因此会调用不定次的delete。同时比如说其实地址为A，应该从A开始释放，现在会从A-4开始释放。

  如果new[]和delete一起使用，程序会认为这是一个对象占用的空间，而不是数组，因此就析构一次。同时释放的是new[]中表示长度的前4个字节的地址，应该从A-4开始释放，如果不从头释放的话回出问题。



## free释放内存的理解

> 其实malloc算法有很多，除了glibc使用的ptmalloc以外，还有tcmalloc, jemalloc等等。但总体上个人认为主要分两个流派。第一个流派是ptmalloc为代表的隐藏头风格，第二个流派就是以tcmalloc和jemalloc为代表的位图风格。且就目前的情况看，后者在性能上要占据上风。其中一个重要原因在于，隐藏头风格的算法，元数据（即chunk size）之间间隔太远，不利于CPU cache命中。

- 如何知道要释放的空间大小？

  对于glibc的malloc算法，**空间的大小记录在参数指针指向地址的前面，free的时候通过这个记录即可知道要释放的内存有多大。**

> 你把房子卖了，你就算还拿着钥匙，能进门，这也不是你的房子了。你照样可以把你的钱放在在这个房子里，但是不保证过一会还在。
>
> p，你的房子所在地址，根据p这个地址，你可以找到你的房子，在有效范围内生活（如做饭、大便等），但记得别越界到邻居家了；如memcpy(p, xxx, xx);需要指定长度
>
> free(p)后你把房子卖了，但p这个地址还存在你的记忆中，除非你把你房子的地址从你记忆中抹去，即p = NULL;
>
> 如果你没有抹去对你房子的记忆，即p != NULL; 你仍然可以找到那所房子，但是那房子已经不属于你了；
>
> 如果你还要进房子生活（如做饭、大便等），即对p进行写入操作，那么你已经违法了

[参考链接](https://bbs.csdn.net/topics/300014026/)

**被free回收的内存是立即返还给操作系统吗？**

这个需要看源码。

被free回收的内存会首先被ptmalloc使用双链表保存起来，当用户下一次申请内存的时候，会尝试从这些内存中寻找合适的返回。这样就避免了频繁的系统调用，占用过多的系统资源。同时ptmalloc也会尝试对小块内存进行合并，避免过多的内存碎片



## 怎么在栈上分配内存？

alloca函数

alloca函数分配的内存不需要手动释放，和普通的栈上对象的处理一样：超出作用域自动回收内存。

alloca函数并不被推荐使用，因为它不安全。对于一个很大的数据结构，如果采用默认的内存分配模式，会引起爆栈。但是你用alloca去分配，虽然能够在栈上得到一个地址，但是这个地址可能超出了栈的边界，可能对其他的内存空间造成了破坏。并且alloca函数本身不知道是否踩了其他的内存空间。

使用场景：有时候我们只是想暂时打印日志信息或者错误信息，并不需要长期保存其内容，随着程序运行超出数组作用域，[内存](https://so.csdn.net/so/search?q=内存&spm=1001.2101.3001.7020)自动释放。下次需要的时候再动态的申请，不用管理释放，这样很方便

```c++
if(!result){
	int length;	
	length = getLogLength();  		//凭空捏造的函数
	char* message = (char*)alloca(sizeof(char) * length);
	message = getLogInformation();	//凭空捏造的函数
	std:cout << message << std::endl;
}
```





## 带返回值的函数如果不return会怎么样？

首先不是BUG，这种情况属于**未定义的行为**，而未定义的行为不会导致编程失败。

当main函数没有return结尾的时候会在生成的目标文件中自动加入return 0



## c++ 四种强制类型转换

[参考链接](https://blog.csdn.net/starryheavens/article/details/4617637?spm=1001.2101.3001.6650.12&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-12-4617637-blog-79570788.pc_relevant_multi_platform_whitelistv1&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-12-4617637-blog-79570788.pc_relevant_multi_platform_whitelistv1&utm_relevant_index=15)

### 向上类型转换和向下类型转换

说这个之前要说一下类对象的内存结构：

<img src="https://img-blog.csdnimg.cn/20190405172522761.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01PVV9JVA==,size_16,color_FFFFFF,t_70" alt="img" style="zoom:80%;float:left" />

**向上类型转换：**upcast，把派生类的指针或引用转换成基类的指针或者引用是安全的（或者说基类指针指向派生类）；因为用转换后的指针只能访问基类部分的函数时候，都可以访问，肯定安全。这个是隐式转换，c++认为是安全的。

**向下类型转换：**downcast，把基类指针或引用转换成派生类表示（或者说把派生类指针指向基类）时，由于没有动态类型检查，所以是不安全的。如果转换后的指针访问派生类新增加的函数，这个时候基类中本来没有这个函数，那就会出错。

> 很形象，向上就是派生类指针变成基类指针，向下就是基类指针变成派生类指针。

### 四种强制类型转换

1. **static_cast**

   用于基本数据类型之间的转换

   void*和其他类型指针之间的转换

   子类对象的指针转换成父类对象指针

   以上三个都是隐式转换，最好吧所有隐式转换都用static_cast代替

2. **dynamic_cast**

   只用于对象的指针和引用，主要用于执行“安全的向下转型”，因为downcast是不安全的

   dynamic_cast是唯一一个在运行时处理的，因为我们转换后的指针如果请求一块无效的内存的话是会报错的，但是用该强转后会返回null，即转换成功会返回引用或者指针，失败返回null。如果一个引用类型执行了类型转换并且这个转换是不可能的，运行时一个`bad_cast`的异常类型会被抛出：

3. **const_cast**

   const_cast转换符是用来移除const或volatile属性。一般用于强制消除对象的常量性。而*C*不提供消除*const*的机制（已验证）。

   但是不能用于去除变量的常量性，而是去除指向对象的引用或指针的常量性，因此去除对象必须是指针或者引用。

   指向常量的指针被转化成非常量指针，并且仍然指向原来的对象；常量引用被转换成非常量引用，并且仍然指向原来的对象；常量对象被转换成非常量对象。

4. **reinterpret_cast**

   `reinpreter_cast<type-id> (expression)`

   reinterpret的意思是重新解释，可以将任意类型指针转换为其他类型的指针。所以他的type-id必须是一个指针、引用、算术类型。

   这个操作符能够在非相关的类型之间转换。它可以把一个指针转换成一个整数，也可以把一个整数转换成一个指针。
   
   底层实现是从一个指针到别的指针的值的二进制拷贝。

### 为什么要引入四种强制类型转换

> c语言可以在任意类型之间进行转换，但是有一点就是不安全。可能会不经意间将指向const对象的指针转换成非const对象的指针，也有可能将基类对象指针转换成派生类对象的指针。因此这四种强制类型转换是的代码更加严谨规范

同时c++风格的强转很清晰的知道在干什么，只要扫一眼就知道这样转换的目的

### 为什么说不要使用 dynamic_cast

没有说一定不能用，而是需要在恰当的场合使用恰当的特性。比如：能在编译时解决掉的问题没必要留到运行时、能用多态搞定的事情也没必要使用 dynamic_cast 和 [typeid](https://www.zhihu.com/search?q=typeid&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A170472080}) 等。



## RAII基本理解与使用

**基本概念：**RAII是c++中的一个惯用法，即“Resource Acquisition Is Initialization”，翻译为“资源获取就初始化”。是一种资源管理技术。c++之父说这种技术是依赖于类中构造函数和析构函数的性质以及与异常处理的交互性质来管理资源。

**提出原因：**首先要明确在计算机系统中，资源的数量是有限的，一定要合理管理和使用有限的资源。比如内存，文件，套接字等等吧。因此在使用资源的时候要遵循三个步骤：

1. 获取资源
2. 使用资源
3. 释放资源

正常情况下没什么问题，大家都非常规规矩矩的这样做。但是我们都知道程序员很懒，一般不喜欢干重复性很高的工作，因此有两种情况下会出现一些问题。第一种比如说对文件操作，考虑一种极端情况，各种if判断后都要释放资源，也就是说释放资源的语句要写很多次，这样是非常麻烦的。第二种情况就是在使用资源的过程中程序会抛出异常，我们必须用catch来捕获所有异常然后关闭文件，当控制流程特别复杂的时候就很烦，代码很臃肿。而且有时候释放资源的语句就不会被执行。那么有些资源就是放不掉，因此Bjarne Stroustrup就想到不管啥情况都能释放资源的就是析构函数，因为stack unwinding（栈展开）导致析构函数能被执行。因此将资源的初始化和释放都放到一个类中就能解决上面遇到的问题。

stack winding:When program run, each function(data, registers, program counter, etc) is mapped onto the stack as it is called. Because the function calls other functions, they too are mapped onto the stack. This is stack winding.

stack unwinding:Unwinding is the removal of the functions from the stack in the reverse order.(展开是以相反的顺序从堆栈中删除函数)。在c++中，系统必须确保调用所有创建起来的局部对象的析构函数。

**总结：**在构造函数中申请分配资源，在析构函数中释放资源。因为C++的语言机制保证了，当一个对象创建的时候，自动调用构造函数，当对象超出作用域的时候会自动调用析构函数。所以，在RAII的指导下，我们应该使用类来管理资源，将资源和对象的生命周期绑定。**RAII的核心思想是将资源或者状态与对象的生命周期绑定，通过C++的语言机制，实现资源和状态的安全管理,智能指针是RAII最好的例子**。

> RALL是c++区别于其他所有编程语言的重要特性。最初学习c++时的教条是new和delete一定要配套使用，但是使用RALL思想后，改成每一个资源配置动作都应该在单一语句执行，获得资源后立刻交给对象去管理，一般不要出现delete，用智能指针。



## C++11的enum class 、enum struct 和 enum

枚举类型(enumeration)使我们可以将一组整型常量组织在一起。每个枚举类型定义了一种新的类型。枚举属于字面值常量类型。

- 旧版本enum存在的问题
  1. 没有非常完全的类型安全。即不同枚举之间不能赋值，同时整形不能向枚举类型转换，但是枚举可以向整形转。
  2. 无法确定数据的类型，导致无法明确枚举类型所占用的内存大小。
  3. 枚举中的成员可以在括号外部直接访问，而不需要使用域运算符。

- enum class 、enum struct 

  有更好的类型安全和封装的特性。

  1. 与整形之间不会发生隐式类型转换，除非用static_cast强制转换
  2. 可以指定底层的数据类型，默认是int
  3. 需要通过域运算符来访问枚举成员



## **内存泄漏？出现内存泄漏如何调试？**

内存泄露一般指的是堆内存的泄露，即用户自己开辟的内存空间。应用程序使用malloc、realloc、new等函数从堆中分配到一块内存后，必须调用free或delete进行回收，否则这块内存不能继续被使用。内存泄漏会因为减少可用内存的数量从而降低计算机的性能。最终，在最糟糕的情况下，过多的可用内存被分配掉导致全部或部分设备停止正常工作，或者应用程序崩溃。内存泄漏可能不严重，甚至能够被常规的手段检测出来。在现代操作系统中，一个应用程序使用的常规内存在程序终止时被释放。这表示一个短暂运行的应用程序中的内存泄漏不会导致严重后果。在C++中出现内存泄露的主要原因就是程序猿在申请了内存后(`malloc(), new`)，没有及时释放没用的内存空间，甚至消灭了指针导致该区域内存空间根本无法释放。

**内存泄漏的原因**

1. malloc/new和delete/free没有匹配
2. new[] 和 delete[]也没有匹配
3. 没有将父类的析构函数定义为虚函数，当**父类的指针指向子类对象**时，delete该对象不会调用子类的析构函数

**检测手段**

1. 良好的程序设计能力，把new和delete全部都封装到构造函数和析构函数中，保证任何资源的释放都在析构函数中进行
2. 智能指针（万一被问道，这也是一个问题）
3. valgrind ，这个可以打印出发生内存泄露的部分代码
3. linux使用swap命令观察还有多少可以用的交换空间，两分钟内执行三四次，肉眼看看交换区是不是变小了
3. 使用/usr/bin/stat工具如netstat、vmstat等。如果发现波段有内存被分配且没有释放，有可能进程出现了内存泄漏。

**valgrind**

[参考](http://senlinzhan.github.io/2017/12/31/valgrind/)



##   :watermelon:C++11新特性

[参考链接](https://subingwen.cn/cplusplus/)

### auto和decltype

auto和decltype都是c++11新增的关键字，都用于自动类型推到，但是语法格式有区别。一句话概括，当你需要某个表达式的返回值类型而又不想实际执行它时用decltype。

- **auto**

  auto的出现有对我的代码来说两个作用：

  1. 为了避免太长的类型描述影响代码可读性。比如`std::vector<MyType>::iterator it =  myArray.begin();  `
  2. 这个类型不是我们所关注的，也会用。比如遍历容器中的值，用到

  auto自动帮我们获得定义变量的类型所以auto定义的变量必须有初始值。

  auto可以推断基本类型，也可以推断引用类型，当推断引用类型时候，将引用对象的类型作为推断类型（重要）

  auto的自动类型推断发生在编译期，所以使用auto并不会造成程序运行时效率的降低。

  编译器可以根据初始值自动推导出类型。但是不能用于函数传参以及数组类型的推导

- **decltype**

  一句话概括，当你需要某个表达式的返回值类型而又不想实际执行它时用decltype。

  有时候我们想从表达式中推断出要定义的类型，不会真的求表达式的值。

   `decltype`是为了解决复杂的类型声明而使用的关键字

  1. auto忽略顶层const，decltype保留顶层const；
  2. 对引用操作，auto推断出原有类型，decltype推断出引用；（重要）
  3. 对解引用操作，auto推断出原有类型，decltype推断出引用；
  4. auto推断时会实际执行，decltype不会执行，只做分析。

- **有了auto为什么还需要decltype?**

  `decltype` 可以让你获得编译期的类型。 `auto`不能。所以**当你需要某个表达式的返回值类型而又不想实际执行它时用decltype**。

  ```c++
  int a=8, b=3;
  auto c=a+b; //运行时需要实际执行a+b，哪怕编译时就能推导出类型
  decltype(a+b) d; //编译期类型推导
  //不可以用auto c; 直接声明变量，必须同时初始化。
  ```



### c++智能指针

https://aijishu.com/a/1060000000286819

> 智能指针是一个`RAII`（`Resource Acquisition is initialization`）类模型，用来动态的分配内存。
>
> 把指针用类封装然后实例化成对象，在对象过期的时候，让析构函数删除指向的内存
>
> 它提供所有普通指针提供的接口，却很少发生异常。在构造中，它分配内存，当离开作用域时，它会自动释放已分配的内存。这样的话，程序员就从手动管理动态内存的繁杂任务中解放出来了。

|   指针类别   |     支持     |                 备注                  |
| :----------: | :----------: | :-----------------------------------: |
| `unique_ptr` |    C++ 11    |   拥有独有对象所有权语义的智能指针    |
| `shared_ptr` |    C++ 11    |   拥有共享对象所有权语义的智能指针    |
|  `weak_ptr`  |    C++ 11    | 到 std::shared_ptr 所管理对象的弱引用 |
|  `auto_ptr`  | C++ 17中移除 |   拥有严格对象所有权语义的智能指针    |

#### 为什么要用智能指针？

原因1：内存泄露，即new和delete不匹配

原因2：多线程下对象析构问题，造成这个问题本质的原因是类对象自己销毁(析构)的时候无法对自己加锁,所以要独立出来,采用这个中间层(shared_ptr).

#### auto_ptr

最早的智能指针，c++11之后就删除了，有以下问题：

1. auto_ptr不能指向一组对象，不能和new[]一起使用
2. auto_ptr不能和标准容器一起用
3. 容易野指针。有两个auto_ptr比如说`p1和p2`，当在函数参数见传递指针的时候，所有权也会发生转移。具体来说比如p1指向一块内存，然后p2是p1的拷贝，因此p2也指向了这块内存。当函数调用完后，p2指向的这块内存释放掉了，p1不就成为了一个野指针。

所以这个东西很烂，没什么人用。

#### shared_ptr

**概述**

共享所有权，也就是说多个指针可以指向一个相同的对象，当最后一个shared_ptr离开作用域的时候才会释放掉内存。

实现原理：在shared_ptr内部有一个共享引用计数器来自动管理，计数器实际上就是指向该资源指针的个数，每当复制一个 shared_ptr，引用计数会 + 1。当一个 shared_ptr 离开作用域时，引用计数会 - 1，当引用计数为 0 的时候，则delete 内存。这样相比auto来说就好很多，当计数器为0的时候指针才会彻底释放掉这个资源。

**线程安全问题？**

[参考，有时间总结一下](https://www.zhihu.com/question/56836057)

> Boost 文档对于 shared_ptr 的线程安全有一段专门的记述，内容如下：
>
> shared_ptr objects offer the same level of thread safety as built-in types. 
>
> A shared_ptr instance can be "read" (accessed using only const operations) simultaneously by multiple threads. 一个 shared_ptr 实例可以同时被多个线程“读”（仅使用不变操作进行访问）
>
> Different shared_ptr instances can be "written to" (accessed using mutable operations such as operator= or reset) simultaneosly by multiple threads (even when these instances are copies, and share the same reference count underneath.)Any other simultaneous accesses result in undefined behavior.不同的 shared_ptr 实例可以同时被多个线程“写入”（使用类似 operator= 或 reset 这样的可变操作进行访问）（即使这些实
> 例是拷贝，而且共享下层的引用计数）。
> 任何其它的同时访问的结果会导致未定义行为。”
>
> 总结：1、同一个shared_ptr被多个线程“读”是安全的。2、同一个shared_ptr被多个线程“写”是不安全的。3、共享引用计数的不同的shared_ptr被多个线程”写“ 是安全的。

所以说我们可以借助shared_ptr实现线程安全的对象释放，但是shared_ptr本身不是100%线程安全的，不考虑其管理对象的安全级别

看线程安全问题之前最好还是要看一下源码解析。

shared_ptr 可能的线程安全隐患大概有如下几种，一是引用计数的加减操作是否线程安全，二是shared_ptr修改指向时，是否线程安全。

1. shared_ptr 的引用计数是原子操作的，所以引用计数的加减是线程安全的。

2. shared_ptr修改指针指向的时候会不安全。 同一个shared_ptr被多个线程“读”是安全的。同一个shared_ptr被多个线程“写”是不安全的(多个线程操作同一个shared_ptr对象)。如下面的代码：

   ```c++
   void fn(shared_ptr<A>& sp) {
       ...
       if (..) {
           sp = other_sp;
       } else if (...) {
           sp = other_sp2;
       }
   }
   ```

   当你在多线程回调中修改shared_ptr指向的时候。shared_ptr内数据指针要修改指向，sp原先指向的引用计数的值要减去1，other_sp指向的引用计数值要加1。然而这几步操作加起来并不是一个原子操作，如果多少线程都在修改sp的指向的时候，那么有可能会出问题。比如在导致计数在操作减一的时候，其内部的指向，已经被其他线程修改过了。引用计数的异常会导致某个管理的对象被提前析构，后续在使用到该数据的时候触发core dump。当然如果你没有修改指向的时候，是没有问题的。
   
   测试：在多个线程中同时对一个shared_ptr循环执行两遍swap。
   shared_ptr的swap函数的作用就是和另外一个shared_ptr交换引用对象和引用计数，是写操作。执行两遍swap之后,
   shared_ptr引用的对象的值应该不变。
   
   ```c++
   #include <stdio.h>
   #include <tr1/memory>
   #include <pthread.h>
   
   using std::tr1::shared_ptr;
   
   shared_ptr<int> gp(new int(2000));
   
   //多线程操作不同的shared_ptr对象，安全
   //该函数拷贝了一个p1，用p1进行操作
   shared_ptr<int>  CostaSwapSharedPtr1(shared_ptr<int> & p)
   {
       shared_ptr<int> p1(p);
       shared_ptr<int> p2(new int(1000));
       p1.swap(p2);
       p2.swap(p1);
       return p1;
   }
   
   //多线程操作指向同一个shared_ptr对象，不安全
   //直接对全局变量gp进行操作
   shared_ptr<int>  CostaSwapSharedPtr2(shared_ptr<int> & p)
   {
       shared_ptr<int> p2(new int(1000));
       p.swap(p2);
       p2.swap(p);
       return p;
   }
   
   //线程执行函数
   void* thread_start(void * arg)
   {
       int i =0;
       for(;i<100000;i++)
       {
           shared_ptr<int> p= CostaSwapSharedPtr2(gp);
           if(*p!=2000)
           {
               printf("Thread error. *gp=%d \n", *gp);
               break;
           }
       }
       printf("Thread quit \n");
       return 0;
   }
   
   int main()
   {
       pthread_t thread;
       int thread_num = 10, i=0;
       pthread_t* threads = new pthread_t[thread_num];
       for(;i<thread_num;i++)
           pthread_create(&threads[i], 0 , thread_start , &i);
       for(i=0;i<thread_num;i++)
           pthread_join(threads[i],0);
       delete[] threads;
       return 0;
   }
   ```
   
   解决方案之一就是加锁。所以甭管安全不安全，加锁就完事儿了。

**所管理数据的线程安全性**

我们上面说的是针对shared_ptr本身的线程安全问题。但是用shared_ptr管理对象的线程安全问题又是另一会儿事。

如果shared_ptr管理的数据是STL容器，那么多线程如果存在同时修改的情况，是极有可能触发core dump的。比如多个线程中对同一个vector进行push_back，或者对同一个map进行了insert。甚至是对STL容器中并发的做clear操作，都有可能出发core dump，当然这里的线程不安全性，其实是其所指向数据的类型的线程不安全导致的，并非是shared_ptr本身的线程安全性导致的。尽管如此，由于shared_ptr使用上的特殊性，所以我们有时也要将其纳入到shared_ptr相关的线程安全问题的讨论范围内。

**拥有的一些方法**

1. reset方法

   reset() 释放并销毁原生指针。如果参数为一个新指针，将管理这个新指针

   ”当智能指针调用了reset函数的时候,就不会再指向这个对象了,所以如果还有其它智能指针指向这个对象,那么其他的智能指针的引用计数会减1

   [cppreference参考](https://en.cppreference.com/w/cpp/memory/shared_ptr/reset)

2. make_shared方法

   返回一个指定类型的 std::shared_ptr，和shared_ptr的构造函数一样都是用来初始化一个智能指针对象的。但是效率上有所不同：

   > make_shared执行一次堆分配，而shared_ptr构造函数执行两次

   读过源码的应该都知道，stared_ptr里面维护了两个部分，或者叫两个控制块：

   - 引用计数相关控制块，添加删除等等
   - 被管理的对象，原生指针

   如果使用new即自身构造函数来分配内存的话，就会对于上面两部分执行heap-allocation，即两次堆分配，如下图：

   <img src="C:\Users\ACER\AppData\Roaming\Typora\typora-user-images\image-20220514103558156.png" alt="image" style="float: left;" />

   但是如果使用make_shared的话，只用执行一次heap_allocation，如下图：

   <img src="C:\Users\ACER\AppData\Roaming\Typora\typora-user-images\image-20220514104204749.png" alt="image" style="float: left;" />

   **其次使用make_shared还是异常安全的**

   在c++17之后就不是问题了，因为函数的求职顺序发生了变化，函数的每个参数都需要在计算其他参数之前完全执行

   比如下面代码：

   ```c++
    //潜在的资源泄露 
   processWidget(std::shared_ptr<Widget>(new Widget),computePriority());
   ```

   在运行期，函数的参数必须在函数被调用前被估值，所以在调用processWidget时，下面的事情肯定发生在processWidget能开始执行之前：

   1、表达式`new Widget`必须被估值即一个Widget必须被创建在堆上。2、std::shared_ptr（负责管理由new创建的指针）的构造函数必须被执行。
   3、computePriority必须跑完。
   编译器不需要必须产生这样顺序的代码。**但`new Widget`必须在std::shared_ptr的构造函数被调用前执行**，因为new的结构被用为构造函数的参数，但是computePriority可能在这两个调用前（后，或很奇怪地，中间）被执行。也就是，编译器可能产生出这样顺序的代码：

   ```cpp
   执行“new Widget”。
   执行computePriority。
   执行std::shared_ptr的构造函数。
   ```

   如果computePriority产生了一个异常，则在第一步动态分配的Widget就会泄露了，因为它永远不会被存放到在第三步才开始管理它的std::shared_ptr中。

   使用std::make_shared可以避免这样的问题。

3. swap方法

   swap 交换两个 shared_ptr 对象(即交换所拥有的对象)

4. shared_from_this

   我们往往会需要在类内部使用自身的 shared_ptr，如下代码：

   ```c++
   class Widget
   {
   public:
       void do_something(A& a)
       {
           a.widget = 该对象的 shared_ptr;
       }
   }
   ```

   上述代码是说我们将当前对象的sp交由对象a管理，那就意味着当前对象的生命周期的结束不能早于对象 a。因为对象 a 在析构之前还是有可能会使用到 `a.widget`。如果我们直接 `a.widget = this;`那肯定不行， 因为这样并没有增加当前 shared_ptr 的引用计数。shared_ptr 还是有可能早于对象 a 释放。如果我们使用 `a.widget = std::make_shared<Widget>(this);`，肯定也不行，因为这个新创建的 shared_ptr，跟当前对象的 shared_ptr 毫无关系。当前对象的 shared_ptr 生命周期结束后，依然会释放掉当前内存，那么之后 `a.widget` 依然是不合法的。对于这种，需要在对象内部获取该对象自身的 shared_ptr, 那么该类必须继承 `std::enable_shared_from_this<T>`。

**总结：**智能指针的优势在于一旦某个对象不再被引用，系统会立刻回收内存，通常发生在关键任务完成后的清理时期。同时，内存中所有的对象都是有用的，绝对没有垃圾占内存的现象出现。

#### weak_ptr

`weak_ptr` 比较特殊，它主要是为了配合`shared_ptr`而存在的。就像它的名字一样，它本身是一个弱指针，因为它本身是不能直接调用原生指针的方法的。如果想要使用原生指针的方法，需要将其先转换为一个`shared_ptr`。那`weak_ptr`存在的意义到底是什么呢？

weak指针的出现是为了解决shared指针循环引用造成的内存泄漏的问题。由于`shared_ptr`是通过引用计数来管理原生指针的，那么最大的问题就是循环引用（比如 a 对象持有 b 对象，b 对象持有 a 对象），这样必然会导致内存泄露(无法删除)。而`weak_ptr`不会增加引用计数，因此将循环引用的一方修改为弱引用，可以避免内存泄露。

如下述代码：

```c++
struct A{
    shared_ptr<B> b;
};
struct B{
    shared_ptr<A> a;
};
shared_ptr<A> pa = make_shared<A>();
shared_ptr<B> pb = make_shared<B>();
pa->b = pb;
pb->a = pa;
```

pa 和 pb 存在着循环引用，根据 shared_ptr 引用计数的原理，pa 和 pb 都无法被正常的释放，因为我们需要对方先释放。对于这种情况, 我们可以使weak_ptr：

```c++
struct A{
    shared_ptr<B> b;
};
struct B{
    weak_ptr<A> a;
};
shared_ptr<A> pa = make_shared<A>();
shared_ptr<B> pb = make_shared<B>();
pa->b = pb;
pb->a = pa;
```

weak_ptr 不会增加引用计数，因此可以打破 shared_ptr 的循环引用。

当创建一个shared指针对象时候，该指针所指向的资源数为1，当用shared对象指针创建一个weak对象时候，资源计数器没有变化。weak_ptr的构造和析构并不会改变引用计数的大小，同时由于weak_ptr没有重载运算符*，->，因此他不操作资源，只是观测

**方法**

1. expired() 判断所指向的原生指针是否被释放，如果被释放了返回 true，否则返回 false
2. use_count() 返回原生指针的引用计数
3. lock() 返回 shared_ptr，如果原生指针没有被释放，则返回一个非空的 shared_ptr，否则返回一个空的 shared_ptr
4. reset() 将本身置空

**有以下问题：**

1. 要是用weak指针对象如何判断该指针指向的对象是否销毁？

   答：weak_ptr类中有一个成员函数lock()，这个函数可以返回一个指向共享对象的shared_ptr，如果weak指针所指向的资源不存在，那么lock函数返回一个空shared指针，通过这个可以判断

2. weak_ptr类中没有重载operator *和operator->，因此不能使用weak_ptr类对象直接访问指针所指向的资源，因此如果想要访问weak_ptr指向的资源的时候，必须首先使用lock成员函数获取到该weak_ptr所指向资源的shared_ptr的对象，然后再去访问。这样做也为了避免我们在写程序时，忘记考虑weak_ptr所指向的资源被释放的情况。

> 弱指针的使用有两个：第一当 parent 类持有 child 的 shared_ptr, child 持有指向 parent 的 weak_ptr。第二是定义对象时，用强智能指针shared_ptr，在其它地方引用对象时，使用弱智能指针weak_ptr。

#### unique_ptr

`unique_ptr`的核心特点就如它的名字一样，它拥有对持有对象的唯一所有权。即两个`unique_ptr`不能同时指向同一个对象。

那具体这个唯一所有权如何体现呢？

1. `unique_ptr`不能被复制到另外一个`unique_ptr`
2. `unique_ptr`所持有的对象只能通过转移语义将所有权转移到另外一个`unique_ptr`

```c++
std::unique_ptr<A> a1(new A());
std::unique_ptr<A> a2 = a1;//编译报错，不允许复制
std::unique_ptr<A> a3 = std::move(a1);//可以转移所有权，所有权转义后a1不再拥有任何指针
```

**`unique_ptr`本身拥有的方法主要包括：**

1. get() 获取其保存的原生指针，尽量不要使用
2. bool() 判断是否拥有指针
3. release() 释放所管理指针的所有权，返回原生指针。但并不销毁原生指针。
4. reset() 释放并销毁原生指针。如果参数为一个新指针，将管理这个新指针

```c++
std::unique_ptr<A> a1(new A());
A *origin_a = a1.get();//尽量不要暴露原生指针
std::unique_ptr<A> a2(a1.release());//常见用法，转义拥有权
a2.reset(new A());//释放并销毁原有对象，持有一个新对象
a2.reset();//释放并销毁原有对象，等同于下面的写法
a2 = nullptr;//释放并销毁原有对象
```





### lambda表达式

我觉得lambda表达式的出现很简洁，也使得代码变得没那么膨胀吧

lambda 表达式定义了一个匿名函数，并且可以捕获一定范围内的变量。lambda 表达式的语法形式简单归纳如下：

```c++
[capture](params) opt -> ret {body;};
```

- 捕获列表 [capture]

  捕获一定范围内的变量，有以下几种方式：

  1. [] - 表示不捕捉任何变量
  2. [&] - 捕获外部作用域中所有变量，并作为引用在函数体内使用 (按引用捕获)
  3. [=] - 捕获外部作用域中所有变量，并作为副本在函数体内使用 (按值捕获)
  4. [=, &foo] - 按值捕获外部作用域中所有变量，并按照引用捕获外部变量 foo
  5. [this] - 捕获当前类中的 this 指针，让 lambda 表达式拥有和当前类成员函数同样的访问权限

  ```c++
  void output(int x, int y)
  {
      auto x1 = [] {return m_number; };                      // error
      auto x2 = [=] {return m_number + x + y; };             // ok
      auto x3 = [&] {return m_number + x + y; };             // ok
      auto x4 = [this] {return m_number; };                  // ok
      auto x5 = [this] {return m_number + x + y; };          // error
      auto x6 = [this, x, y] {return m_number + x + y; };    // ok
      auto x7 = [this] {return m_number++; };                // ok
  }
  ```

- 参数列表 (params): 和普通函数的参数列表一样，如果没有参数参数列表可以省略不写

- opt 选项，不需要可以省略，一般有两个

  1. mutable: 可以修改按值传递进来的拷贝（注意是能修改拷贝，而不是值本身）
  2. exception: 指定函数抛出的异常，如抛出整数类型的异常，可以使用 throw ();

- 返回值类型

  很多时候，lambda 表达式的返回值是非常明显的，因此在 C++11 中允许省略 lambda 表达式的返回值。

- 函数体：函数的实现，这部分不能省略，但函数体可以为空。

### nullptr和null的区别

[非常详细的参考链接0](https://blog.csdn.net/justdoithai/article/details/51492133)

- 首先给出NULL在C和C++中的定义

  ```c++
  #ifdef __cplusplus  
  #define NULL    0  
  #else  
  #define NULL    ((void *)0)  
  #endif  
  ```

> 要明白一点儿，NULL是一个无类型的东西，而且是一个宏。而宏这个东西，从C++诞生开始，就是C++之父嗤之以鼻的东西，他推崇尽量避免宏。

下面看一段代码：

```c++
void f(void*){}

void f(int){}

int main()
{
    f(NULL); // what function will be called?
}
```

我们本来是想用NULL来代替空指针，但是在将NULL输入到函数中时，它却选择了int形参这个函数版本，所以是有问题的，这就是用NULL代替空指针在C++程序中的二义性。**而引入了nullptr，这个问题就得到了真正解决，会很顺利的调到void f(void*)这个版本。**

**nullptr，可以保证在任何情况下都代表空指针**

nullptr并非整型类别，甚至也不是指针类型，但是能转换成任意指针类型。nullptr的实际类型是std:nullptr_t。

### 成员列表初始化

首先要说明成员列表初始化的格式

**其次说明必须被初始化的几个情况：**

1. const修饰的成员变量。因为const只能被初始化不能被赋值

2. 类中有对象或者继承关系时（没有默认构造函数的情况下）。首先要明确一点就是如果一个类有自定义的构造函数时后，编译器就不会创建默认构造函数了。 

   所以类中引用了其他的类时候（成员类），那么这个被引用的类如过有自定义的构造函数没有默认构造函数时候，就会报错

   还有继承的时候也是，创建派生类对象时会先创建基类对象，调用基类的构造函数，如果基类有自定义的构造函数的话你有没有列表初始化，编译器会调用默认构造函数，但是你没有就会出错

3. 引用的数据成员。因为const和引用都必须初始化而不能被赋值，都需要成员列表初始化。

**成员初始化的一些特点：**

1. 成员的初始化顺序与成员的声明顺序相同
2. 成员的初始化顺序与初始化列表中的位置无关
3. 初始化列表先于构造函数的函数体执行

**为什么用成员初始化列表会快一些？或者类中初始化数据成员与对数据成员赋值有什么区别？**

（区分基本类型和非基本类型）

答：构造函数执行有两个阶段，首先是初始化阶段，这个阶段所有类中的成员都会被初始化，即使成员没有出现在初始化列表中。第二个阶段是计算阶段，一般是执行构造函数体内部的赋值操作。对于基本内置类型，没啥区别，所以不讨论。主要讨论的是类类型相关的问题。举个例子：

```c++
class classA {...};
class classB
{
public:
    //赋值
    classB(classA a) {mA = a;}
    //成员列表初始化
    classB(classA a): mA(a) {}
private:
    classA mA;
};
```

对上述两个构造函数的实现来说，结果上是一样的，但在内部实现上有很大的区别。使用成员列表初始化的时候，直接调用的是A的拷贝构造函数完成。但是当赋值的时候，首先调用一次A的构造函数生成对象a，然后在调用一次A的构造函数生成对象mA，然后执行赋值构造函数。可以看到成员列表初始化的情况下少一次构造函数的调用，效率上肯定会提高。

就好比：

```c++
//拷贝构造
classA a;		//1次默认构造函数
classA b = a;
//赋值构造
classA a;		//1次默认构造函数
classA b;		//2次默认构造函数
b = a;
```



### [右值引用](#左值和右值)

### for循环

### 可变参数模板

可变参数模板和普通模板的语义是一样的，只是写法上稍有区别，声明可变参数模板时需要在typename或class后面带上省略号“...”。比如我们常常这样声明一个可变模版参数：template<typename...>或者template<class...>，一个典型的可变模版参数的定义是这样的：

```c++
template <class... T>
void f(T... args);
```

省略号的作用如下：

1. 声明一个参数包T... args，这个参数包中可以包含0到任意个模板参数；
2. 在模板定义的右边，可以将参数包展开成一个一个独立的参数。

### C++11中的原子操作（atomic operation）

[参考链接](https://blog.csdn.net/yockie/article/details/8838686?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1.control)

所谓的原子操作，取的就是“原子是最小的、不可分割的最小个体”的意义，它表示在多个线程访问同一个全局资源的时候，能够确保所有其他的线程都不在同一时间内访问相同的资源。也就是他确保了在同一时刻只有唯一的线程对这个资源进行访问。这有点类似互斥对象对共享资源的访问的保护，但是原子操作更加接近底层，因而效率更高。

互斥对象的使用，保证了同一时刻只有唯一的一个线程对这个共享进行访问，从执行的结果来看，互斥对象保证了结果的正确性，但是也有非常大的性能损失

在以往的C++标准中并没有对原子操作进行规定，我们往往是使用汇编语言，或者是借助第三方的线程库，例如intel的pthread来实现。在新标准C++11，引入了原子操作的概念，并通过这个新的头文件提供了多种原子操作数据类型，例如，atomic_bool,atomic_int等等，如果我们在多个线程中对这些类型的共享资源进行操作，编译器将保证这些操作都是原子性的，也就是说，确保任意时刻只有一个线程对这个资源进行访问，编译器将保证，多个线程访问这个共享资源的正确性。从而避免了锁的使用，提高了效率。

### C++11的std::function和std::bind

> C++11的std::function和std::bind作用的对象叫做可调用对象，先解释一下什么是可调用对象c++中有几种可调用对象，比如函数、函数指针、lambda表达式、bind对象、函数对象。
>
> **函数：**这个刚学编程的时候大家都知道了，所以说这就不说了
>
> **函数指针：**函数指针就是指向函数的指针，把函数当做变量来处理，大部分用作回调函数
>
> **lambda表达式：**（匿名函数对象，一个C++的语法糖）　一个lambda表达式表示一个可调用的代码单元，我们可以将其理解为有一个未命名的内联函数，与任何函数类似，一个lambda具有一个返回类型，一个参数列表和一个函数体，并且这个函数体是可以定义在其他函数内部的。
>
> **重载了函数调用符的类：**C++的类厉害的地方之一就是可以重载函数运算，就是retType operator( )(parameter...){ }的形式，这种重载了函数调用符的类可以直接让我们用类名来实现函数的功能，比如：
>
> ```c++
> class FunctonalClass
> {
> public:
>     bool operator()(const int &a, const int &value)
>     {
>         return a >= value;
>     }
> };
> ```
>
> 调用运算符就是`()`，重载了调用运算符的类就叫做函数对象，在泛型编程中大量使用函数对象作为实参，比如头文件functiona中定义了算术运算符，关系运算符，逻辑运算符的模板类作为函数对象来调用，比如greater源码如下：
>
> ```c++
> template <class T>
> struct greater
> {
>     bool operator()(const T& x, const T& y) const{return x > y;}
> };
> ```
>
> **std::bind：**用来生产一个可调用对象来适应原对象的参数列表。

**std::function**

从上面看由于可调用对象的定义方式比较多，但是函数的调用方式比较类似，因此我们可以使用一个统一的方式保存可调用对象或者传递可调用对象，因此就有了std::function。

std::function是一个可调用对象包装器，是一个类模板，可以容纳除了类成员函数指针之外的所有可调用对象，它可以用统一的方式处理函数、函数对象、函数指针，lambda表达式并允许保存和延迟它们的执行。下面是代码示例：

```c++
typedef std::function<int(int, int)> comfun;
// 普通函数
int add(int a, int b) { return a + b; }
// lambda表达式
auto mod = [](int a, int b){ return a % b; };
// 函数对象类
struct divide{
    int operator()(int denominator, int divisor){
        return denominator/divisor;
    }
};

int main(){
	comfun a = add;
	comfun b = mod;
	comfun c = divide();
    std::cout << a(5, 3) << std::endl;
    std::cout << b(5, 3) << std::endl;
    std::cout << c(5, 3) << std::endl;
}
```

总结：std::function对C++中各种可调用实体(普通函数、Lambda表达式、函数指针、以及其它函数对象等)的封装，形成一个新的可调用的std::function对象，简化调用。std::function对象是对C++中现有的可调用实体的一种类型安全的包裹(如：函数指针这类可调用实体，是类型不安全的)。

**std::bind**

std::bind可以看作一个通用的函数适配器，它接受一个可调用对象，生成一个新的可调用对象来适应原对象的参数列表。std::bind将可调用对象与其参数一起进行绑定，绑定后的结果可以使用std::function保存。std::bind主要有以下两个作用：

1. 将可调用对象和其参数绑定成一个仿函数；
2. 只绑定部分参数，减少可调用对象传入的参数。

bind的调用形式如下：

```c++
auto newCallable = bind(callable, arg_list);
```

该形式表达的意思是：当调用`newCallable`时，会调用`callable`，并传给它`arg_list`中的参数。需要注意的是：arg_list中的参数可能包含形如`_n`的名字。其中n是一个整数，这些参数是占位符，表示newCallable的第n个参数，它们占据了传递给newCallable的参数的位置。数值n表示生成的可调用对象中参数的位置：`_1`为newCallable的第一个参数，`_2`为第二个参数，以此类推。

```c++
//表示绑定函数 fun 的第一，二，三个参数值为： 1 2 3
std::function<void(int, int, int)> f1 = std::bind(fun_1, 1, 2, 3); 					
f1(); 	//print: x=1,y=2,z=3

//表示绑定函数 fun 的第三个参数为 3，而fun 的第一，二个参数分别由调用 f2 的第一，二个参数指定
std::function<void(int, int, int)> f2 = std::bind(fun_1, std::placeholders::_1, std::placeholders::_2, 3);
f2(1, 2);		//print: x=1,y=2,z=3

//表示绑定函数 fun 的第三个参数为 3，而fun 的第一，二个参数分别由调用 f3 的第二，一个参数指定
std::function<void(int, int, int)> f3 = std::bind(fun_1, std::placeholders::_2, std::placeholders::_1, 3);
//注意： f2  和  f3 的区别。
f3(1, 2);		//print: x=2,y=1,z=3
```

从上可以看到，std::bind的返回值是可调用实体，可以直接赋给std::function。



### c++11关键字

#### noexcept

noexcept告诉编译器指定某个函数不抛异常

C++中的异常处理是在运行时而不是编译时检测的。为了实现运行时检测，编译器创建额外的代码，然而这会妨碍程序优化。

一个操作或者函数不可能抛出任何异常，在以往的C++版本中常用throw()表示，在C++ 11中已经被noexcept代替。

如果在运行时，noexecpt函数向外抛出了异常（如果函数内部捕捉了异常并完成处理，这种情况不算抛出异常），程序会直接终止，调用std::terminate()函数，该函数内部会调用std::abort()终止程序。

> 成员函数声明后面跟上throw()，表示告诉类的使用者：我的这个方法不会抛出异常，所以，在使用该方法的时候，不必把它至于 try/catch 异常处理块中。

```c++
void swap(Type& x, Type& y) throw()   //C++11之前
{
    x.swap(y);
}
void swap(Type& x, Type& y) noexcept  //C++11
{
    x.swap(y);
}

```

#### override

告诉编译器要重写父类的方法（函数参数、返回类型必须相同）

#### final关键字

该关键字用来修饰类，当用final修饰后，该类不允许被继承，在 C++ 11 中 final 关键字要写在类名的后面

#### =default

如果一个 C++ 类没有显式地给出构造函数、析构函数、拷贝构造函数、operator = 这几类函数的实现，在需要它们时，编译器会自动生成；或者，在给出这些函数的声明时，如果没有给出其实现，编译器在链接时就会报错。=default 如果标记这类函数，编译器会给出默认实现。

=default 笔者觉得最大的作用就是，在开发中简化了那些构造函数中没有实际的初始化代码的写法，尤其是声明和实现分别属于一个 .h 和 .cpp 文件。

#### =delete

禁止编译器生成这些函数

#### using

一般的using关键子我们都是用来声明当前文件的命名空间，比如标准库的命名空间std-> using namespace std;

但在c++11中，它的用处还有几个 :

1. 取代typedef 
2. 让父类同名函数在子类中以重载方式使用



## 实现一个引用计数功能？c++中共享指针是怎样计数的？

> **什么是引用计数？**
>
> 使用一个计数器来标识当前对象被多少指针所指或者被引用的次数。当引用对象被创建或被拷贝时，引用计数要加1；当引用对象被销毁或被覆盖时，引用计数减1；当引用计数为0时，数据对象被销毁。（也是核心原理）。通俗的来讲即这块地址上每多一个指针指向他，计数加一；
>
> 因为有多个指针指向了同一个内存，如果提前释放了这个内存，那其他指向这个地址的指针则会成为野指针，就是指针悬挂现象。同时如果所有的指针都不指向这个地址，这块地址还没被释放，就会被造成内存泄漏。所以采用计数的方式来判断这个地址上还有多少个指针，当最后一个指针不再指向这块内存的时候，就释放掉这块内存。
>
> **实现引用计数的目的**
>
> 1. [右值引用](#左值和右值)一旦一个对象通过调用new被分配出来，记录谁拥有这个对象是很重要的，因为其所有者要负责对它进行delete。但是对象所有者可以有多个，且所有权能够被传递，这就使得内存跟踪变得困难。引用计数可以跟踪对象所有权，并能够自动销毁对象。
> 2. 节省内存，提高程序运行效率。如何很多对象有相同的值，为这多个相同的值存储多个副本是很浪费空间的，所以最好做法是让所有对象都共享同一个值的实现。

```c++
template <class T>
class Ref_count{
private:
    T* ptr;         //数据对象指针
    int* count;     //引用计数器指针
public:
    /*
    普通指针构造共享指针,注意这样有问题，造成二龙治水
    因为同一块内存的普通指针构建的共享指针也指的是同一块内存，所以不应该是1，应该++
    比如shared_ptr<int> s_ptr(p);     s_ptr指向了这块地址，pCount = 1
    shared_ptr<int> s_ptr1 = s_ptr;  s_ptr1也指向了这块地址，pCount = 2
    shared_ptr<int> s_ptr2(p);       s_ptr2也指向了这块地址，不过重新创建了引用计数，pCount1 = 1，这样显然不行*/
    //所以要避免一个原生指针多次使用这个函数
    Ref_count(T* t):ptr(t),count(new int(1)){}
    
    
    ~Ref_count(){
        decrease();
    }

    //拷贝构造
    Ref_count(const Ref_count<T>& tmp){
        count = tmp->count;
        ptr = tmp->ptr
        increase();
    }

    //注意=在指针里面是指向的意思，因此说明=左边的共享指针指向了=右边的
    //因此=左边的共享指针-1，=右边的共享指针+1
    Ref_count<T>& operator=(const Ref_count& tmp){
        if(tmp != this){
            decrease();
            ptr = tmp->ptr;
            count = tmp->count;
            increase();
        }
        return *this
    }

    T* operator ->() const{
        return ptr;
    }

    T& operator *() const{
        return *ptr;
    }

    void increase(){
        if(count){
            *(count)++;
        }
    }

    void decrease(){
        if(count){
            *(count)--;
            if(*count == 0){
                //引用计数为0的时候就删除数据对象指针和引用对象指针
                delete ptr;
                ptr = nullptr;
                delete count;
                count = nullptr;
            }
        }
    }

    T* get() const{
        return ptr;
    }

    int get_count() const{
        if(!count){
            return 0;
        }
        return *count;
    }
};
```

**注意千万不要吧一个原生指针给多个共享指针管理，会造成错误，具体看我的注释。**



## 哈希表时间复杂度为什么是O(1)?

首先要参考数组的查找，数组在内存中是一块连续的地址空间，只要知道查找数据的下标就可以快速定位到数据的内存。

那么哈希表就是利用了数组的这种特性，即**hash表的物理存储其实是数组**。

事实上，(“abc”,“hello”) 这样的 Key、Value 数据并不会直接存储在 Hash 表的数组中，因为数组要求存储固定数据类型，主要目的是每个数组元素中要存放固定长度的数据。所以，数组中存储的是 Key、Value 数据元素的地址指针。一旦发生 Hash 冲突，只需要将相同下标，不同 Key 的数据元素添加到这个链表就可以了。查找的时候再遍历这个链表，匹配正确的 Key。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203071623899.png" alt="阿里架构师数据结构原理：Hash表的时间复杂度为什么是O(1)？" style="zoom:80%;float:left" />





## sizeof相关面试题

> **sizeof的定义**
>
> sizeof是C语言的一种单目操作符，它并不是函数。**sizeof操作符以字节形式给出了其操作数所占存储空间的大小。**操作数可以是一个表达式或括在括号内的类型名。操作数所占存储空间的大小由操作数的类型决定。作用就是返回一个对象或者类型所占的内存字节数。sizeof在头文件中typedef为unsigned int，其值在编译时即计算好了，参数可以是数组、指针、类型、对象、函数等。它的功能是：获得保证能容纳实现所建立的最大对象的字节大小。由于在编译时计算，因此sizeof不能用来返回动态分配的内存空间的大小。
>
> 数组——编译时分配的数组空间大小；
>
> 指针——存储该指针所用的空间大小（存储该指针的地址的长度，是长整型，应该为4）；
>
> 类型——该类型所占的空间大小；
>
> 对象——对象的实际占用空间大小；
>
> 函数——函数的返回类型所占的空间大小。函数的返回类型不能是void。
>
> 对了，还要注意结构体的内存对齐原则！！！这个也是考点

问：定义一个不包含任何成员变量和成员函数的空的类，对该类型sizeof，得到的结果是多少？

答：1。因为该类的实例不包含任何信息，按常理来说应该sizeof=0的。但是当我们声明该类实例时，必须在内存中占用一定的空间才行，否则你无法使用这些实例。至于占用多少内存是由编译器决定的。用了一个char为了保证空类和空类之间在内存中不会有相同的地址。c++中的struct和class本质其实没有区别，区别仅仅是默认的“权限不同”，class是private，struct是public，sizeof(class)或者sizeof(struct)是1。

问：如果在空类里面添加一个构造函数和析构函数，sizeof是多少？

答：还是一样的。因为调用构造函数和析构函数或者其他函数只需要知道函数的地址就行，函数的地址和类的实例无关。

问：如果吧析构函数或者其他函数编程虚函数呢？

答：如果类中有虚函数，会生成虚函数表，并且每个对象都会在头部添加一个指向虚函数表的指针。所以sizeof就是指针的大小，计算机内部地址总线的宽度，32位机器上是4，64位机器上是8。

问：不用sizeof如何获得int所占的字节数？

思路：设初始值为1，则循环将值左移，直到值为0，记录循环的次数，即总共的位数，再除以8（一个字节=8位），即该类型的字节长度。

```c++
int main()
{
    int i = 1;
    int count = 0;
    while(i)
        i = i <<1;//一个循环，每次左移一位
    	count++;
    cout << count/8 << endl;//因为一个字节8位
    return 0;
}
```



## Volatile的作用？是否具有原子性？对编译器有什么影响？

对于volatile这个单词，权威词典有三个意思：

1. likely：可能的。这意味着被 volatile 形容的对象「有可能也有可能不」发生改变，因此我们不能对这样的对象的状态做出任何假设。
2. suddenly：突然地。这意味着被 volatile 形容的对象可能发生瞬时改变。
3. unexpectedly：不可预期地。这与 likely 相互呼应，意味着被 volatile 形容的对象可能以各种不可预期的方式和时间发生更改。

因此，volatile 其实就是告诉我们，被它修饰的对象出现任何情况都不要奇怪，我们不能对它们做任何假设。

volatile是一种类型修饰符

**在常规程序中的volatile**

```c++
volatile int *p = /* ... */;
int a, b;
a = *p;
b = *p;
```

如果忽略volatile关键字，上述代码只需要从内存读取一次就够了。因为从内存中读取一次之后，CPU 的寄存器中就已经有了这个值；把这个值直接复用就可以了。这样一来，编译器就会做优化，把两次访存的操作优化成一次。但是如果加上 volatile 关键字后，编译器对访问该变量的代码就不再进行优化，从而可以提供稳定访问，

总结： 当读取一个变量时，为提高存取速度，编译器优化时有时会先把变量读取到一个寄存器中；以后，再取变量值时，就直接从寄存器中取值。这个时候在寄存器和内存中都有我们的值，按道理来说应该是一致的，但有几种情况：

1. 当变量值在本线程里改变时，会同时把变量的新值copy到该寄存器中，以便保持一致
2. 当变量在因别的线程而改变了值，该寄存器的值不会相应改变，从而造成应用程序读取的值和实际的变量值不一致
3. 当该寄存器在因别的线程而改变了值，原变量的值不会改变，从而造成应用程序读取的值和实际的变量值不一致

volatile的意思是让编译器每次操作该变量时一定要从内存中真正取出，而不是使用已经存在寄存器中的值

但是要知道volatile并不能真正解决多线程之间的问题。对于临界区的资源我们可以用锁机制来保护，对于非临界区的资源，如果使用 `volatile` 会禁止编译器优化相关变量，从而降低性能，所以也不建议依赖 `volatile` 在这种情况下做线程同步。

使用`std::atomic<type>` 操作是原子的，同时构建了良好的内存屏障

**多线程编程中什么情况下需要加 volatile？**

C/C++多线程编程中不要使用volatile。C++11标准中明确指出解决多线程的数据竞争问题应该使用原子操作或者互斥锁。

因为C和C++中的volatile并不是用来解决多线程竞争问题的，而是用来修饰一些因为程序不可控因素导致变化的变量，比如访问底层硬件设备的变量，以提醒编译器不要对该变量的访问擅自进行优化。

**是否可以和const一起使用？**

没问题，这俩又不冲突



## extern 关键字

①为了能够正确实现C++代码调用其他C语言代码。加上extern "C"后，会指示编译器这部分代码按C语言的进行编译，而不是C++的。主要原因是C++和C程序编译完成后在目标代码中的命名规则不同。比如C++语言在编译的时候为了解决函数的多态问题，会将函数名和参数联合起来生成一个中间的函数名称，而C语言则不会，因此会造成链接时找不到对应函数的情况，此时C函数就需要用extern “C”进行链接指定，这告诉编译器，请保持我的名称，不要给我生成用于链接的中间函数名。

②extern是C/C++语言中表明函数和全局变量作用范围（可见性）的关键字，该关键字告诉编译器，其声明的函数和变量可以在本模块或其它模块中使用。



## auto类型推断的原理

[参考链接](https://www.cnblogs.com/harlanc/p/10628321.html)

auto使用的是**模板实参推断**（Template Argument Deduction）的机制。

从函数实参来确定模板实参的过程被称为模板实参推断(template argument deduction)；

在使用类模板创建对象时，程序员需要显式的指明实参（也就是具体的类型）,而对于函数模板，调用函数时可以不显式地指明实参,编译器会根据传入的实参类型来自动推导出模板实参类型。

看代码：

```c++
template<typename Container>
void useContainer(const Container& container)
{
    auto pos = container.begin();
    while (pos != container.end())
    {
        auto& element = *pos++;
        … // 对元素进行操作
    }
}

// auto pos = container.begin()的推断等价于如下调用模板的推断
template<typename T>
void deducePos(T pos);
deducePos(container.begin());
```

auto被一个虚构的模板类型参数T替代，然后进行推断，即相当于把变量设为一个函数参数，将其传递给模板并推断为实参，auto相当于利用了其中进行的实参推断，承担了模板参数T的作用



## C++程序优化的方法

- 空间足够时，可以将经常需要读取的资源，缓存在内存中。
- 尽量减少大内存对象的构造与析构，考虑缓存暂时不用的对象，等待后续继续使用。
- 尽量使用C++11的右值语义，减少临时对象的构造。
- 简单的功能函数可以使用内联。少用继承，多用组合，尽量减少继承层级。
- 在循环遍历时，优化判断条件，减少循环次数。
- 优化线程或进程的同步方式，能用原子操作的就不用锁。能应用层同步的就不用内核对象同步。
- 优化堆内存的使用，如果有内存频繁的申请与释放，可以考虑内存池。
- 优化线程的使用，节省系统资源与切换造成的性能损耗，线程使用频繁的可以考虑线程池。
- 尽量使用事件通知，谨慎使用轮循或者sleep函数。
- 界面开发中，耗时的业务代码不要放在UI线程中执行，使用单独的线程去异步处理耗时业务，提高界面响应速度。
- 经常重构、优化代码结构。优化算法或者架构，从设计层面进行性能的优化。



## void*（泛型指针）

指针是对内存区域的抽象。指针变量中存放着目标对象的内存地址，而与指针相复合的类型，则说明了相应内存区域中的内容具有哪些属性，以及能做什么事情。也就是说，在内存空间某块区域中的内容，原本可以是不可解读的；但是，如果有一个描述这块内存区域的指针存在，我们就能找到它（地址的作用），并且合理地使用它（类型的作用）。void* 只有其中一半的作用。因为没有明确与指针相复合的类型，所以不能解引用，也不能使用基于类型之上（sizeof(T)）的指针运算。



## C++11 RVO/NRVO机制

RVO (return value optimization) 和NRVO (named return value optimization) 是C++在处理 “返回一个class object的函数” 时常用的优化技术，主要作用就是消除临时对象的构造和析构成本。

RVO就是我经常自己写的那种，就是如果函数返回值有返回值，编译器会优化成传入一个引用，然后直接将值放在引用中：

```c++
int get_max(){
    int a;
    return a;
}
//改成
int get_max(int& a){
    int a = max;
}
```

[参考链接](https://blog.csdn.net/qq_32378713/article/details/79354943)



## C++从源代码到可执行程序的流程是怎样的

源程序（source code）→预处理器（preprocessor）→编译器（compiler）→汇编程序（assembler）→目标程序（object code）→连接器（链接器，Linker）→可执行程序（executables）

- **预处理**

  生成test.i文件，做一下处理：

  1. 展开宏定义
  2. 处理#if，#end，#ifndef
  3. 处理#include指令，把.h文件插入对应位置
  4. 删除注释

- **编译**

  编译过程所进行的是对预处理后的文件进行语法分析，词法分析，语义分析，符号汇总，然后生成汇编代码文件test.s

  词法分析阶段是编译过程的第一个阶段。这个阶段的任务是从左到右一个字符一个字符地读入源程序，即对构成源程序的字符流进行扫描然后根据构词规则识别单词(也称单词符号或符号)。词法分析程序实现这个任务。词法分析程序可以使用lex等工具自动生成。

  语法分析是编译过程的一个逻辑阶段。语法分析的任务是在词法分析的基础上将单词序列组合成各类语法短语，如“程序”，“语句”，“表达式”等等.语法分析程序判断源程序在结构上是否正确.源程序的结构由上下文无关文法描述.

  语义分析是编译过程的一个逻辑阶段. 语义分析的任务是对结构上正确的源程序进行上下文有关性质的审查, 进行类型审查

  生成test.s文件

- **汇编**

  将汇编代码转成二进制文件，二进制文件就可以让机器来读取。每一条汇编语句都会产生一句机器语言。生成test.o文件

- **链接**

  将二进制文件变成一个可执行文件。链接会涉及到动态链接和静态链接。

  

## C++的静态链接和动态链接讲一下

### 静态链接

在程序的链接阶段，将上一阶段生成的test.o文件与库函数合并生成可执行文件。

这样做好处就是以后的代码和库函数无关了，可以随便移植。

坏处是①静态链接的文件体积太大。②如果库函数更新的话需要重新链接。③在内存中会存在多分拷贝，因为每个程序都会存在一份库函数，如下图：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203201437522.png" alt="img" style="float: left;" />

静态库的生成使用如下命令：

```shell
ar -crv libadd.a add.o
```

### 动态链接

显然程序员都比较懒，比如我只用一个功能，我把所有静态库链接进去肯定是不科学的，而且每次库省级都要重新编译链接

动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入。不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例，规避了空间浪费问题。动态库在程序运行是才被载入，也解决了静态库对程序的更新、部署和发布页会带来麻烦。用户只需要更新动态库即可，增量更新。

我们把静态链接与动态链接做一个这样子的比喻：把链接过程看做我们平时学习时做笔记的过程。我们平时学习时准备一本笔记本专门记录我们的学习笔记，比如在某本书的某一页上看到一个很好很有用的知识，这时候我们有两种方法记录在我们的笔记本上。一种是直接把那一页的内容全部抄写一遍到笔记本上（静态链接）；另一种是我们在笔记本上做个简单的记录（动态链接），比如写上：xxx知识点在《xxx》的xxx页。从这两种方法中我们可以很清楚地知道两种方式的特点。第一种方式的优点就是我们在复习的时候就很方便，不用翻阅其它书籍了，但是缺点也很明显，就是占用笔记本的空间很多，这种方法很快就把我们的笔记本给写满了。第二种方式的优点就是很省空间，缺点就是每当我们复习的时候，手头上必须备着相关的参考书籍，比如我们去教室复习的时候，就得背着一大摞书去复习，这样我们复习的效率可能就没有那么高了。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203201443321.jpeg" alt="img" style="float: left;" />



## 动态编译和静态编译

静态编译，编译器在编译可执行文件时，把需要用到的对应链接库中的部分提出来，连接到可执行文件中，使可执行文件在运行时不需要依赖于动态链接库。

动态编译，可执行文件需要附带一个动态链接库，在执行的时候，需要调用其对应动态链接库的命令。优点是缩小了执行文件本身的体积，另一方面加快了编译速度，节省系统资源。缺点是需要附着一个动态链接库，当这个库很大的时候很麻烦；其次是如果该环境没有安装对应的库，动态编译的可执行文件不能运行。



## 动态联编和静态联编

在c++中联编指的是计算机程序不同部分彼此关联起来的过程。

静态联编指联编工作在编译期完成，这种联编过程是在程序运行之前完成的，又叫做早期联编。如果要实现静态联编，就必须在编译阶段确定程序中的操作调用与执行该操作代码的关系。静态联编对函数的选择是基于执行对象的指针或引用的类型，优点是效率高，但灵活性太差。

动态联编指的是程序运行的时候动态的进行。实际上是虚函数的实现过程，又叫做晚期联编。动态联编对成员函数的选择是基于对象类型的，针对不同对象类型做出不同编译结果。

c++一般情况下的联编是静态联编，当涉及到虚函数的时候就会使用动态联编。



## 指针没有初始化会怎么样

没有初始化的指针叫做野指针

指针未初始化能通过编译，但是运行的时候可能报错也可能不报错。因为你如果没使用这个指针，那倒是无所谓。但是如果你使用了，可能会出问题。因为这个指针由于没有初始化，可能会指向任何内存空间，完全随机的，有两种情况：

1. 指向的地址是系统使用的内存，用户程序不能使用，如果用户程序使用则会报错
2. 指向的不是系统的内存，不报错。但是如果这个指针指向了你之前程序使用过的内存，则你在个指针赋值，就会修改之前的内存上的数据，也会出问题。

指针变量设置为nullptr表明它不指向任何内容,这样引用她也不会出现上面的问题。

**空指针到底是什么？**

 由系统保证空指针不指向任何实际的对象或函数，也就是说，任何对象或者函数的地址都不可能是空指针，空指针与任何对象或函数的指针值都不相等。空指针表示“未分配”或者“尚未指向任何地方”。它与未初始化的指针有所不同，空指针可以确保不指向任何对象或函数，而未初始化指针可能指向任何地方。



## 野指针和指针悬挂

野指针(wild pointer)指的是未经初始化的指针

悬挂指针(dangling pointer)指的是已经销毁的对象或已经回收的地址



## 基础变量没有初始化怎么样

不怎么样，不使用他就行。

建议变量在构造函数时均初始化完成，避免不必要的问题。比如变量char buf[2000]，把字符串"hello world"拷贝进入buf，恰好EOF("\0")没有被复制，由于没有使用memset初始化变量，buf空间时随机值,那么调用print，strcmp之类的操作时，有可能会因为没有EOF,导致访问到非法地址，然后程序异常。



## c/c++参数入栈顺序和参数计算顺序

**c/c++中规定了函数参数的压栈顺序是从右至左**

举个例子：

```c++
void fun(int x, int y, int z)
{
    cout << x << &x << endl;
    cout << y << &y << endl;
    cout << z << &z << endl;
}

int main(int argc, char *argv[])
{
    fun(1, 2, 3);
    system("pause");
    return 0;
}
```

输出如下：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203301037301.png" alt="图片" style="zoom:50%;float:left" />

我们知道先入栈的占高地址，从结果看出入栈的顺序依次为`z->y->x`，即压栈顺序从右至左。

**why?**

本质上是因为支持可变长参数导致的。如果是从左至右的入站方式，最左边的参数就会被压在栈底，栈顶指针指向的是最右边的长度参数，由于可变长度，编译器无法找到最左边的参数吧。但是如果从右至左入栈，最左边的参数就在栈顶。

**printf的原理**

C/C++的函数参数是通过压入堆栈的方式来给函数传参数的。 最先压⼊的参数最后出来，在计算机的内存中，数据有 2 块，⼀块是堆，⼀块是栈（函数参数及局部变量在这里），而栈是从内存的高地址向低地址生长的，控制生长的就是堆栈指针了，最先压入的参数是在最上面，就是说在所有参数的最后面，最后压⼊的参数在最下面，结构上看起来是第⼀个，所以最后压⼊的参数总是能够被函数找到。 因为它就在堆栈指针的上方。printf的第⼀个被找到的参数就是那个字符指针，就是被双引号括起来的那⼀部分， 函数通过判断字符串里控制参数的个数来判断参数个数及数据类型，通过这些就可算出数据需要的堆栈指针的偏移了。



## 模板元编程

泛型编程是一种编程风格。

在c中不同参数相同功能函数名不同，现在函数名相同，但是可能参数类型不同也要重新写函数。模板出现就是提高了程序的复用性，提高效率。我觉得，编程能力本质上就是一个量变引起质变的过程，当刚上手的时候肯定是根据具体的数据类型来组织代码。但是随着越来越熟了，就会偷懒就会方便，所以你想用一种广泛的表达去取代具体数据类型，这在c++中就叫做模板编程。

c++模板主要分成两大类：函数模板和类模板。

模板的格式是`template<template T>`或者`template<class T>`。template是一个声明模板的关键字，表示声明一个模板关键字class不能省略，如果类型形参多余一个 ，每个形参前都要加class <类型 形参表>可以包含基本数据类型可以包含类类型.

### 模板底层怎么实现？

编译器并不是把函数模板处理成能够处理任意类的函数；

编译器从函数模板通过具体类型产生不同的函数；

编译器会对函数模板进行两次编译：在声明的地方对模板代码本身进行编译，在调用的地⽅对参数替换后的代码进行编译。 这是因为函数模板要被实例化后才能成为真正的函数，在使用函数模板的源⽂件中包含函数模板的头文件，如果该头文件中只有声明，没有定义，那编译器⽆法实例化该模板，最终导致链接错误。

### 函数模板

函数模板分为成员函数模板和普通函数模板。

**调用方式（重要）：**

1. 自动类型推导，隐式调用

   `mySwap(a, b)`

2. 显式指定类型

   `mySwap<int>(a, b)`

**模板注意事项：**

1. 自动类型推导，必须推导出一致的数据类型T才可以使用。也就是说参数类型和你模板定义的得一致才行。
2. 模板必须要确定出T的类型

**普通函数与模板函数的区别：**

1. 普通函数调用时可以发生自动类型转换（隐式类型转换）
2. 如果使用函数模板，自动类型推导的话，则不会发生隐式转换
3. 如果使用函数模板，显式指定类型，则可以发生隐式转换

**普通函数与函数模板的调用规则：**

1. 优先调用普通函数

2. 可以使用空模板参数来强制调用模板函数

   `myPrint<>(arg1, arg2,...)`

3. 函数模板也可以重载

4. 如果函数模板可以产生更好的匹配，优先调用函数模板

### 类模板

> 为什么成员函数模板不能是虚函数(virtual)？
>
> 这是因为c++ 编译器在解析一个类的时候就要确定虚函数表的大小，如果允许一个虚函数是模板函数，那么compiler就需要在parse这个类之前扫描所有的代码，找出这个模板成员函数的调用（实例化），然后才能确定vtable的大小，而显然这是不可行的，除非改变当前compiler的工作机制。因为类模板中的成员函数在调用的时候才会创建

类模板没有自动类型推导的使用方式，只有显式指定参数类型

**类模板中成员函数创建时间：**

1. 普通类中的成员函数在编译的时候就创建
2. 类模板中的成员函数在调用的时候才会创建

**类模板对象做函数参数：**

就是类模板实例化出的对象，作为参数的形式传入函数

1. 指定传入的类型 —— 直接显示对象的数据类型

   ```c++
   void print(Person<string, int>&p);
   ```

2. 参数模板化 —— 将对象中的参数变为模板进行传递

   ```c++
   template<class T1, class T2>
   void print(Person<T1, T2>& p);
   ```

3. 整个类模板化 —— 将整个对象类型模板化进行传递

   ```c++
   template<class T>
   void print(T& p);
   ```

**类模板与继承：**

1. 当派生类继承基类的一个类模板时，子类在声明时，要指定出分类中的T类型

   ```c++
   template<class T>
   class Father{
       T m;
   };
   
   //报错
   class Son: public Father{
       
   }; 
   
   //正确
   class Son: public Father<int>{
       
   }; 
   ```

   > 因为子类要继承父类中的成员变量，但是模板没有指定内存大小，所以是不确定的，而不确定性是c++所嗤之以鼻的。因此继承的时候得指定要继承模板的数据类型才行。
   >
   > 但是这样不灵活，父类中的类型就被定死了，有违背c++灵活编程，所以这种方法不太实用

2. 如果不指定，编译器无法给子类非配内存

3. 如果要灵活的话，子类也需变为类模板

   ```c++
   template<class T1, class T2>
   class Son: public Father<T2>{
       T1 obj;
   }; 
   ```


**类模板成员函数的类外实现**

```c++
//构造函数类外实现
template<class T1, class T2>
Person<T1, T2>::Person(T1 name, T2 age){}

//成员函数类外实现
template<class T1, class T2>
void Person<T1, T2>::show(){}
```

### 模板和实现可不可以不写在一个文件里面？为什么？

不可以，实习的时候出错过。编译能通过，连接不能通过。如下代码：

```c++
// add.h
template <typename T>
T add(const T &a, const T &b);

// add.cpp
#include "add.h"
template <typename T>
T add(const T &a, const T &b)
{
    return a + b;
}

// main.cpp
#include "add.h"
int main()
{
    int i = add(1, 1);
    return 0;
}

$ gcc -c main.cpp          # main.cpp编译通过
$ gcc -c add.cpp           # add.cpp编译通过
$ gcc -o main main.o add.o # 链接失败！
main.o: In function `main':
main.cpp:(.text+0x34): undefined reference to `int add<int>(int const&, int const&)'
collect2: error: ld returned 1 exit status
```

编译器面对巨量代码的时候，也是以一个一个的.cpp/.c文件作为基本单元，根据代码的include包含找到声明，翻译代码产生.o文件。注意他们每个cpp/c文件都是相互独立完成自己工作的，对于缺少的部分，如果妥善声明，会留待链接过程的时候产生引用关系。由于我们在编译main.cpp的时候只是找到了.h文件，即模板的声明，但是没有模板函数的具体实现，因此就没有办法实例化add函数。在add.cpp中有模板函数的使用，可以实例化，但是cpp编译单元中并没有人使用该函数，因此该cpp不会产生任何可执行代码，编译add.cpp时没有生成可执行代码。因此在链接的时候会报错，因为没有可执行代码

《C++编程思想》第15章(第300页)说明了原因：模板定义很特殊。由template<…>处理的任何东西都意味着编译器在当时不为它分配存储空间，它一直处于等待状态直到被一个模板实例告知。在编译器和连接器的某一处，有一机制能去掉指定模板的多重定义。所以为了容易使用，几乎总是在头文件中放置全部的模板声明和定义。

### 模板类和模板函数的区别是什么？

函数模板的实例化是由编译程序在处理函数调用时自动完成的，而类模板的实例化必须由程序员在程序中显式地指定。即函数模板允许隐式调用和显式调用而类模板只能显示调用。在使用时类模板必须加`<T>`，而函数模板不必



## 模板和继承，这个区别是什么？

**第一点：**

模板可以生成一组类或者函数，这些类或函数的实现都是一样的

继承是事物之间的一种关系，从父类到子类实际上就是从普遍到特殊、从共性到特性

**第二点：**

模板和继承都是多态性的体现，继承是运行时的多态性，模板是编译时的多态性。

**第三点：**

继承是数据的复制、模版是代码的复制。

模板函数在编译完成之后，会生成对应参数数类型的函数；

继承是对虚表、数据的复制



## mutable关键字

mutable：可变的

首先想到的是在lamba表达式中有这个东西，表示如果是值传递的，可以修改，不加这个mutable属性不能修改，表示传递过来的是常量。虽然在匿名函数内部改变了变量的值，但是在外部还是原来的值

除了lamba表达式中的，就只有类中的了

mutable 在类中只能够修饰非静态数据成员，用来修饰一个 const 示例的部分可变的数据成员的。如下代码：

```c++
struct Test
{
    int a;
    mutable int b;
};

const struct Test test = {1,2};
test.a = 10;  # 编译错误
test.b = 20;  # 允许访问
```



## c++RITT机制

**概念：**

RTTI(Run Time Type Identification)即通过运行时类型识别，C++引入这个机制是为了让程序在运行时能根据基类的指针或引用来获得该指针或引用所指的对象的实际类型。但是现在RTTI的类型识别已经不限于此了，它还能通过typeid操作符识别出所有的基本类型（int，指针等）的变量对应的类型。

和很多其他语言一样，C++是一种静态类型语言。其数据类型是在编译期就确定的，不能在运行时更改。然而由于面向对象程序设计中多态性的要求，C++中的指针或引用(Reference)本身的类型，可能与它实际代表(指向或引用)的类型并不一致。有时我们需要将一个多态指针转换为其实际指向对象的类型，就需要知道运行时的类型信息，这就产生了运行时类型识别的要求。C++要想获得运行时类型信息，只能通过RTTI机制，并且C++最终生成的代码是直接与机器相关的。

**如何实现：**

C++通过以下的两个操作提供RTTI：

（1）typeid运算符，该运算符返回其表达式或类型名的实际类型。返回指针和引用所指的实际类型；

（2）dynamic_cast运算符，该运算符将基类的指针或引用安全地转换为派生类类型的指针或引用。

我们知道C++的多态性（运行时）是由虚函数实现的，对于多态性的对象，无法在程序编译阶段确定对象的类型。当类中含有虚函数时，其基类的指针就可以指向任何派生类的对象，这时就有可能不知道基类指针到底指向的是哪个对象的情况，类型的确定要在运行时利用运行时类型标识做出。为了获得一个对象的类型可以使用typeid函数，该函数反回一个对type_info类对象的引用，要使用typeid必须使用头文件`<typeinfo>`，因为typeid是一个返回类型为typ_info的引用的函数





## 虚继承

**为什么要引入虚拟继承**

虚拟继承是多重继承中特有的概念。虚拟基类是为解决多重继承而出现的。如:类D继承自类B1、B2，而类B1、B2都继承自类A，因此在类D中两次出现类A中的变量和函数。实现的代码如下：

class A

class B1:public virtual A;

class B2:public virtual A;

class D:public B1,public B2;

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210104152509818.png" alt="img" style="zoom:80%;float:left" />

上述就是菱形继承会产生两个问题。首先是空间问题，不节省空间。类B中有类A的数据，类C中也有。其次是二义性，歧义问题。当类D调用类A中的数据时候，到底是走类B的还是走类D的？如下：

```c++
void seta(int a){ B::m_a = a; }	// B类中的m_a
void seta(int a){ C::m_a = a; }	// C类中的m_a
```

虚拟继承在一般的应用中很少用到，所以也往往被忽视，这也主要是因为在C++中，多重继承是不推荐的，也并不常用，而一旦离开了多重继承，虚拟继承就完全失去了存在的必要因为这样只会降低效率和占用更多的空间。

> C++标准库中的 iostream 类就是一个虚继承的实际应用案例。iostream 从 istream 和 ostream 直接继承而来，而 istream 和 ostream 又都继承自一个共同的名为 base_ios 的类，是典型的菱形继承。此时 istream 和 ostream 必须采用虚继承，否则将导致 iostream 类中保留两份 base_ios 类的成员。
>
> <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210104152649800.png" alt="img" style="zoom:80%;float:left" />

**引入虚继承和直接继承会有什么区别呢**

由于有了间接性和共享性两个特征，所以决定了虚继承体系下的对象在访问时必然会在时间和空间上与一般情况有较大不同。

时间：在通过继承类对象访问虚基类对象中的成员（包括数据成员和函数成员）时，都必须通过某种间接引用来完成，这样会增加引用寻址时间（就和虚函数一样），其实就是调整this指针以指向虚基类对象，只不过这个调整是运行时间接完成的。

空间：由于共享所以不必要在对象内存中保存多份虚基类子对象的拷贝，这样较之多继承节省空间。虚拟继承与普通继承不同的是，虚拟继承可以防止出现diamond继承时，一个派生类中同时出现了两个基类的子对象。也就是说，为了保证这一点，在虚拟继承情况下，基类子对象的布局是不同于普通继承的。因此，它需要多出一个指向基类子对象的指针。

在虚继承中，虚基类是由最终的派生类初始化的，换句话说，最终派生类的构造函数必须要调用虚基类的构造函数。对最终的派生类来说，虚基类是间接基类，而不是直接基类。这跟普通继承不同，在普通继承中，派生类构造函数中只能调用直接基类的构造函数，不能调用间接基类的。比如 在最终派生类 D 的构造函数中，除了调用 B 和 C 的构造函数，还调用了 A 的构造函数，这说明 D 不但要负责初始化直接基类 B 和 C，还要负责初始化间接基类 A。而在以往的普通继承中，派生类的构造函数只负责初始化它的直接基类，再由直接基类的构造函数初始化间接基类，用户尝试调用间接基类的构造函数将导致错误。

为什么这么做呢？因为现在采用了虚继承，虚基类 A 在最终派生类 D 中只保留了一份成员变量 m_a，如果由 B 和 C 初始化 m_a，那么 B 和 C 在调用 A 的构造函数时很有可能给出不同的实参，这个时候编译器就会犯迷糊，不知道使用哪个实参初始化 m_a。为了避免出现这种矛盾的情况，C++ 干脆规定必须由最终的派生类 D 来初始化虚基类 A，直接派生类 B 和 C 对 A 的构造函数的调用是无效的。在第 50 行代码中，调用 B 的构造函数时试图将 m_a 初始化为 90，调用 C 的构造函数时试图将 m_a 初始化为 100，但是输出结果有力地证明了这些都是无效的，m_a 最终被初始化为 50，这正是在 D 中直接调用 A 的构造函数的结果。

**笔试，面试中常考的C++虚拟继承的知识点**

```c++
第一种情况：　　　　　　　　 	 	第二种情况：　　　　　　　　　　第三种情况　　　　　　　　　　　　  第四种情况：
class a　　　　　　　　　　　		class a　　　　　　　　　　　　  class a　　　　　　　　　　　　　　class a
{　　　　　　　　　　　　　 		  {　　　　　　　　　　　　　　　    {　　　　　　　　　　　　　　　　　 {
    virtual void func();　　　　　　virtual void func();　　　　　　virtual void func();　　　　  virtual void func();
};　　　　　　　　　　　　　 	  };　　　　　　　　　　　　　　　　　    char x;　　　　　　　　　　　　   char x;
class b:public virtual a　　　  class b :public a　　　　　　　 };　　　　　　　　　　　　　　　   };
{　　　　　　　　　　　　　　       {　　　　　　　　　　　　　　 　   class b:public virtual a　　　 class b:public a
    virtual void foo();　　　　　　  virtual void foo();　　　　{　　　　　　　　　　　　　　　　  {
};　　　　　　　　　　　　　        };　　　　　　　　　　　　　　　　　　virtual void foo();　　　　　　　virtual void foo();
　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　           };　　　　　　　　　　　　　　　　 };
```

如果对这四种情况分别求sizeof(a）, sizeof(b)。结果是什么样的呢？下面是输出结果：

第一种：4，12   第二种：4，4   第三种：8，16   第四种：8，8

每个存在虚函数的类都要有一个4字节的指针指向自己的虚函数表，所以每种情况的类a所占的字节数应该是没有什么问题的。同时虚继承要有这样的一个指针vptr_b_a，这个指针叫虚类指针，也是四个字节；还要包括类a的字节数，所以类b的字节数就求出来了。而“第二种”和“第四种”情况则不包括vptr_b_a这个指针，这回应该木有问题了吧。

 

## c++出现的内存问题

c++中内存问题大致有这几个方面：

1. 缓冲区溢出。一般来说vector或者string都很智能帮我们管理缓冲区，所以很多时候不会出现
2. 指针悬挂/野指针，用shared_ptr和weak_ptr就可以解决
3. 重复释放，用boost的scoped_ptr或者仔细检查，只在对象析构的时候释放一次
4. 内存泄漏，也可以用scoped_ptr，这个比其他的来说还算正常，至少用一段时间内感觉不出来
5. new[]和delete不配对，moduo书中给的方案是把new[]统统换成vector就行
6. 内存碎片，这个就非常深邃了



## C++编译期多态与运行期多态

**编译期多态**

又叫做静态多态。指的是c++的泛型编程中（引申出泛型编程）模板的具现化与函数的重载解析。

编译期多态的类之间没有继承关系，约束他们的是相似的接口。在编译期间，编译器推断出模板参数，因此确定调用函数是哪个具体类型的接口。不同的推断结果调用不同的函数，这就是编译器多态。这类似于重载函数在编译器进行推导，以确定哪一个函数被调用。

**运行期多态**

又叫做动态多态。指的是c++面向对象编程中的三大特性之一。（引申出虚函数）

运行期多态要归结于类的继承思想。对于有相关功能的对象集合，我们总希望能够抽象出它们共有的功能集合，在基类中将这些功能声明为虚接口（虚函数），然后由子类继承基类去重写这些虚接口，以实现子类特有的具体功能。

运行期多态的实现依赖于虚函数机制。当某个类声明了虚函数时，编译器将为该类对象安插一个虚函数表指针，并为该类设置一张唯一的虚函数表，虚函数表中存放的是该类虚函数地址。运行期间通过虚函数表指针与虚函数表去确定该类虚函数的真正实现。

**运行期多态与编译期多态优缺点分析**

- 运行期多态优点
  1. 灵活
  2. 方便程序耦合同时减少内聚
  3. 能够处理异质对象集合（一个动物园有一堆动物，每一种动物都是一个对象）
- 运行期多态缺点
  1. 运行期间进行虚函数绑定，提高了程序运行开销。
  2. 庞大的类继承层次，对接口的修改易影响类继承层次。
  3. 由于虚函数在运行期在确定，所以编译器无法对虚函数进行优化。
- 编译期多态优点
  1. 它带来了泛型编程的概念，使得C++拥有泛型编程与STL这样的强大武器。
  2. 在编译器完成多态，提高运行期效率。
  3. 具有很强的适配性与松耦合性，对于特殊类型可由模板偏特化、全特化来处理。
- 编译期多态缺点
  1. 程序可读性降低，代码调试带来困难。
  2. 无法实现模板的分离编译，当工程很大时，编译时间不可小觑。
  3. 无法处理异质对象集合。





## C++ 中的指针参数传递和引用参数传递

指针参数传递本质上是值传递，它所传递的是⼀个地址值。值传递过程中，被调函数的形式参数作为被调函数的局部变量处理，会在栈中开辟内存空间以存放由主调函数传递进来的实参值，从而形成了实参的⼀个副本（替身）。 值传递的特点是，被调函数对形式参数的任何操作都是作为局部变量进⾏的，不会影响主调函数的实参变量的值 （形参指针变了，实参指针不会变）。 引⽤参数传递过程中，被调函数的形式参数也作为局部变量在栈中开辟了内存空间，但是这时存放的是由主调函数 放进来的实参变量的地址。被调函数对形参（本体）的任何操作都被处理成间接寻址，即通过栈中存放的地址访问 主调函数中的实参变量（根据别名找到主调函数中的本体）。因此，被调函数对形参的任何操作都会影响主调函数 中的实参变量。 

引用传递和指针传递是不同的，虽然他们都是在被调函数栈空间上的⼀个局部变量，但是任何对于引⽤参数的处理 都会通过⼀个间接寻址的⽅式操作到主调函数中的相关变量。而对于指针传递的参数，如果改变被调函数中的指针 地址，它将应⽤不到主调函数的相关变量。如果想通过指针参数传递来改变主调函数中的相关变量（地址），那就 得使⽤指向指针的指针或者指针引⽤。 

从编译的⻆度来讲，程序在编译时分别将指针和引⽤添加到符号表上，符号表中记录的是变量名及变量所对应地 址。指针变量在符号表上对应的地址值为指针变量的地址值，而引用在符号表上对应的地址值为引⽤对象的地址值 （与实参名字不同，地址相同）。符号表⽣成之后就不会再改，因此指针可以改变其指向的对象（指针变量中的值 可以改），而引用对象则不能修改。



## 简单说一下函数指针

**定义：**函数指针首先是一个指针，其次这个指针指向函数的入口地址，函数指针本身就是一个指针变量。在编译的时候，每个函数都有一个入口地址，该入口地址就是函数指针所指向的地址，有了指向函数的指针后，可以用该指针变量调用函数。

**用途：**调用该函数，或者做函数的参数，比如回调函数。



## 如何让函数在 main 函数执行前执行？

```c++
//第⼀种：gcc扩展，标记这个函数应当在main函数之前执⾏。
//同样有⼀个__attribute((destructor))，标记函数应当在程序结束之前（main结束之后，或者调⽤了exit后）执⾏;
__attribute((constructor))void before() {
 	printf("before main 1\n");
}
//第⼆种：全局和static变量的初始化在程序初始阶段，先于 main 函数的执⾏
int test1(){
     cout << "before main 2" << endl;
     return 1;
}
static int i = test1();

// 第三种：知乎⼤⽜ Milo Yip 的回答利⽤ lambda 表达式
int a = []() {
 cout << "before main 3" << endl;
 return 0;
}();

int main(int argc, char** argv) {
 cout << "main function" <<endl;
 return 0;
}

//输出
before main 1
before main 2
before main 3
main function
```



## i++和++i的区别

前置加加不会产生临时对象，后置加加必须产生临时对象，临时对象会导致效率降低

```c++
//++i
int& int::operator++ (){
     *this +=1；
     return *this；
}

//i++
const int int::operator（int）{
     int oldValue = *this；
     ++（*this）；
     return oldValue；
}
```



## 变量声明和定义区别？

- **声明**仅仅是把变量的声明的位置及类型提供给编译器，并不分配内存空间

- **定义**要在定义的地方为其分配存储空间。

**相同变量可以在多处声明（外部变量extern），但只能在一处定义**



## C++异常处理的方法

**1、try、throw和catch关键字**

C++中的异常处理机制主要使用**try**、**throw**和**catch**三个关键字。就是程序中需要throw一个类型的异常，然后catch住这个类型的异常进行处理。

程序的执行流程是先执行try包裹的语句块，如果执行过程中没有异常发生，则不会进入任何catch包裹的语句块，如果发生异常，则使用throw进行异常抛出，再由catch进行捕获，throw可以抛出各种数据类型的信息，代码中使用的是数字，也可以自定义异常class。

**2、函数的异常声明列表**

有时候，程序员在定义函数的时候知道函数可能发生的异常，可以在函数声明和定义时，指出所能抛出异常的列表，写法如下：

```text
int fun() throw(int,double,A,B,C){...};
```

这种写法表名函数可能会抛出int,double型或者A、B、C三种类型的异常，如果throw中为空，表明不会抛出任何异常，如果没有throw则可能抛出任何异常

**3、C++标准异常类 exception**

exception 类位于` <exception> `头文件中

下表是对层次结构中出现的每个异常的说明：

| 异常                  |                             描述                             |
| --------------------- | :----------------------------------------------------------: |
| **std::exception**    |              该异常是所有标准 C++ 异常的父类。               |
| std::bad_alloc        |                  该异常可以通过 new 抛出。                   |
| std::bad_cast         |              该异常可以通过 dynamic_cast 抛出。              |
| std::bad_exception    |        这在处理 C++ 程序中无法预期的异常时非常有用。         |
| std::bad_typeid       |                 该异常可以通过 typeid 抛出。                 |
| std::logic_error      |            理论上可以通过读取代码来检测到的异常。            |
| std::domain_error     |          当使用了一个无效的数学域时，会抛出该异常。          |
| std::invalid_argument |             当使用了无效的参数时，会抛出该异常。             |
| std::length_error     |        当创建了太长的 std::string 时，会抛出该异常。         |
| std::out_of_range     | 该异常可以通过方法抛出，例如 std::vector 和 std::bitset<>::operator。 |
| std::runtime_error    |           理论上不可以通过读取代码来检测到的异常。           |
| std::overflow_error   |               当发生数学上溢时，会抛出该异常。               |
| std::range_error      |           当尝试存储超出范围的值时，会抛出该异常。           |
| std::underflow_error  |               当发生数学下溢时，会抛出该异常。               |

**4、自定义异常类**

c++网络库的源码中有



## C++函数调用的压栈过程

当函数从入口函数main函数开始执行时，编译器会将我们操作系统的运行状态，main函数的返回地址、main的参数、mian函数中的变量、进行依次压栈；

当main函数开始调用func()函数时，编译器此时会将main函数的运行状态进行压栈，再将func()函数的返回地址、func()函数的参数从右到左、func()定义变量依次压栈；当func()调用f()的时候，编译器此时会将func()函数的运行状态进行压栈，再将的返回地址、f()函数的参数从右到左、f()定义变量依次压栈



## codedump

coredump是程序由于异常或者bug在运行时异常退出或者终止，在一定的条件下生成的一个叫做core的文件，这个core文件会记录程序在运行时的内存，寄存器状态，内存指针和函数堆栈信息等等。对这个文件进行分析可以定位到程序异常的时候对应的堆栈调用信息。



## 怎样判断两个浮点数是否相等？

对两个浮点数判断大小和是否相等不能直接用==来判断，会出错！明明相等的两个数比较反而是不相等！对于两个浮点数比较只能通过相减并与预先设定的精度比较，记得要取绝对值！浮点数与0的比较也应该注意。与浮点数的表示方式有关



## C++为什么提供move函数？

我想说一下一个我的个人经历

有一段代码，作用是把数据库表保存到XML文件。这个转换的过程，有个中间容器，大概是这样：

```c++
std::map<string, std::vector<int>> mapTable;
```

可以理解为map的key是数据表的列名，std::vector是那列数据（一行一行的）。

我之前是这么填充的：

```c++
std::vector<std::variant> vecRow;
for(){
	vecRow.push_back(...);
}
mapTable["列名1"] = vecRow;
```

codereview的时候我的mentor就和我讲了这个事情，本质上上述代码，把vecRow中的所有元素都复制了以便然后放到mapTable中，白白的重新创建了一遍所有行数据，又把不再需要的vecRow释放掉了。这样就很蠢。

改进：当我们知道vecRow生命（作用域后），我们可以利用这个vecRow，在std::move之前，还是有办法的，创建vecRow 的时候就让它是mapTable里某列的引用，如下：

```c++
std::vector<std::variant> &vecRow = mapTable["列名1"];
for(){
	vecRow.push_back(...);
}
```

但是考虑到这样的话会改动别的代码，所哟用谁提的std::move是最好的

`mapTable["列名1"]= std::move(vecRow);`

就这么一点点改动，就能让vecRow里的东西放进mapTable里，又没避免大规模创建、析构对象。执行完上面的函数，应该会发现vecRow空了。

**总结**

其实编译器已经在力所能及的优化他能够优化的东西了，但是编译器的优化不是万能的。有时候某个变量的生命周期编译器不可预见，但是我们自己是可以知道的，因此对于这些生命周期很短的变量我们为了节省效率就可以使用move函数。举个例子：比如黄金交易，张三买了李四的黄金，就应该把黄金从李四家移动到张三家里。但如果黄金量很大，移动的成本就会非常高。另一种方式就是大家的黄金都存在银行里，张三买李四的黄金，无非就是账户里的黄金数发生个变化，实体黄金不移动，这样效率就高很多。至于"为什么管理机构（编译器）不优化全世界的黄金交易为纸上黄金交易？"，那是因为真的有人需要搬黄金回家用啊



+++



# STL

## STL介绍

Standard Template Library，标准模板库，是C++的标准库之一，一套基于模板的容器类库，还包括许多常用的算法，提高了程序开发效率和复用性。

**STL包含6大部件：容器、迭代器、算法、仿函数、适配器和空间配置器。**

- 容器：容纳一组元素的对象，提供各种数据结构。
- 迭代器：提供一种访问容器中每个元素的方法，从实现的角度来说，迭代器是一种将`operator*`, `operator->`, `operator++`等指针操作赋予 重载的类模板。
- 仿函数：一个行为类似函数的对象，调用它就像调用函数一样，重载了`operator()`的类或者类模板。
- 算法：包括查找算法、排序算法等等。

- 适配器：用来修饰容器等，比如queue和stack，底层借助了deque。
- 空间配置器：负责空间配置和管理，是一个实现了动态空间配置，空间管理，空间释放的类模板。



## **各个容器特点总结**

> 容器分类：
>
> 1. 序列容器 sequence containers
>
>    - array
>    - vector
>    - deque
>    - list
>    - forward-list 
>
> 2. 关联容器 associative containers
>
>    （红黑树实现）
>
>    - set
>    - multiset
>    - map
>    - multimap
>
>    (hash表实现）
>
>    - hash_set
>    - hash_multiset
>    - hash_map
>    - hash_multimap
>    
> 3. 无序容器
>
>    - unordered_map
>    - unordered_multimap
>    - unordered_set
>    - unordered_multiset



1. vector:底层数据结构为数组 ，支持快速随机访问。

1. array：固定大小数组。支持快速随机访问，不能添加或者删除元素

3. list:底层数据结构为双向链表，支持快速增删。

3. forward_list:单向链表，只支持单向顺序访问

3. deque:底层数据结构为一个中央控制器和多个缓冲区，支持首尾（中间不能）快速增删，也支持随机访问。

4. stack:底层一般用23实现，封闭头部即可，不用vector的原因应该是容量大小有限制，扩容耗时

5. queue:底层一般用23实现，封闭头部即可，不用vector的原因应该是容量大小有限制，扩容耗时（stack和queue其实是适配器,而不叫容器，因为是对容器的再封装）

6. priority_queue:底层数据结构一般为vector为底层容器，堆heap为处理规则来管理底层容器实现

7. set:底层数据结构为红黑树，有序，不重复。

8. multiset:底层数据结构为红黑树，有序，可重复。 

11. map:底层数据结构为红黑树，有序，不重复。

10. multimap:底层数据结构为红黑树，有序，可重复。

11.  hash_set:底层数据结构为hash表，无序，不重复。

12. hash_multiset:底层数据结构为hash表，无序，可重复 。

13. hash_map :底层数据结构为hash表，无序，不重复。

14. hash_multimap:底层数据结构为hash表，无序，可重复。 

15. 4种无序容器

    | 无序容器           | 功能                                                         |
    | ------------------ | ------------------------------------------------------------ |
    | unordered_map      | 存储键值对 <key, value> 类型的元素，其中各个键值对键的值不允许重复，且该容器中存储的键值对是无序的。 |
    | unordered_multimap | 和 unordered_map 唯一的区别在于，该容器允许存储多个键相同的键值对。 |
    | unordered_set      | 不再以键值对的形式存储数据，而是直接存储数据元素本身（当然也可以理解为，该容器存储的全部都是键 key 和值 value 相等的键值对，正因为它们相等，因此只存储 value 即可）。另外，该容器存储的元素不能重复，且容器内部存储的元素也是无序的。 |
    | unordered_multiset | 和 unordered_set 唯一的区别在于，该容器允许存储值相同的元素。 |

18. 支持随机访问的容器：string,array,vector,deque

    支持在任意位置插入/删除的容器：list,forward_list

    支持在尾部插入元素：vector,string,deque





## vector

### vector描述

vector是动态空间，随着元素的加入它内部机制会自行空充空间以容纳新元素。vector维护了一个连续的线性空间，普通指针就可以满足要求作为vector的迭代器，随机访问迭代器。vector里面其实有三个迭代器，分别是指向空间头部的iterator，指向空间尾部的iterator和指向可用空间的iterator。当有新的元素插入时，如果当前容量够就直接插入，如果容量不够则扩容至两倍或1.5倍，如果两倍不足，则扩容至足够大的空间。由于扩充过程不是在原有的空间后面追加，而是重新申请一块新的连续内存，所以所有迭代器都会失效。

### vector的底层原理

vector底层是一个**动态数组**，包含三个迭代器，start和finish之间是已经被使用的空间范围，end_of_storage是整块连续空间包括备用空间的尾部。如图：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210906132837.png" alt="在这里插入图片描述" style="zoom: 33%;" />

### vector内存增长机制

**当空间不够装下数据（vec.push_back(val)）时，会自动申请另一片更大的空间（1.5倍或者2倍），然后把原来的数据拷贝到新的内存空间，接着释放原来的那片空间**(gcc是2倍，vs下的mingw是1.5倍)

当释放或者删除（vec.clear()）里面的数据时，其存储空间不释放，仅仅是清空了里面的数据。

因此，对vector的任何操作一旦引起了空间的重新配置，指向原vector的所有迭代器会都失效了。

### vector中的reserve和resize的区别

reserve是**直接扩充到已经确定的大小**，可以减少多次开辟、释放空间的问题（优化push_back），就可以提高效率，其次还可以减少多次要拷贝数据的问题。reserve只是保证vector中的空间大小（capacity）最少达到参数所指定的大小n。**reserve()只有一个参数。**

resize()可以改变有效空间的大小，也有改变默认值的功能。capacity的大小也会随着改变。**resize()可以有多个参数。**

 vector 的reserve增加了vector的capacity，但是它的size没有改变！而resize改变了vector的capacity同时也增加了它的size！
原因如下：

1.  reserve是容器预留空间，但在空间内不真正创建元素对象，所以在没有添加新的对象之前，不能引用容器内的元素。加入新的元素时，要调用push_back()/insert()函数。
2.   resize是改变容器的大小，且在创建对象，因此，调用这个函数之后，就可以引用容器内的对象了，因此当加入新的元素时，用operator[]操作符，或者用迭代器来引用元素对象。此时再**调用push_back()函数，是加在这个新的空间后面的。**

可能大家平时用reserve()比较多，顾名思义，reserve就是预留内存。为的是避免内存重新申请以及容器内对象的拷贝。说白了，reserve()是给push_back()准备的！而resize除了预留内存以外，还会调用容器元素的构造函数，不仅分配了N个对象的内存，还会构造N个对象。从这个层面上来说，resize()在时间效率上是比reserve()低的。但是在多线程的场景下，用resize再合适不过。

### vector中size()和capacity()的区别

size()指容器当前拥有的元素个数（对应的resize(size_type)会在容器尾添加或删除一些元素，来调整容器中实际的内容，使容器达到指定的大小。

capacity()指容器在必须分配存储空间之前可以存储的元素总数。

size表示的这个vector里容纳了多少个元素，capacity表示vector能够容纳多少元素，它们的不同是在于vector的size是2倍增长的。如果vector的大小不够了，比如现在的capacity是4，插入到第五个元素的时候，发现不够了，此时会给他重新分配8个空间，把原来的数据及新的数据复制到这个新分配的空间里。（会有迭代器失效的问题)

### vector的元素类型可以是引用吗？

vector中的元素有两个要求：

1. 元素必须能赋值
2. 元素必须能复制

对于类类型来说，需要拷贝构造和赋值运算符支持，对于像map，set这种容器需要重载运算符<的支持，而引用是必须初始化的，指向一个特定对象，本质上是一个常量指针，因此引用是不能复制，意味着容器的拷贝复制就失效了

容器开辟的时候还没有值，无法初始化，你咋能用引用

### vector迭代器失效的情况

当插入一个元素到vector中，由于引起了内存重新分配，所以指向原内存的迭代器全部失效。

当删除容器中一个元素后,该迭代器所指向的元素已经被删除，那么也造成迭代器失效。erase方法会返回下一个有效的迭代器，所以当我们要删除某个元素时，需要it=vec.erase(it)

### vector在栈还是堆，能开10万个元素的vector吗，怎么扩容的，怎么开辟内存

[参考链接](https://blog.csdn.net/apacat/article/details/111502396?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-4.pc_relevant_default&spm=1001.2101.3001.4242.3&utm_relevant_index=7)

无论你的定义是：
`vector<int*> *p = new vector<int*>`;
还是
`vector<int*> p`
其元素都是在堆上进行分配。

C++语言中，所有`new`和`malloc`创建的变量均存放在堆区，这已经是一个共识。但是鲜为人知的是，STL库中的容器虽没有经过这两个关键字创建，但同样是存放在堆区。这与动态数组性质相同。如果从汇编角度观察便会发现，容器均调用了`allocator`来创建。



### vector作为函数返回值用法

1. 在C++11中提供了RVO/NRVO机制可以防止这种重复拷贝开销。另一种是RVO/NRVO机制实现复制消除机制。
2. RVO机制使用父栈帧（或任意内存块）来分配返回值的空间，来避免对返回值的复制。也就是将Base fun();改为void fun(Base &x);

### emplace_back和push_back

**相同**

emplace_back和push_back都支持左值和右值的传入。

我们这里就说类元素，不说内置和基本类型了。

传入左值的时候，会调用拷贝构造函数构造出一个匿名对象，然后将该对象存储到vector中

传入右值的时候，调用的是两个函数的移动构造函数构。

**不同**

emplace_back 还支持另一种调用方式，原地构造（in-place construction）！

即emplace_back的参数是可变的，传入的参数可以是vector类型的构造函数的参数，直接原地构造

比如emplace_back(10, “test”)可以只调用一次constructor

而push_back(MyClass(10, “test”))中MyClass(10, “test”)调用了一次构造函数，同时值传递又调用拷贝构造函数。

### 一个vetor内存很大但实际我只用了很小一部分怎么解决

swap

### vector元素是指针类型

清空 vector 数据时，如果保存的数据项是指针类型，需要逐项 delete，否则会造成内存泄漏。

### 频繁调用push_back的影响

向 vector 的尾部添加元素，很有可能引起整个对象存储空间的重新分配，重新分配更大的内存，再将原数据拷贝到新空间中，再释放原有内存，这个过程是耗时耗力的，频繁对 vector 调⽤ push_back()会导致性能的下降。

所以我们可以用reserver（容器预留空间）解决这个问题。

### Vector如何释放空间?

vector的内存占用空间只增不减，比如你首先分配了10,000个字节，然后erase掉后面9,999个，留下一个有效元素，但是内存占用仍为10,000个。

**所有的内存空间是在vector析构时候才能被系统回收。**

empty()用来检测容器是否为空的，clear()可以清空所有元素。但是即使clear()，vector所占用的内存空间依然如故，无法保证内存的回收。

如果需要空间动态缩小，可以考虑使用deque。如果vector，可以用swap()来帮助你释放内存。

```c++
vector(Vec).swap(Vec); //将Vec的内存清除； 
vector().swap(Vec); //清空Vec的内存；
```

### vector的插入复杂度

<img src="https://img-blog.csdnimg.cn/20190804120900612.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpa2VfdGhhdA==,size_16,color_FFFFFF,t_70" alt="img" style="zoom: 50%; float: left;" />

### vector为什么是成倍增长而不是固定大小的一个容量呢？

空间和时间的权衡。

简单来说， 空间分配的多，平摊时间复杂度低，但浪费空间也多。

如果是以固定数量扩容的话，通过数学方法可以算出来平摊下来的push_back时间是O(n)

而以倍数增长的扩容方式push_back的时间复杂度是O(1)

### **为什么选择以1.5倍或者2倍方式进行扩容？而不是3倍4倍扩容？**

扩容原理为：申请新空间，拷贝元素，释放旧空间，理想的分配方案是在第N次扩容时如果能复用之前N-1次释放的空间就太好了。

**使用2倍（k=2）扩容机制扩容时，每次扩容后的新内存大小必定大于前面的总和。**

**而使用1.5倍（k=1.5)扩容时，在几次扩展以后，可以重用之前的内存空间了。**

**linux下是按照2倍的方式扩容的，而vs下是按照1.5倍的方式扩容的。**



## deque

### deque描述

vector是单向开口的连续线性空间，deque是一种双向开口的连续线性空间。双向开口就是说deque支持从头尾两端进行元素的插入和删除操作相比于vector的扩容空间的方式，deque实际上更加贴切的实现了动态空间的概念。deque没有容量的概念，因为它是动态以分段连续空间组合而成，随时可以增加一段新的空间并连接起来。由于要维护这种整体连续的假象，并提供随机存取的接口，也就是说提供random access iterator，避开重新配置，复制，释放的轮回，代价是复杂的迭代器结构。也就是说如果非必要的话，我们尽量使用vector。

### deque容器的底层存储机制

deque 容器存储数据的空间是由一段一段等长的连续空间构成，各段空间之间并不一定是连续的，可以位于在内存的不同区域。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203101434582.gif" alt="deque容器的底层存储机制" style="float: left;" />

采用一块所谓的map作为主控，这里的map实际上是一块大小连续的空间，其中每一个元素我们称之为节点node，都指向了另一段连续线性空间，成为缓冲区，缓冲期才是deque的真正存储空间主体。

通过建立 map 数组，deque 容器申请的这些分段的连续空间就能实现“整体连续”的效果。换句话说，当 deque 容器需要在头部或尾部增加存储空间时，它会申请一段新的连续空间，同时在 map 数组的开头或结尾添加指向该空间的指针，由此该空间就串接到了 deque 容器的头部或尾部。

**问：如果 map 数组满了怎么办？**

答：再申请一块更大的连续空间供 map 数组使用，将原有数据（很多指针）拷贝到新的 map 数组中，然后释放旧的空间。

### deque的iterator

deque另外一个关键的就是它的iterator设计。deque中的iterator有四个部分，cur指向缓冲区现行元素。First指向缓冲区的头，last指向缓出去的尾（有时会包含备用空间），node指向管控中心。所以总结来说，deque数据结构中包含了指向第一个节点的iterator star和指向最后一个节点的iterator finist，一块儿连续空间作为主控map，也需要记住map的大小，已备判断何时配置更大的map。

### deque和vector的区别

- vector是单向开口的连续区间，deque是双向开口的连续区间（可以在头尾两端进行插入和删除操作）
- deque没有提供空间保留功能，也就是没有capacity这个概念，而vector提供了空间保留功能。即vector有capacity和reserve函数，deque 和 list一样，没有这两个函数。

deque是在功能上合并了vector和list。

**优点：**

1. 随机访问方便，即支持[ ]操作符和vector.at()

2. 在内部方便的进行插入和删除操作

3. 可在两端进行push、pop

缺点：占用内存多



## list

### list描述

与 vector 相比，list的好处就是每次插⼊或删除⼀个元素就配置或释放⼀个空间，而且原有的迭代器也不会失 效。list 是⼀个双向链表，普通指针已经不能满足 list 迭代器的需求，因为 list 的存储空间是不连续的。list的迭代器必需具备前移和后退功能，所以list提供的是 BidirectionalIterator。list 的数据结构中只要⼀个指向 node 节点的指针就可以了。

### list和vector的区别

vector数据结构 vector和数组类似，拥有一段连续的内存空间，并且起始地址不变。因此能高效的进行随机存取，时间复杂度为o(1);但因为内存空间是连续的，所以在进行插入和删除操作时，会造成内存块的拷贝，时间复杂度为o(n)。它与数组最大的区别就是vector不需程序员自己去考虑容量问题，库里面本身已经实现了容量的动态增长，而数组需要程序员手动写入扩容函数进形扩容。

list数据结构 list是由双向链表实现的，因此内存空间是不连续的。只能通过指针访问数据，所以list的随机存取非常没有效率，时间复杂度为o(n);但由于链表的特点，能高效地进行插入和删除。非连续存储结构：list是一个双链表结构，支持对链表的双向遍历。每个节点包括三个信息：元素本身，指向前一个元素的节点（prev）和指向下一个元素的节点（next）。因此list可以高效率的对数据元素任意位置进行访问和插入删除等操作。由于涉及对额外指针的维护，所以开销比较大。

区别如下：

1. vector的随机访问效率高，但在插入和删除时（不包括尾部）需要挪动数据，不易操作。
2. list的访问要遍历整个链表，它的随机访问效率低。但对数据的插入和删除操作等都比较方便，改变指针的指向即可。
3. 从遍历上来说，list是单向的，vector是双向的。
4. vector中的迭代器在使用后就失效了，而list的迭代器在使用之后还可以继续使用。

### 怎么找某vector或者list的倒数第二个元素

**vector**

int mySize = vec.size();vec.at(mySize -2);

**list**

list不提供随机访问，所以不能用下标直接访问到某个位置的元素，要访问list里的元素只能遍历，不过你要是只需要访问list的最后N个元素的话，可以用反向迭代器来遍历：

```c++
list<int> test_list; 
for (size_t i = 1; i < 8; i++) { 
    test_list.push_back( i*2 ); 
} 
list<int>::reverse_iterator rit = find(test_list.rbegin(), test_list.rend(), 8); 
list<int>::iterator it(rit.base()); 
cout << *rit << endl; 
cout << *it << endl;
```



## stack

是⼀种先进后出的数据结构，只有⼀个出口，stack 允许从最顶端新增元素，移除最顶端元素，取得最顶端元素。 deque 是双向开口的数据结构，所以使⽤ deque 作为底部结构并封闭其头端开口，就形成了⼀个 stack。

## queue

是⼀种先进先出的数据结构，有两个出口，允许从最底端加入元素，取得最顶端元素，从最底端新增元素，从最顶端移除元素。deque 是双向开⼝的数据结构，若以 deque 为底部结构并封闭其底端的出口，和头端的⼊口就形成了⼀个 queue。（其实 list 也可以实现 deque）



## vector, list, map等容器使用场合是什么？

顺序容器首选 vector，关联容器首选 unordered_map。



## 关联式容器（map,multimap,set,multiset）

### 为何关联容器的插入删除效率一般比用其他序列容器高？

答：关联容器一般指map,multimap,set,multiset这四种底层实现都是红黑树。**对于关联容器来说，存储的只是节点。插入删除只是节点指针的换来换去，不需要做内存拷贝和内存移动。**

### set multiset 重复数据是怎么实现的？

set提供的插入函数接口：

```c++
pair<iterator,bool> insert(const value_type& elem);
iterator insert(iterator pos_hint, const value_type& elem);
```

multiset提供的插入函数的接口：

```c++
iterator insert(const value_type& elem);
iterator insert(iterator pos_hint, const value_type& elem);
```

set的返回值型别是由pair组织起来的两个值：

1. pair第一个元素返回新元素的位置，或返回现存的同值元素的位置。
2. pair第二个元素表示插入是否成功。

set的第二个insert函数，如果插入失败，就只返回重复元素的位置！

multiset中所有拥有位置提示参数的插入函数的返回值型别是相同的。这样就确保了至少有了一个通用型的插入函数，在各种容器中有共通接口。

### 为何每次insert之后，以前保存的iterator不会失效？

因为每次只是节点指针的改变，每个节点的内存没有改变。iterator就是指向每个节点内存的指针，所以插入之后，该指针是不会变的。

### 为何map和set不能像vector一样有个reserve函数来预分配数据？

最主要的原因是关联式容器内部存储的不是元素的本身，同时还有元素的节点信息，是无法预分配的。

### 当数据元素增多时（10000和20000个比较），map和set的插入和搜索速度变化如何？

查找时间复杂度是logn，所以不会有什么变化

### map用[]越界会发生什么？

- **首先要了解通过key获得map的方法都有哪些？**

  - 首先要判断key存不存在，有两种判断办法
    1. 通过count函数计算key的个数，0表示不存在，1表示存在1个
    2. 通过find函数，如果`map.find(key) != map.end()`，即find指针不是最后一个就表明找到了
  - 获得value的方法
    1. 通过重载的`[]`，即`map[key]`
    2. 通过map自身的迭代器iter，即`iter->first = key`和`iter->second = value`

- 如果通过下标去访问map中的value会有越界的可能，会发生什么？

  map源码如下：

  ```c++
  mapped_type& operator[](key_type&& _Keyval){ 
     iterator _Where = this->lower_bound(_Keyval);
      //如果没有返回end指针
     if (_Where == this->end()|| this->comp(_Keyval, this->_Key(_Where._Mynode())))
         _Where = this->insert(_Where,_STD pair<key_type, mapped_type>(_STD move(_Keyval),mapped_type()));
    	return ((*_Where).second);
  }
  ```

  可以发现如果当没有要找的key的话，会返回end，然后会执行insert语句，插入一个pair类型的对儿，key是你输入的和默认的value。
  
  所以会自动插入一个你搜索的key和默认的value。如果value为内置类型，其值将被初始化为0；如果value为自定义数据结构且用户定义了默认值则初始化为默认值，否则初始化为0。

### map和set为什么用红黑树

高度越小越好，BST这种有特殊情况，比如只有左子树有值，导致O(n)复杂度

AVL树平衡有点太变态了，导致每次自适应的时候效率低一点。所以综合来说红黑树是最优秀的

### map中[]与find的区别？

1. map的下标运算符[]的作用是：将key作为下标去执行查找，并返回对应的值；如果不存在这个key，就将一个具有该关键码和值类型的默认值的项插入这个map。
2. map的find函数：用key执行查找，找到了返回该位置的迭代器；如果不存在这个关键码，就返回尾迭代器。





## 容器内部删除一个元素

**顺序容器（序列式容器，比如vector、deque）**

erase迭代器不仅使所指向被删除的迭代器失效，而且使被删元素之后的所有迭代器失效(list除外)，所以不能使用erase(it++)的方式，但是erase的返回值是下一个有效迭代器；

```c++
It = c.erase(it);
```

**关联容器(关联式容器，比如map、set、multimap、multiset等)**

erase迭代器只是被删除元素的迭代器失效，但是返回值是void，所以要采用erase(it++)的方式删除迭代器；

```c++
c.erase(it++)
```





## allocator的使用

[参考链接](https://zhuanlan.zhihu.com/p/34725232)



## 迭代器的底层机制和失效的问题

**迭代器失效的定义：对容器的操作影响了元素的存放位置，称为迭代器失效。**

失效情况分为三种：

1. 当容器调用`erase()`方法后，当前位置到容器末尾元素的所有迭代器全部失效。
2. 当容器调用`insert()`方法后，当前位置到容器末尾元素的所有迭代器全部失效。
3. 如果容器扩容，在其他地方重新又开辟了一块内存。原来容器底层的内存上所保存的迭代器全都失效了。

通过迭代器可以在不了解容器内部原理的情况下遍历容器

它的底层实现包含两个重要的部分：萃取技术和模板偏特化。

- 萃取技术

  萃取技术可以进行类型推导，根据迭代器的不同类型处理不同流程。例如vector的迭代器类型为随机访问迭代器，list为双向迭代器

- 模板偏特化

  比较深澳

- 迭代器的类型

  1. 输入迭代器。从容器中读取元素。输入迭代器只能一次读入一个元素向前移动
  2. 输出迭代器。向容器中写入元素。输出迭代器只能一次一个元素向前移动。
  3. 正向迭代器。组合输入迭代器和输出迭代器的功能，并保留在容器中的位置
  4. 双向迭代器。组合正向迭代器和逆向迭代器的功能
  5. 随机访问迭代器。组合双向迭代器的功能与直接访问容器中任何元素的功能，即可向前向后跳过任意个元素



**序列式容器失效**

**失效原因：**因为 vetor、deque 使用了连续分配的内存，`erase`操作删除一个元素导致后面所有的元素都会向前移动一个位置，这些元素的地址发生了变化，所以当前位置到容器末尾元素的所有迭代器全部失效。

**解决办法：**由于`erase`可以返回下一个有效的iterator，因此`q.earse(it)`不行，但是`it=q.erase(it)`可以

```c++
int main() {
	vector<int> q{ 1,2,3,4,5,6 };
	// 在这里想把大于2的元素都删除
	for (auto it = q.begin(); it != q.end(); it++) {
		if (*it > 2)
			q.erase(it); // 这里就会发生迭代器失效
	}
	// 打印结果
	for (auto it = q.begin(); it != q.end(); it++) {
		cout << *it << " ";
	}
	cout << endl;
	return 0;
}

//解决办法
for(auto it=q.begin();it!=q.end();)
{
    if(*it>2)
    {
    	it=q.erase(it); // 这里会返回指向下一个元素的迭代器，因此不需要再自加了
    }
    else
    {
    	it++;
    }
}
```

**链表式容器失效**和**关联式容器失效**

**失效原因：**链表的插入和删除节点不会对其他节点造成影响，因此只会使得当前的iterator失效

**解决办法：**利用`erase`可以返回下一个有效的iteratord的特性，或者直接iterator++

```c++
//方法1
for (iter = cont.begin(); it != cont.end();)
{
   (*iter)->doSomething();
   if (shouldDelete(*iter))
      cont.erase(iter++);
   else
      iter++;
}
//方法2
for (iter = cont.begin(); iter != cont.end();)
{
   (*it)->doSomething();
   if (shouldDelete(*iter))
      iter = cont.erase(iter);  //erase删除元素，返回下一个迭代器
   else
      ++iter;
}
```



## 迭代器和指针的区别

迭代器实际上是对“遍历容器”这一操作进行了封装。迭代器不是指针，是类模板。重载了指针的一些操作符如：，->, * , ++, --等。

在编程中我们往往会用到各种各样的容器，但由于这些容器的底层实现各不相同，所以对他们进行遍历的方法也是不同的。例如，数组使用指针算数就可以遍历，但链表就要在不同节点直接进行跳转。c++我觉得是一门非常讲究方便的语言，显然这种情况是不能够出现的。因此就出现了迭代器，将遍历容器的操作封装起来，可以针对所有容器进行遍历。



## 迭代器的种类

- 前向迭代器（forward iterator）

  则 p 支持 ++p，p++，*p 操作，还可以被复制或赋值，可以用 == 和 != 运算符进行比较。

- 双向迭代器（bidirectional iterator）

  双向迭代器具有正向迭代器的全部功能，除此之外，假设 p 是一个双向迭代器，则还可以进行 --p 或者 p-- 操作（即一次向后移动一个位置）。

- 随机访问迭代器（random access iterator）

  随机访问迭代器具有双向迭代器的全部功能。除此之外，假设 p 是一个随机访问迭代器，i 是一个整型变量或常量，则 p 还支持以下操作：

  1. p+=i：使得 p 往后移动 i 个元素。
  2. p-=i：使得 p 往前移动 i 个元素。
  3. p+i：返回 p 后面第 i 个元素的迭代器。
  4. p-i：返回 p 前面第 i 个元素的迭代器。
  5. p[i]：返回 p 后面第 i 个元素的引用。

- 输入迭代器 (input iterator)

  可用于读取容器中的元素，但是不保证能支持容器的写入操作。

  只支持自增运算

- 输出迭代器 (output iterator)

  可视为与输入迭代器功能互补的迭代器；

  输出迭代器可用于向容器写入元素，但是不保证能支持读取容器内容。

  只支持自增运算





## 仿函数



## 算法

### stable_sort

stable_sort (first, last)和sort() 函数功能相似，不同之处在于该函数不会改变它们的相对位置。

stable_sort() 函数是基于归并排序实现的。

sort() 函数是基于快速排序实现的。



## STL容器是线程安全的吗？

众所周知，STL容器不是线程安全的。对于vector，即使写方（生产者）是单线程写入，但是并发读的时候，由于潜在的内存重新申请和对象复制问题，会导致读方（消费者）的迭代器失效。实际表现也就是招致了core dump。另外一种情况，如果是多个写方，并发的push_back()，也会导致core dump。

**解法如下：**

1、加锁

2、通过固定vector的大小，避免动态扩容（无push_back）来做到lock-free！即在开始并发读写之前（比如初始化）的时候，给vector设置好大小。代码如下：

```c++
vector<int> v;
v.resize(1000);
```

注意是resize，不是reserve！



## c++STl中vector、list和map插入1000万个元素，消耗对比

毫无疑问vector最小

使用std::map和std::list存放数据，消耗内存比实际数据大得多

原因：std::list和std::map属于散列容器，容器的空间之间是通过指针来关联的，所以指针会占用一部分内存，当自身存放的数据较2*8（std::list，双向链表）差别不大时，会有很大的额外内存开销。为了避免此开销，可以使用线性容器，std::vector。






+++



# c++工具类

## double buffer代替锁（无锁化）

在“读多写一”的场景下代替锁，实现高效的性能。

在《Linux服务器面试》那部分中详细讲述了锁的开销问题

**思路：**一个线程对一个变量进行写的话不会有任何问题，同时多个线程读一个变量也不会有什么问题。所以我们可以想到，用两个变量或者对象是否就可以代替锁的功能。具体的思路是假设有两个共享资源A和B，当前情况下，读线程正在读资源A。突然在某一个时刻，写线程需要更新资源，写线程发现资源A正在被访问，那么其更新资源B，更新完资源B后，进行切换，让读线程读资源B，然后写线程继续写资源A，这样就能完全实现了lock-free的目标，此种方案也可以成为双buffer方式。

**重点：**一定要保证写的时候那个buffer不能有读操作。因为写操作时删除的话，读操作读到了被删除的元素位置，会产生不可预估的问题。

**具体实现：**

- 双 buffer 的备份机制，避免了同时读写同一变量。双buffer 就是指对于通常要被多个线程访问的变量，再额外定义一个备份变量。由于是一写多读，写线程只向备份变量中写入，而所有的读线程只需要访问主变量本身即可。当写进程对备份变量的写操作完成后，会触发主变量指针和备份变量指针的互换操作，即指针切换，从而将原变量和备份变量的身份进行互换，达到数据更新的目的。
- 共享指针 shared_ptr，由于其记录了对变量的引用次数，因而可以避免指针切换时的“访问丢失”问题。要解决的问题是就是如何判断一个对象上存在线程读操作。std::shared_ptr内部有个成员函数use_count()来判断当前智能指针所指向变量的访问个数

代码部分一直没看明白

[1](https://github.com/MachinePlay/DoubleBuffer)

[2](http://www.4k8k.xyz/article/INGNIGHT/107296427)

[3](https://juejin.cn/post/6976431184892936228)

[4](https://blog.51cto.com/u_15403441/5010426)

**扩展**

双buffer方案在“一写多读”的场景下能够实现lock-free的目标，那么对于“多写一读”或者“多写多读”场景，是否也能够满足呢？

答：不太合适。首先在多写的场景下，多个写之间需要通过锁来进行同步，虽然避免了对读写互斥情况加锁，但是多线程写时通常对数据的实时性要求较高，如果使用双buffer，所有新数据必须要等到索引切换时候才能使用，很可能达不到实时性要求。其次多线程写时若用双buffer模式，则在索引切换时候也需要给对应的对象加锁，并且也要用类似于上面的while循环保证没有现成在执行写入操作时才能进行指针切换，而且此时也要等待读操作完成才能进行切换，这时候就对备用对象的锁定时间过长，在数据更新频繁的情况下是不合适的。

**应用场景：**

双buffer方案在多线程环境下能较好的解决 “一写多读” 时的数据更新问题，特别是适用于数据需要定期更新，且一次更新数据量较大的情形。



## 内存池

### 内存池概述

我们在进行数据库操作的时候为了提高数据库（关系型数据库）的访问瓶颈，除了在服务器端增加缓存服务器（例如 redis）缓存常用的数据之外，还可以增加连接池，来提高数据库服务器的访问效率。一般来说，对于数据库操作都是在访问数据库的时候创建连接，访问完毕断开连接。但是如果在高并发情况下，有些需要频繁处理的操作就会消耗很多的资源和时间，比如：

1. 建立通信连接的 TCP 三次握手
2. 数据库服务器的连接认证
   数
3. 据库服务器关闭连接时的资源回收
4. 断开通信连接的 TCP 四次挥手

### 连接数据库的步骤

MySQL 数据库是一个典型的 C/S 结构，即：客户端和服务器端。如果我们部署好了 MySQL 服务器，想要在客户端访问服务器端的数据，在编写程序的时候就可以通过官方提供的 C 语言的 API 来实现。

在程序中连接 MySql 服务器，主要分为已经几个步骤：

- 初始化连接环境

- 连接 mysql 的服务器，需要提供如下连接数据:

  1. 服务器的 IP 地址
  2. 服务器监听的端口（默认端口是 3306）
  3. 连接服务器使用的用户名（默认是 root），和这个用户对应的密码
  4. 要操作的数据库的名字

- 连接已经建立，后续操作就是对数据库数据的添删查改(调用API完成)

- 如果要进行数据 添加 / 删除 / 更新，需要进行事务的处理需要对执行的结果进行判断

  成功：提交事务

  失败：数据回滚

- 数据库的读操作 -> 查询 -> 得到结果集

- 遍历结果集 -> 得到了要查询的数据

- 释放资源


# 什么是gcc

**gcc的全称是GNU Compiler Collection，它是一个能够编译多种语言的编译器。**

最开始gcc是作为C语言的编译器（GNU C Compiler），现在除了c语言，还支持C++、java、Pascal等语言。



# gcc工作流程

- 预处理（--E）
  - 宏替换
  - 头文件展开
  - 去掉注释
  - .c文件变成了.i文件（本质上还是.c文件，只不过#include中的程序给链接进去）
- 编译（--S）
  - gcc调用不同语言的编译器
  - .i文件编程.s（汇编文件）
  - 生成汇编文件

- 汇编（-c）
  - .s文件转化成.o文件
  - 翻译成机器语言指令
  - 二进制文件
- 链接
  - .o文件变成可执行文件，一般不加后缀

> ![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202201241320667.jpeg)
>
> **预处理**实际上是将头文件、宏进行展开。
>
> **编译阶段**gcc调用不同语言的编译器。gcc实际上是个工具链，在编译程序的过程中调用不同的工具。
>
> **汇编阶段**gcc调用汇编器进行汇编。汇编语言是一种低级语言，在不同的设备中对应着不同的机器语言指令，一种汇编语言专用于某种计算机体系结构，可移植性比较差。通过相应的汇编程序可以将汇编语言转换成可执行的机器代码这一过程叫做汇编过程。汇编器生成的是可重定位的目标文件，在源程序中地址是从0开始的，这是一个相对地址，而程序真正在内存中运行时的地址肯定不是从0开始的，而且在编写源代码的时候也不能知道程序的绝对地址，所以**重定位**能够将源代码的代码、变量等定位为内存具体地址。
>
> **链接过程**会将程序所需要的目标文件进行链接成可执行文件。



# gcc常用参数

- -v/--version：查看gcc的版本
- -I：编译的时候指定头文件路径，不然头文件找不到
- -c：将汇编文件转换成二进制文件，得到.o文件
- -g：gdb调试的时候需要加
- -D：编译的时候指定一个宏（调试代码的时候需要使用例如printf函数，但是这种函数太多了对程序性能有影响，因此如果没有宏，则#ifdefine的内容不起作用）
- -wall：添加警告信息
- -On：-O是优化代码，n是优化级别：1，2，3



# 静态库和动态库

![clip_image002[4]](https://images0.cnblogs.com/blog/92071/201310/16201602-9c6047fe25ac46659d0a5ab2945552ce.png)

1. 什么是库？

   - 库是写好的现有的，成熟的，可以复用的代码。
   - 现实中每个程序都要依赖很多基础的底层库，不可能每个人的代码都从零开始，因此库的存在意义非同寻常。			

   - 库是二进制文件，.o文件
   - 将源代码变成二进制的源代码
   - 主要起到加密的作用，为了防止泄露

2. 静态库的制作

   - 原材料：源代码（.c或.cpp文件）

   - 将.c文件生成.o文件（ex：g++ a.c -c）

   - 将.o文件打包
     - ar rcs  静态库名称   原材料(ex: ar rcs libtest.a  a.0)

   - 态库的使用

   <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210608145829.png" alt="image-20210509140337810" style="zoom: 50%;" align="left" />

3. 动态库的制作(so代表动态库)
   - 命名规则：libxxx.so
   - 制作步骤
     - 将源文件生产.o文件（gcc a.c -c -fpic）
     - 打包（gcc -shared a.o -o libxxx.so）
   - 动态库的使用
     - 跟静态库一样 
   - 动态库无法加载的问题
     - 使用环境变量（临时设置和全局设置）




# gdb相关问题

- gdb 不能显示代码（No symbol table is loaded. Use the "file" command）
  - 要是用-g 比如： g++ map_test.cpp -g -o mao



# linux权限相关问题

对任意一个文件使用ls -l命令，如下图所示：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210608145838.png" alt="image-20210512102626440" style="float: left;" />

**任意取一行，如：drwxr-xr-x  2 root root 4096 2009-01-14 17:34 bin**

**用序列表示为：0123456789**

- 第一列

  - d：代表目录
  - -：代表文件
  - l：代表链接，如同windows的快捷方式

- 第一到九列

  - r：可读
  - w：可写
  - x：可执行文件
  - 0：代表文件类型
  - 123：表示文件所有者的权限
  - 456：表示同组用户的权限
  - 789：表示其他用户的权限

- 权限的数字表示

  - 读取的权限等于4，用r表示
  - 写入的权限等于2，用w表示
  - 执行的权限等于1，用x表示

- 改变文件权限命令

  > chmod 权限数字（如777） filename

- 改变目录下所有的文件的权限命令

  > chmod -R 权限数字（如777） 目录(如/home)



# 套接字类型

下面是创建套接字所用的socket所用的函数

```
#include<sys/socket.h>
int socket(int domain,int type,int protocol);
```

- **协议簇（Protocol Family）（int domain）**

  > 套接字有许多不同的通信协议分类，由socket函数第一个参数进行传递。其中最重要的是PF_INET（IPv4互联网协议族）

- **套接字类型（Type）（int type）**

  > socket函数的第二个参数决定套接字数据传输的方式。
  >
  > 协议族并不能决定数据传输方式，因为一个协议族也有很多数据传输方式

  - 面向连接的套接字（SOCK_STREAM）

     **面向连接的套接字类似于传送带**

    ![传送带图片素材_免费传送带PNG设计图片大全_图精灵](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQzwO3Qhkco3js6miYcXs9Z1Ng0zvNsfcHFkw&usqp=CAU)

    有如下特点

    1. 传输的过程中数据不会丢失
    2. 按需传送数据
    3. 传输数据不存在数据边界问题
    4. 两端套接字必须一一对应

    > 收发的套接字内部有缓冲，就是有字节数组。因此通过套接字传输的数据将保存在数组，因此数据可以填满缓冲一次被读取，也可以分段被读取，不存在数据边界问题。当缓冲区占满后，套接字无法接受数据，停止传输。所以不存在数据丢失问题

  - 面向消息的套接字（SOCK_DGRAM）

    **面向消息的套接字类似于快递**

    有如下特点

    1. 强调快速传送而非顺序传送
    2. 传输的数据可能丢失也可能损坏
    3. 传输的数据有边界
    4. 限制每次传输的数据大小

- **协议信息（int protocol）**

  > 由于socket函数前两个参数的存在，大部分情况可以向第三个参数传递0。但若同一个协议族中存在多个数据传输方式相同的协议，即数据传输方式相同，协议不同，需要第三个参数制定具体协议

  ```c++
  //IPv4中面向连接的套接字
  int tcp_socket=(PF_INET,SOCK_STREAM,IPPROTO_TCP)
  //IPv4中面向消息的套接字
  int tcp_socket=(PF_INET,SOCK_STREAM,IPPROTO_UDP)
  ```

  

# 实现基于TCP/IP的客户端服务端

- **TCP服务端默认函数调用顺序**

  1. socket()   创建套接字 
  2. bind()       分配套接字地址
  3. listen()      等待连接请求状态
  4. accpet()       允许连接
  5. read()/write()   交换数据
  6. close()         断开连接

- **TCP客户端默认函数调用顺序**

  1. socket()      创建套接字

  2. connect()    请求连接

  3. read()/write()    交换数据

  4. close()         断开连接

      >实现服务器端重要/必经过程就是给套接字分配IP和端口号（bind），但是客户端实现过程并未出现套接字的分配，而是创建套接字后立即调用了connect函数，为什么？
      >
      >答：客户端其实是分配了IP和端口号的。在调用connect的时候分配的（何时），在操作系统内核中进行分配（何地），IP用的是主机的IP，端口号随机分配（何种方式）

- **注意事项**

  - 服务器端创建套接字后连续调用bind、listen函数进入等待状态，客户端通过connect函数发起连接请求
  - 客户端只能等到服务端调用listen后才能调用connect函数
  - 客户端调用connect函数前，服务器可能率先调用accept函数，然后服务端进入阻塞状态，直到客户端调用connect为止
  
- **TCP套接字中的I/O缓冲**

  > write函数调用后并不是立刻传送数据，read函数调用后也不是马上接收数据。而是将这些数据移到输入和输出缓冲中

  如下图所示：

  ![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210615153016.png)

  I/O缓冲有以下特点：

  1. I/O缓冲在每个TCP套接字中单独存在
  2. I/O缓冲在创建套接字时自动生成
  3. 即使关闭套接字也会继续传递输出缓冲中遗留的数据
  4. 关闭套接字将丢失输入缓冲中的数据

- **套接字的断开**

  > close()函数表示完全断开套接字链接，并且不能收发任何数据。很显然这样做是不好的，若A主机断开连接后，完全无法调用接收数据和发送数据相关函数，这会导致B向A发送数据，A必须接受的数据也被销毁

  套接字中会生成两个I/O流，如下图：

![TCP/IP网络编程》第7 章优雅的断开套接字的连接笔记_riba2534的博客-CSDN博客](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210616133503.png)

​		一旦两台主机间建立了套接字链接，每个主机就会拥有单独的输入流和输出流



# Linux操作系统中断

- **中断概念**

  > 中断是指在CPU正常运行期间，由于内外部事件或由程序预先安排的事件引起的CPU暂时停止正在运行的程序，转而为该内部或外部事件或预先安排的事件服务的程序中去，服务完毕后再返回去继续运行被暂时中断的程序。这样的中断机制极大的提高了CPU运行效率。

  根据CSAPP中所描述，中断是异常的一种类别。（p504）什么是异常？比如说在处理器中，依次执行对应的指令流程，这样的控制转移序列叫做控制流。但是系统会出现一些变化，系统必须对这种变化做出反应，而且这种变化是随机的，也不一定跟执行当前的程序关联，比若说子进程终止时父进程必须得到通知，硬盘定时器定期产生一个信号。这种叫做**控制流发生突变**，这些突变成为**异常控制流**。计算机的各个层次都会发生异常。(p502)

  异常可以分为：中断、陷阱、故障、终止

  | 类别 |       原因        | 同步/异步 |       返回行为       |
  | :--: | :---------------: | :-------: | :------------------: |
  | 中断 | 来自I/O设备的信号 |   异步    | 总是返回到下一条指令 |
  | 陷阱 |    有意的异常     |   同步    | 总是返回到下一条指令 |
  | 故障 | 潜在可恢复的错误  |   同步    |  可能返回到当前指令  |
  | 终止 |  不可恢复的错误   |   同步    |       不会返回       |
  
  
  
- **硬中断**

  硬中断是我们通常所说的中断的概念。硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的IRQ（中断请求）。内核中维护了一个IDT（中断描述符表），表中是中断处理函数的地址和一些其他的控制位。0-31号中断号位系统为预定义的中断和异常保留的，用户不得使用，所以硬件中断号从32开始分发。每当CPU接收到一个中断或者异常信号，CPU首先要做的决定是否响应这个中断（具体由中断控制器根据中断优先级决定是否给CPU发送中断信号），如果决定响应，就终止当前运行进程的运行，根据IDTR寄存器获取中断描述符表基地址，然后根据中断号定位具体的中断描述符。

- **软中断**	

  软中断是由当前正在运行的进程所产生的。 软中断并不会直接中断CPU。这种中断是一种需要内核为正在运行的进程去做一些事情（通常为I/O）的请求。

  > 中断在本质上是软件或者硬件发生了某种情形而通知处理器的行为，处理器进而停止正在运行的指令流，去转去执行预定义的中断处理程序。软件中断也就是通知内核的机制的泛化名称，目的是促使系统切换到内核态去执行异常处理程序。这里的异常处理程序其实就是一种系统调用，软件中断可以当做一种异常。总之，软件中断是当前进程切换到系统调用的过程。



# 系统调用知识点

## 用户态和内核态

[l链接](https://blog.csdn.net/u013291303/article/details/63682298)

## 系统调用过程

用户空间的程序无法直接执行内核代码，它们不能直接调用内核空间中的函数，因为内核驻留在受保护的地址空间上。如果进程可以直接在内核的地址空间上读写的话，系统安全就会失去控制。所以，应用程序应该以某种方式通知系统，告诉内核自己需要执行一个系统调用，希望系统切换到内核态，这样内核就可以代表应用程序来执行该系统调用了。

通知内核的机制是靠软件中断实现的。首先，用户程序为系统调用设置参数。其中一个参数是系统调用编号。参数设置完成后，程序执行“系统调用”指令。这个指令会导致一个异常：产生一个事件，这个事件会致使处理器切换到内核态并跳转到一个新的地址，并开始执行那里的异常处理程序。此时的异常处理程序实际上就是系统调用处理程序。它与硬件体系结构紧密相关。

> **系统调用的过程：**首先将API函数参数压到栈上，然后将函数内调用系统调用的代码放入寄存器，通过陷入中断，进入内核将控制权交给操作系统，操作系统获得控制后，将系统调用代码拿出来，跟操作系统一直维护的一张系统调用表做比较，已找到该系统调用程序体的内存地址，接着访问该地址，执行系统调用。执行完毕后，返回用户程序

## 系统调用和函数调用区别	

**库函数调用**

函数调用主要通过压栈出栈的操作，面向应用开发。库函数顾名思义是把函数放到库里。是把一些常用到的函数编完放到一个文件里，供别人用。别人用的时候把它所在的文件名用#include<>加到里面就可以了。一般是指编译器提供的可在c源程序中调用的函数。可分为两类，一类是c语言标准规定的库函数，一类是编译器特定的库函数。(由于版权原因，库函数的源代码一般是不可见的，但在头文件中你可以看到它对外的接口)

**系统调用**

系统调用就是用户在程序中调用操作系统所提供的一个子功能，也就是系统API，系统调用可以被看做特殊的公共子程序。通俗的讲是操作系统提供给用户程序调用的一组“特殊”接口。用户程序可以通过这组“特殊”接口来获得操作系统内核提供的服务，比如用户可以通过文件系统相关的调用请求系统打开文件、关闭文件或读写文件，可以通过时钟相关的系统调用获得系统时间或设置定时器等。系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，凡是与资源有关的操作（如存储分配、进行I/O传输及管理文件等），都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

------



# 对事件的两种处理方式

## reactor

如果要让服务器服务多个客户端，那么最直接的方式就是为每一条连接创建线程。其实创建进程也是可以的，原理是一样的，进程和线程的区别在于线程比较轻量级些，线程的创建和线程间切换的成本要小些，为了描述简述，后面都以线程为例。处理完业务逻辑后，随着连接关闭后线程也同样要销毁了，但是这样不停地创建和销毁线程，不仅会带来性能开销，也会造成浪费资源，而且如果要连接几万条连接，创建几万个线程去应对也是不现实的。要这么解决这个问题呢？我们可以使用「资源复用」的方式。也就是不用再为每个连接创建线程，而是创建一个「线程池」，将连接分配给线程，然后一个线程可以处理多个连接的业务。不过，这样又引来一个新的问题，线程怎样才能高效地处理多个连接的业务？

当一个连接对应一个线程时，线程一般采用「read -> 业务处理 -> send」的处理流程，如果当前连接没有数据可读，那么线程会阻塞在 `read` 操作上（ socket 默认情况是阻塞 I/O），不过这种阻塞方式并不影响其他线程。但是引入了线程池，那么一个线程要处理多个连接的业务，线程在处理某个连接的 `read` 操作时，如果遇到没有数据可读，就会发生阻塞，那么线程就没办法继续处理其他连接的业务。要解决这一个问题，最简单的方式就是将 socket 改成非阻塞，然后线程不断地轮询调用 `read` 操作来判断是否有数据，这种方式虽然该能够解决阻塞的问题，但是解决的方式比较粗暴，因为轮询是要消耗 CPU 的，而且随着一个 线程处理的连接越多，轮询的效率就会越低。

有没有办法在只有当连接上有数据的时候，线程才去发起读请求呢？答案是有的，实现这一技术的就是 I/O 多路复用。线程池复用+IO复用就形成了reactor模式。

**Reactor的定义：**是一种接收多个输入事件的服务器事件驱动处理模式。服务器端通过IO多路复用来处理这些输入事件，并将这些事件同步分派给对应的处理线程。其实reactor模式也叫做Dispatcher 模式，本质上就是将收到的事件进行分发处理。Reactor模式中有两个关键的组成：①主反应堆reactor在一个单独的线程中运行，负责监听和分发事件，将接收到的事件分为监听socket和连接socket，连接socket放入任务队列让线程池线程去抢占式调度。②Handlers或Accepter，处理任务队列中具体的逻辑或者建立连接socket。

根据 Reactor 的数量和处理资源池线程的数量不同，有 3 种典型的实现：

1. 单 Reactor 单线程；
2. 单 Reactor 多线程；
3. 主从 Reactor 多线程。

接下来一一介绍：

- **单 Reactor 单线程**

  顾名思义，一个主反应堆reactor，一个accepter或者handler来处理接收的事件。

  <img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost4@main/操作系统/Reactor/单Reactor单进程.png" alt="img" style="zoom:50%;float:left" />

  **优点：**模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成。

  **缺点：**性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈。
  可靠性问题，线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。

  **使用场景：**客户端的数量有限，业务处理非常快速，比如 Redis，业务处理的时间复杂度 O(1)，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。

- **单 Reactor 多线程**

  一个主反应堆reactor和一个线程池，线程池用来处理分发的事件

  <img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost4@main/操作系统/Reactor/单Reactor多线程.png" alt="img" style="zoom:46%;float:left" />

  **优点：**可以充分利用多核 CPU 的处理能力。

  **缺点：**多线程数据共享和访问比较复杂；Reactor 承担所有事件的监听和响应，在单线程中运行，高并发场景下容易成为性能瓶颈。

- **主从 Reactor 多线程**

  就是游双书里面的半同步/半反应堆模型，给这个归到了代码逻辑层面。

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203290943547.png" style="zoom:45%;float:left" />

  主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。

  主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。

  **优点：**父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。
  父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。
  这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。

## preactor

在 Reactor 模式中，Reactor 等待某个事件或者可应用或者操作的状态发生（比如文件描述符可读写，或者是 Socket 可读写）。
然后把这个事件传给事先注册的 Handler（事件处理函数或者回调函数），由后者来做实际的读写操作。
其中的读写操作都需要应用程序同步操作，所以 Reactor 是非阻塞同步网络模型。
如果把 I/O 操作改为异步，即交给操作系统来完成就能进一步提升性能，这就是异步网络模型 Proactor。

preactor模型如下图所示：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203290949372.png" alt="img" style="zoom:50%;float:left" />

工作流程如下：

1. Proactor Initiator 负责创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过
   Asynchronous Operation Processor 注册到内核；
2. Asynchronous Operation Processor 负责处理注册请求，并处理 I/O 操作；
3. Asynchronous Operation Processor 完成 I/O 操作后通知 Proactor；
4. Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理；
5. Handler 完成业务处理；

理论上 Proactor 比 Reactor 效率更高，异步 I/O 更加充分发挥 DMA(Direct Memory Access，直接内存存取)的优势。
但是Proactor有如下缺点：

1. 编程复杂性，由于异步操作流程的事件的初始化和事件完成在时间和空间上都是相互分离的，因此开发异步应用程序更加复杂。应用程序还可能因为反向的流控而变得更加难以 Debug；
2. 内存使用，缓冲区在读或写操作的时间段内必须保持住，可能造成持续的不确定性，并且每个并发操作都要求有独立的缓存，相比 Reactor 模式，在 Socket 已经准备好读或写前，是不要求开辟缓存的；
3. 操作系统支持，Windows 下通过 IOCP 实现了真正的异步 I/O，而在 Linux 系统下，Linux 2.6 才引入，目前异步 I/O 还不完善。
4. Reactor处理耗时长的操作会造成事件分发的阻塞，影响到后续事件的处理；

> 可惜的是，在 Linux 下的异步 I/O 是不完善的，
> `aio` 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，这也使得基于 Linux 的高性能网络程序都是使用 Reactor 方案。
>
> 而 Windows 里实现了一套完整的支持 socket 的异步编程接口，这套接口就是 `IOCP`，是由操作系统级别实现的异步 I/O，真正意义上异步 I/O，因此在 Windows 里实现高性能网络程序可以使用效率更高的 Proactor 方案。



# 文件(不带缓存的)I/O和标准(带缓存的)I/O

​	**首先要明确一个问题：有无缓存是相对于用户层面来说的，而不是系统内核层面。在系统内核层面，一直都存在有“内核高速缓存”**

- 不带缓存的概念

  > 所谓不带缓存，并不是指内核不提供缓存，而是在用户进程层次没有提供缓存。不带缓存的I/O只存在系统调用(write和read函数)，不是函数库的调用。**系统内核对磁盘的读写都会提供一个块缓冲（在有些地方也被称为内核高速缓存）**，当用write函数对其写数据时，直接调用系统调用，将数据写入到块缓存进行排队，当块缓存达到一定的量时，才会把数据写入磁盘。因此所谓的不带缓存的I/O是指用户进程层面不提供缓存功能（但内核还是提供缓冲的）。
  >
  > 文件I/O以文件标识符（整型）作为文件唯一性的判断依据。这种操作与系统有关，移植有一定的问题。

- 带缓存的概念

  >  与之相对的就是带缓存I/O。而带缓存的是在不带缓存的基础之上封装了一层，在用户进程层次维护了一个输入输出缓冲区，使之能跨OS，成为ASCI标准，称为标准IO库。其实就是在用户层再建立一个缓存区，这个缓存区的分配和优化长度等细节都是标准IO库代你处理好了，不用去操心。第一次调用带缓存的文件操作函数时标准库会自动分配内存并且读出一段固定大小的内容存储在缓存中。所以以后每次的读写操作并不是针对硬盘上的文件直接进行的，而是针对内存中的缓存的。
  >
  >  不带缓存的文件操作通常都是系统提供的系统调用， 更加低级，直接从硬盘中读取和写入文件，由于IO瓶颈的原因，速度并不如意，而且原子操作需要程序员自己保证，但使用得当的话效率并不差。另外标准库中的带缓存文件IO 是调用系统提供的不带缓存IO实现的。

  - 因此，标准I/O函数有两个优点：

    ​	1. 具有良好的移植性

    ​	2. 利用用户层提供的缓存区（流缓冲）提高性能

  - 标准I/O函数缺点

    1. 不容易进行双向通信
    2. 有时可能频繁调用fflush函数
    3. 需要以FILE结构体指针的形式返回文件描述符

- 举例说明

  > **带缓冲的I/O在往磁盘写入相同的数据量时，会比不带缓冲的I/O调用系统调用的次数要少。**比如内核缓冲存储器长度为100字节，在进行写操作时每次写入10个字节，则你需要调用10次write函数才能把内核缓冲区写满。但是要注意此时数据还在缓冲区，不在磁盘中，缓冲区满时才进行实际的I/O操作，把数据写入到磁盘，这样调用了太多次系统调用，显得效率很低。但是若调用标准I/O函数，假设用户层缓冲区为50字节（称为流缓存），则用fwrite将数据写入到流缓存，等到流缓存区存满之后再进入内核缓存区，在调用write函数将数据写入到内核缓冲区中，若内核缓冲区满或执行fflush操作，那么内核缓冲区的数据会写入到磁盘中

  - 无缓存IO操作数据流向路径：**数据——内核缓存区——磁盘**
  - 标准IO操作数据流向路径：**数据——流缓存区——内核缓存区——磁盘**

- apue三种io的总结

  在apue中有三种io类型，如下：

  1. 文件I/O（不带缓冲的I/O）：open、read、write、lseek、close
  2. 标准I/O（带缓冲的I/O）：标准I/O库由ISO C标准说明
  3. 高级I/O：非阻塞I/O、I/O多路转接、异步I/O、readv和writev



# 阻塞非阻塞，同步异步的区别

[参考](https://blog.51cto.com/yaocoder/1308899)

[参考2，这个比较符合我的想法](https://blog.csdn.net/historyasamirror/article/details/5778378)

进程通讯层面，阻塞就是同步，非阻塞就是异步，一个意思

IO层面，就不一样。要记住，IO操作只有两个阶段：

1. 数据准备阶段    
2. 内核缓冲区（内核空间）复制数据到用户进程缓冲区（用户空间）阶段

对于数据准备阶段，是阻塞和非阻塞的层面。对于数据从内核转移到用户空间，就是同步异步阶段。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203221656865.png" alt="img" style="zoom: 80%; float: left;" />

阻塞和非阻塞的区别在于内核数据还没准备好时，用户进程在一阶段数据准备时是否会阻塞；

同步IO与异步IO的区别在于当数据从内核`copy`到用户空间时，用户进程是否会阻参与第二阶段的数据读写，是由用程序完成还是由内核完成。



# 对于套接字socket的理解

这里我类比一下插座和套接字，为什么这样类比呢？因为套接字的中文有插座的含义....

电器如何才能供电？电器需要连接上电网。如何连接到电网？需要把电器插销插到插座上，通过插座连接到电网，这样电器就有电可以工作

计算机如何收发消息？计算机需要连接上互联网。如何连接互联网？硬件层面我们可以拉一根网线，软件层面需要套接字。通过套接字连接到互联网，进而可以和互利网上的所有主机进行通信。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210824151934.png" alt="img" style="zoom:67%;" />

***socket* 其实就是操作系统提供给程序员操作「网络协议栈」的接口，说人话就是，你能通过*socket* 的接口，来控制协议找工作，从而实现网络通信**



# C++网络通信中send和receive的为什么会阻塞

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203221702388.png" alt="image-20210915102717398" style="zoom:67%;float:left" />

使用tcp协议进行通讯的双方，都各自有一个发送缓冲区和一个接收缓冲区。而缓冲区是有大小的，因此发生阻塞的本质原因是缓冲区满了，别的字节流消息无法进入缓冲区。

send函数只是将内存中的数据拷贝到内核中tcp的发送缓冲区或者说写缓冲区，但是什么时候发送数据是send无法控制的。同时tcp是一个可靠传输协议，发送端必须收到确认报文信息后才会清空发送缓冲区中的内容。对于读缓冲区来，收到数据放到自己的读缓冲区，同时要给发送端发送一个确认消息表明自己收到了信息。这个时候如果读缓冲区的数据被填满，由于滑动窗口协议，导致接收端不在读取数据，进而写缓冲区也会阻止发送数据。这个时候write函数就会阻塞。总结：**接收端接收数据的速度小于发送端发送数据的速度，导致接收端的读缓冲区填满，接收端发送报文给发送端告诉他我已经满了，先别发。这样发送端的写缓冲区被占满了，导致阻塞**

receive阻塞是因为读缓冲区中没数据。

记住，send是等到写缓冲区被填满之后才发送，但是write只要发现读缓冲区有数据，就将数据拷贝。



# send和receive在阻塞和非阻塞模式下的表现

```c
//第一个参数：指定发送端套接字
//第二个参数：指明需要发送数据的缓冲区
//第三个参数：指明实际发送的数据的字节
//第四个参数：一般不写。可以临时设置为非阻塞
int send( SOCKET s, const char *buf, int len, int flags );

//第一个参数：指定接收端文件描述符
//第二个参数：指明一个缓冲区，存放接受来的数据
//第三个参数：指明缓冲区的长度
//第四个参数：一般不写。可以临时设置为非阻塞
int recv( SOCKET s, char *buf, int len, int flags);
```

- recv和send两种模式设置

  对于一个socket是阻塞还是非阻塞有两种方式来处理：

  1. 用fcntl函数

     ```c
     flags = fcntl(sockfd, F_GETFL, 0);                        //获取文件的flags值。
     fcntl(sockfd, F_SETFL, flags | O_NONBLOCK);   			 //设置成非阻塞模式；
     fcntl(sockfd,F_SETFL,flags&~O_NONBLOCK);    			//设置成阻塞模式；
     ```

  2. 将recv和send函数的最后一个flag 参数设置成`MSG_DONTWAIT`

     注意！这种方法是临时的，不管之前是否阻塞

     ```c
     recv(sockfd, buff, buff_size,MSG_DONTWAIT);     //非阻塞模式的消息发送
     send(scokfd, buff, buff_size, MSG_DONTWAIT);   //非阻塞模式的消息接受
     ```

- 整体来看

  - 当`socket`处于阻塞模式时,继续调用`send/recv`函数,程序会阻塞在`send/recv`调用处
  - 当`socket`处于非阻塞模式时,继续调用`send/recv`函数,会返回错误码

- 阻塞和非阻塞条件下read/recv的区别

  **阻塞和非阻塞的区别在于没有数据到达的时候是否立刻返回**

  读或者收的本质是从底层缓冲的数据copy到我们制定的buffer中

  - 阻塞条件下

    1. 如果读缓冲区中没有数据会一直等待

    2. 如果读缓冲区有数据，则会把数据读到用户指定的缓冲区。如果读取的数据量比函数参数中指定的长度要小，read会返回读到的数据长度。

       一般情况下我们都需要采取循环读的方式读取数据

  - 非阻塞条件下

    1. 如果没有数据直接返回EWOULDBLOCK
    2. 读缓冲区有数据，有多少读多少

- 阻塞和非阻塞条件下send/write的区别

  写或者发的本质是把buffer(用户态)中的数据copy到内核态，然后就返回了。发送操作是由系统底层和tcp协议进行。send返回成功，表示数据已经copy到底层缓冲区，而不是表示数据已经发送

  - 阻塞情况下

    一直等待，直到write将数据发送完(发送过程中可能会中断)。

    读的时候我们并不知道是否有数据，以及数据是何时结束发送，如果一直等待就会造成死循环

    对于写由于长度是已知的，所以可以随便写，直到写完。不过写会被打断，造成一次write只能写一部分，可以用循环write。

  - 非阻塞情况下

    对于本地网络阻塞的情况来说，写缓冲区没有足够的内存来存储buf中的数据，因此会出现写不成功的情况。非阻塞不会等到数据全部发送再返回，而是写多少算多少，

    返回值是WSAEWOULDDBLOCK

- [write和read返回值详解](https://blog.csdn.net/songchuwang1868/article/details/90665865?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-3.no_search_link)



# IO多路复用

IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合：

1. 当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。
2. 如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。
3. 如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。
4. 如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。

与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。

## ☆为什么单线程或者单进程下是用select或者epoll就能实现多个客户端的并发？

答： 在套接字中有两种文件描述符，一种是用于监听的文件描述符，一种是用于通信的文件描述符。（对服务器端来说用于监听的文件描述符只有1个，用于通信的文件描述符有n个对应n个连接的客户端）且不论是哪一种文件描述符，都有输入缓冲和输出缓冲。对于用于监听的文件描述符，其读缓冲区会存储来自客户端的链接请求，调用accept函数，如果读缓冲区有数据则解除阻塞，返回对应客户端的文件描述符，用来和响应客户端通信。对于通信的文件描述符，其读缓冲区存储客户端发送来的数据，调用read就能从缓冲区读取，如果没数据就阻塞。写缓冲区同理。从上面来看，accept、read、write函数是互斥的，在单进程中如果有一个陷入了阻塞状态，其余的也没办法工作。因此单线程或者单进程情况下服务器端无法阻止阻塞问题。

单进程或单线程下这个问题从使用者或者是用户层面来说无法解决，因此要把这个问题交给内核处理。程序媛不需要维护文件描述符的读缓冲区和写缓冲区，内核可以同时检测多个文 件描述符缓冲区的变化。比如检测读缓冲区，看是否有有数据，写缓冲区是否有剩余空间等等。如果满足，就会形成事件，内核会将满足条件的文件描述符告诉我们。

总结一下就是本来程序员来检测IO的使用情况，使用阻塞函数检查，交给了内核做。只有满足事件的文件描述符才调用阻塞函数，因此就不会形成阻塞。

## select

- 原理

  select函数将许多个文件描述符集中到一起进行监视。

  使用fd_set数组保存被监视的文件描述符的变化，这个数组是以位存储在内核中的。即该数组所在的索引就是对应文件描述符的id。

  首先创建一个保存监视的数组`fd_set set`，然后将所有文件描述符的状态初始化为0 `FD_ZERO(&set)`，再用`FD_ISSET(i,&set)`查找发生状态的文件描述符，循环查找。

- 存在额问题

  1. 单个进程可监视的文件描述符的数量被限制，即监听的端口有限，这个数目的限制和内存有很大关系，32位默认为1024个，对于64位机默认为2048个

  2. 对这个数组的是线性扫描，时间复杂度为O(n)

  3. 这个是最主要的开销。**每次调用select函数的时候会向操作系统传递监视对象信息。记住，应用程序向操作系统传递数据会造成很大的开销。**select函数是监视套接字变化的函数，但是套接字是由操作系统来管理的，所以select必须要借助操作系统才能完成功能。所以select函数本身就是一个系统调用。

     （另一种说法：不是拷贝进内核，而是通过mmap系统调用开辟了一坨内核态用户态的共享空间，数据放在了这个共享空间了）

> 最low的就是在用户代码中自旋实现所有阻塞socket的监听。但是每次判断socket是否产生数据，都涉及到用户态到内核态的切换。
> 于是select改进：将fd_set传入内核态，由内核判断是否有数据返回；
> 然后最low的只能使用自旋来时刻的去判断socket列表中是否有数据达到。
> 于是select改进：使用等待队列，让线程在没有资源时park（阻塞），当有数据到达时唤醒select线程，去处理socket。



## epoll

> epoll就是解耦了select的模型：
>
> <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203231333124.png" alt="img" style="zoom: 20%;float:left" />

> 设想一个场景：有100万用户同时与一个进程保持着TCP连接，而每一时刻只有几十个或几百个TCP连接是活跃的(接收TCP包)，也就是说在每一时刻进程只需要处理这100万连接中的一小部分连接。那么，如何才能高效的处理这种场景呢？进程是否在每次询问操作系统收集有事件发生的TCP连接时，把这100万个连接告诉操作系统，然后由操作系统找出其中有事件发生的几百个连接呢？实际上，在Linux2.4版本以前，那时的select或者poll事件驱动方式是这样做的.
>
> 这里有个非常明显的问题，即在某一时刻，进程收集有事件的连接时，其实这100万连接中的大部分都是没有事件发生的。因此如果每次收集事件时，都把100万连接的套接字传给操作系统(这首先是用户态内存到内核态内存的大量复制)，而由操作系统内核寻找这些连接上有没有未处理的事件，将会是巨大的资源浪费，然后select和poll就是这样做的，因此它们最多只能处理几千个并发连接。而epoll不这样做，它在Linux内核中申请了一个简易的文件系统，把原先的一个select或poll调用分成了3部分：

首先介绍一下epoll的函数，主要由三个：

```c++
int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);
```

使用epoll_creat**e向操作系统申请创建文件描述符的空间**（这个文件描述符都是在内核空间中），即建立一个epoll对象。epoll_ctl将刚创立的socket加入到epoll中进行监控，或者将某个正在监控的socket移除，不在监控。epoll_wait即监控socket有状态发生变化时候，就返回用户态的进程

> 从这三个函数就可以看到epoll函数的优越性。当调用select时需要传递所有监视的socket给系统调用，意味着需要将用户态的fd_set拷贝到内核态，可想而知效率非常低效。但是epoll中内核通过epoll_ctl函数已经拿到监视socket列表。所以，实际上在你调用epoll_create后，内核就已经在内核态开始准备帮你存储要监控的句柄了，每次调用epoll_ctl只是在往内核的数据结构里塞入新的socket句柄。
>
> 1. 调用epoll_create建立一个epoll对象(在epoll文件系统中给这个句柄分配资源)；
>
> 2. 调用epoll_ctl向epoll对象中添加这100万个连接的套接字；
>
> 3. 调用epoll_wait收集发生事件的连接。

epoll会开辟出自己的内核高速cache区，用于安置每一个我们想监控的socket，这些socket会以红黑树的形式保存在内核cache里，以支持快速的查找、插入、删除。同时还会建立一个双向链表，每个节点保存着满足读写条件，返回给用户的事件。

epoll高效的原因主要是epoll_wait这个函数。由于我们在调用epoll_create时，内核除了帮我们在epoll文件系统里建了个file结点，在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket外，还会再建立一个list链表，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait非常高效。而且，通常情况下即使我们要监控百万计的句柄，大多一次也只返回很少量的准备就绪句柄而已，所以，epoll_wait仅需要从内核态copy少量的文件描述符到用户态而已，如何能不高效？！

那么，这个准备就绪list链表是怎么维护的呢？**当我们执行epoll_ctl时，除了把socket放到epoll文件系统里对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数**，告诉内核，如果这个文件描述符的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，数据copy到内核中后就来把socket插入到准备就绪链表里了。

**总结： 一颗红黑树，一张准备就绪句柄链表，少量的内核cache，就帮我们解决了大并发下的socket处理问题。**

[详解epoll](https://mp.weixin.qq.com/s/miOOrLrC4HWXigLy9Ml-jw)

## select和epoll效率

**select原理概述：**

1. 从用户空间拷贝fd_set到内核空间；
2. 遍历所有fd，只要有事件触发，系统调用返回，将fd_set从内核空间拷贝到用户空间，回到用户态，用户就可以对相关的fd作进一步的读或者写操作了。

**epoll原理概述：**

1. 调用epoll_create

   1. 内核帮我们在epoll文件系统里建了个file结点；
   2. 在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket；
   3. 建立一个list链表，用于存储准备就绪的事件。

2. 调用epoll_ctl

   1. 把socket放到epoll文件系统里file对象对应的红黑树上；
   2. 给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。

3. 调用epoll_wait

   观察list链表里有没有数据。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。而且，通常情况下即使我们要监控百万计的句柄，大多一次也只返回很少量的准备就绪句柄而已，所以，epoll_wait仅需要从内核态copy少量的句柄到用户态而已。

**select缺点:**

1. 最大并发数限制：使用32个整数的32位，即32*32=1024来标识fd，虽然可修改，但是有以下第二点的瓶颈；
2. 效率低：每次都会线性扫描整个fd_set，集合越大速度越慢；
3. 内核/用户空间内存拷贝问题。

**epoll的提升：**

1. 本身没有最大并发连接的限制，仅受系统中进程能打开的最大文件数目限制；
2. 效率提升：只有活跃的socket才会主动的去调用callback函数；
3. 省去不必要的内存拷贝：epoll通过内核与用户空间mmap同一块内存实现。

**总结：**需要看所有被观察的事件是否都活跃。

假设现在有1024个fd，select 和epoll 都同时维护他，假设这些fd 都是活跃的，这种情况下select一次扫描 可以扫描1024个fd，空闲的fd很少，但是epoll 就有可能不一样了， epoll 是先注册等待回调， 有可能出现1024次回调。所以不好说。

如果select 和epoll 同时维护1024个fd ，但是每次只有一个fd有事件，这种情况下 select 每次都会扫描所有的fd， 对比于epoll 每次只有一个fd 回调。 select 做了很多无用功， 此时应该epoll的效率高吧！！

或者在短连接多的时候， 一个连接使用epoll 会触发epoll_ctrl_add/del 两次系统调用，但是select 只有一次扫描 ，此时 也许select 效率性能更高。

## epoll的水平触发模式（LT）

默认模式

在LT（水平触发）模式下，只要这个文件描述符还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作。

## epoll的边缘触发模式（ET）

ET（边缘触发）模式下，在它检测到有 I/O 事件时，通过 epoll_wait 调用会得到有事件通知的文件描述符，**对于每一个被通知的文件描述符，如可读，则必须将该文件描述符一直读到空**，让 errno 返回 EAGAIN 为止，否则下次的 epoll_wait 不会返回余下的数据，会丢掉事件。如果ET模式不是非阻塞的，那这个一直读或一直写势必会在最后一次阻塞。

为什么会有ET模式？

答：如果采用EPOLLLT模式的话，系统中一旦有大量你不需要读写的就绪文件描述符，它们每次调用epoll_wait都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率.。而采用EPOLLET这种边缘触发模式的话，当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你！！！这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。减少epoll_wait的调用次数，系统调用开销是很大的



# tcp 在调用connect失败后要不要重新socket？

connect（套接字默认阻塞）出错返回的情况：

1. 调用connect时内核发送一个SYN分节，若无响应则等待6s后再次发送一个，仍无响应则等待24s再发送一个，若总共等了75s后仍未收到响应则返回ETIMEDOUT错误；

2. 若对客户的SYN的响应是RST，则表示该服务器主机在我们指定的端口上面没有进程在等待与之连接，例如服务器进程没运行，客户收到RST就马上返回ECONNREFUSED错误；

3. 若客户发出的SYN在中间的某个路由上引发了一个“destination unreachable”（目的不可达）ICMP错误，客户主机内核保存该消息，并按1中所述的时间间隔发送SYN，在某个规定的时间（4.4BSD规定75s）仍未收到响应，则把保存的ICMP错误作为EHOSTUNREACH或ENETUNREACH错误返回给进程。

若connect失败则该套接字不再可用，必须关闭，我们不能对这样的套接字再次调用connect函数。在每次connect失败后，都必须close当前套接字描述符并重新调用socket。



# Linux零拷贝技术

splice( )函数

tee( )函数

## **概述：**

零拷贝（Zero-Copy）是一种 `I/O` 操作优化技术，可以快速高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间。其在 `FTP` 或者 `HTTP` 等协议中可以显著地提升性能。

## **由来：**

如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间的复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。其过程如下图所示：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203231452388.webp" alt="img" style="zoom: 50%;Float:left" />

可以想想一下这个过程。服务器读从磁盘读取文件的时候，发生一次系统调用，产生用户态到内核态的转换，将磁盘文件拷贝到内核的内存中。然后将位于内核内存中的文件数据拷贝到用户的缓冲区中。用户应用缓冲区需要将这些数据发送到socket缓冲区中，进行一次用户态到内核态的转换，复制这些数据。此时这些数据在内核的socket的缓冲区中，在进行一次拷贝放到网卡上发送出去。

所以整个过程一共进行了四次拷贝，四次内核和用户态的切换。这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。

## 零拷贝原理

零拷贝主要是用来解决操作系统在处理 I/O 操作时，频繁复制数据的问题。关于零拷贝主要技术有 `mmap+write`、`sendfile`和`splice`等几种方式。

看完下图会发现其实零拷贝就是少了CPU拷贝这一步，磁盘拷贝还是要有的

- mmap/write 方式

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203231457223.webp" alt="image" style="zoom:80%;float:left" />

  把数据读取到内核缓冲区后，应用程序进行写入操作时，直接把内核的`Read Buffer`的数据复制到`Socket Buffer`以便写入，这次内核之间的复制也是需要CPU的参与的。

- sendfile 方式

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203231500195.webp" alt="image" style="zoom:80%;float:left" />

  可以看到使用sendfile后，没有用户空间的参与，一切操作都在内核中进行。但是还是需要1次拷贝

- 带有 scatter/gather 的 sendfile方式

  Linux 2.4 内核进行了优化，提供了带有 `scatter/gather` 的 sendfile 操作，这个操作可以把最后一次 `CPU COPY` 去除。其原理就是在内核空间 Read BUffer 和 Socket Buffer 不做数据复制，而是将 Read Buffer 的内存地址、偏移量记录到相应的 Socket Buffer 中，这样就不需要复制。其本质和虚拟内存的解决方法思路一致，就是内存地址的记录。

  **注意： sendfile适用于文件数据到网卡的传输过程，并且用户程序对数据没有修改的场景；**

- splice 方式

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203231510067.png" style="zoom:80%; float:left" />

  其实就是CPU 在内核空间的读缓冲区（read buffer）和网络缓冲区（socket buffer）之间建立管道（pipeline）直接把数据传过去了，不去要CPU复制了





# accept()、connect()发生在三次握手的哪一步？

<img src="C:\Users\ACER\AppData\Roaming\Typora\typora-user-images\image-20220228223118192.png" alt="image" style="zoom: 50%; float: left;" />

看上图就很明白了，刚准备发SYN同步报文时候，connect函数阻塞，然后服务端收到SYN同步报文的时候，调用accept()阻塞，服务器发送SYN+ACK给客户端，此时connect连接上就返回了，然后等服务器收到ACK报文时，accept也返回。

所以只说返回状态的话connect成功返回是在第二步，accept成功返回是在第三步



# accept的队列

处于“LISTENING”状态的TCP socket，有两个独立的队列：

1. SYN队列(SYN Queue)
2. Accept队列(Accept Queue)

**SYN队列**

SYN队列存储了收到SYN包的连接(对应内核代码的结构体： struct inet_request_sock)。它的职责是回复SYN+ACK包，并且在没有收到ACK包时重传，直到超时。发送完SYN+ACK之后，SYN队列等待从客户端发出的ACK包(也即三次握手的最后一个包)。当收到ACK包时，首先找到对应的SYN队列，再在对应的SYN队列中检查相关的数据看是否匹配，如果匹配，内核将该连接相关的数据从SYN队列中移除

**accept队列**

内核将该连接相关的数据从SYN队列中移除，创建一个完整的连接(对应内核代码的结构体： struct inet_sock )，并将这个连接加入Accept队列。Accept队列中存放的是已建立好的连接，也即等待被上层应用程序取走的连接。当进程调用accept()，这个socket从队列中取出，传递给上层应用程序。一般来说都是select或者epoll上有事件发生时再取走



# 调用close()在哪一步？

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202202282238507.png" alt="image" style="float: left; zoom: 50%;" />

首先注意EOF这个东西。当客户端调用close主动断开时，会在FIN报文后面放入一个文件结束符EOF，会放在服务器端读缓存队列的最后，当接收到EOF时，服务器需要处理这种异常情况，表示以后不会有任何数据到达。因此服务器会返回一个ACK确认报文然后进入closed_wait状态

等服务器处理完后，发送FIN报文后也调用close。



# Posix 信号量与System v信号量的区别

[参考](https://blog.csdn.net/weixin_41413441/article/details/81239859) 

[参考](https://bbs.huaweicloud.com/blogs/detail/232525)

[参考](https://www.cnblogs.com/sparkdev/p/8692567.html)

Posix:是“可移植操作系统接口（Portable Operating System Interface ）的首字母简写，但它并不是一个单一的标准，而是一个电气与电子工程学会即IEEE开发的一系列标准，它还是由ISO（国际标准化组织）和IEC（国际电工委员会）采纳的国际标准。

System v是Unix操作系统众多版本的一个分支，它最初是由AT&T在1983年第一次发布，System v一共有四个版本，而最成功的是System V Release 4，或者称为SVR4。这样看来，一个是Unix 的标准之一（另一个标准是Open Group），一个是Unix众多版本的分支之一（其他的分支还有Linux跟BSD），应该来说，Posix标准正变得越来越流行，很多厂家开始采用这一标准。

区别如下：

1. System v信号量指的是计数信号量集；Posix 信号量指的是单个计数信号量。
2. Posix信号量是基于内存的，即信号量值是放在共享内存中的，它是由可能与文件系统中的路径名对应的名字来标识的。System v信号量测试基于内核的，它放在内核里面，相同点都是它们都可以用于进程或者线程间的同步。
3. POSIX信号量常用于线程；system v信号量常用于进程的同步。
4. POSIX 信号量的头文件是 <semaphore.h>，而 System V 信号量的头文件是 <sys/sem.h>。



# 信号通知流程和处理机制

Linux下的信号采用的异步处理机制，信号处理函数和当前进程是两条不同的执行路线。具体的，当进程收到信号时，操作系统会中断进程当前的正常流程，转而进入信号处理函数执行操作，完成后再返回中断的地方继续执行。为避免信号竞态现象发生，信号处理期间系统不会再次触发它。所以，为确保该信号不被屏蔽太久，信号处理函数需要尽可能快地执行完毕。

一般的信号处理函数需要处理该信号对应的逻辑，当该逻辑比较复杂时，信号处理函数执行时间过长，会导致信号屏蔽太久。提供一种解决方案是，信号处理函数仅仅发送信号通知程序主循环，将信号对应的处理逻辑放在程序主循环中，由主循环执行信号对应的逻辑代码。

> **统一事件源**
>
> 统一事件源，是指将信号事件与其他事件一样被处理。
>
> 具体的，信号处理函数使用管道将信号传递给主循环，信号处理函数往管道的写端写入信号值，主循环则从管道的读端读出信号值，使用I/O复用系统调用来监听管道读端的可读事件，这样信号事件与其他文件描述符都可以通过epoll来监测，从而实现统一处理。

信号处理机制如下图：

![图片](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203051517351.jpeg)

- 信号的接收

  - 接收信号的任务是由内核代理的，当内核接收到信号后，会将其放到对应进程的信号队列中，同时向进程发送一个中断，使其陷入内核态。注意，此时信号还只是在队列中，对进程来说暂时是不知道有信号到来的。

- 信号的检测

  - 进程从内核态返回到用户态前进行信号检测

  - 进程在内核态中，从睡眠状态被唤醒的时候进行信号检测
  - 进程陷入内核态后，有两种场景会对信号进行检测：
  - 当发现有新信号时，便会进入下一步，信号的处理。

- 信号的处理

  - ( **内核** )信号处理函数是运行在用户态的，调用处理函数前，内核会将当前内核栈的内容备份拷贝到用户栈上，并且修改指令寄存器（eip）将其指向信号处理函数。

  - ( **用户** )接下来进程返回到用户态中，执行相应的信号处理函数。
  - ( **内核** )信号处理函数执行完成后，还需要返回内核态，检查是否还有其它信号未处理。
  - ( **用户** )如果所有信号都处理完成，就会将内核栈恢复（从用户栈的备份拷贝回来），同时恢复指令寄存器（eip）将其指向中断前的运行位置，最后回到用户态继续执行进程。

- 至此，一个完整的信号处理流程便结束了，如果同时有多个信号到达，上面的处理流程会在第2步和第3步骤间重复进行。



# 服务器端有100万个TCP长连接，可能会出现的问题

[参考1](https://www.zhihu.com/question/20831000)

[参考2](http://www.blogjava.net/yongboy/archive/2013/04/11/397677.html)



# epoll是同步还是异步的？

1. 
   IO层面
2. 消息处理层面
3. 从IO层面来看,epoll绝对是同步的；
4. 从消息处理层面来看，epoll是异步的.

select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的（可能通过while循环来检测内核将数据准备的怎么样了， 而不是属于内核的一种通知用户态机制），仍然需要read、write去读写数据。

用户线程定期轮询epoll文件描述符上的事件，事件发生后，读取事件对应的epoll_data，该结构中包含了文件fd和数据地址，由于采用了mmap，程序可以直接读取数据（epoll_wait函数）。有人把epoll这种方式叫做同步非阻塞（NIO），因为用户线程需要不停地轮询，自己读取数据，看上去好像只有一个线程在做事情。也有人把这种方式叫做异步非阻塞（AIO），因为毕竟是内核线程负责扫描fd列表，并填充事件链表的。个人认为真正理想的异步非阻塞，应该是内核线程填充事件链表后，主动通知用户线程，或者调用应用程序事先注册的回调函数来处理数据，如果还需要用户线程不停的轮询来获取事件信息，就不是太完美了，所以也有不少人认为epoll是伪AIO，还是有道理的。

# 原子操作的原理

原子操作（atomic operation）意为”不可被中断的一个或一系列操作”



# signal机制



# 使用epoll或select时需要将socket设为非阻塞吗？

**先说结论：**

需要的。但是一个 socket 是否设置为阻塞模式，只会影响到 connect/accept/send/recv 等四个 socket API 函数，不会影响到 select/poll/epoll_wait 函数，后三个函数的超时或者阻塞时间是由其函数自身参数控制的。

 **socket 是否被设置成阻塞模式对下列 API 造成的影响：**

connfd：该端调用 connect 函数主动发起连接；

listenfd：调用 listen 函数发起侦听的一端（服务端）；即监听的socket

clientfd：调用 accept 函数接受连接，由 accept 函数返回的 socket（服务端）。即连接的socket

当connfd 被设置成阻塞模式时（默认行为，无需设置），connect 函数会一直阻塞到连接成功或超时或出错，超时值需要修改内核参数。当 connfd 被设置成非阻塞模式，无论连接是否建立成功，connect 函数都会立刻返回，那如何判断 connect 函数是否连接成功呢？接下来使用 select 和 epoll_wait 函数去判断 socket 是否可写即可，当然，Linux 系统上还需要额外加一步——使用 getsockopt 函数判断此时 socket 是否有错误(因为select中通知有数据达到但是可能数据error checksum或者discard了)，这就是所谓的异步 connect 或者叫非阻塞 connect。

当 listenfd 设置成阻塞模式（默认行为，无需额外设置）时，如果连接 pending(待办) 队列中有需要处理的连接，accept 函数会立即返回，否则会一直阻塞下去，直到有新的连接到来。当 listenfd 设置成非阻塞模式，无论连接 pending 队列中是否有需要处理的连接，accept 都会立即返回，不会阻塞。如果有连接，则 accept 返回一个大于 0 的值，这个返回值即是我们上文所说的 clientfd；如果没有连接，accept 返回值小于 0，错误码 errno 为 EWOULDBLOCK（或者是 EAGAIN，这两个错误码值相等）。

当 connfd 或 clientfd 设置成阻塞模式时：send 函数会尝试发送数据，如果对端因为 TCP 窗口太小导致本端无法将数据发送出去，send 函数会一直阻塞直到对端 TCP 窗口变大足以发数据或者超时；recv 函数则正好相反，如果此时没有数据可收获，recv函数会一直阻塞直到收取到数据或者超时，有的话，取到数据后返回。send 和 recv 函数的超时时间可以分别使用 SO_SNDTIMEO 和 SO_RCVTIMEO 两个 socket 选项来设置。当 connfd 或 clientfd 设置成非阻塞模式时，send 和 recv 函数都会立即返回，send 函数即使因为对端 TCP 窗口太小发不出去也会立即返回，recv 函数如果无数据可收也会立即返回，此时这两个函数的返回值都是 -1，错误码 errno 是 EWOULDBLOCK（或 EAGIN，与上面同）。

**select/poll/epoll_wait 函数的等待或超时时间**

select、poll、epoll_wait 函数的超时时间分别由传给各自函数的时间参数决定的，我们来看下这三个函数的签名：

```c
int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
int poll(struct pollfd *fds, nfds_t nfds, int timeout);
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
```

三个函数最后一个参数是 timeout，只不过 select 函数的 timeout 参数的类型是一个结构体指针

select 函数的 timeout 参数含义有三种：

1.  timeout 为 NULL 时，select 函数将一直阻塞下去，直到出错或者绑定其上的 socket 有事件；
2. 当 timeout->tv_sec 和 timeout->tv_usec 同时为 0 时，select 函数会检查一下绑定在其上的 socket 是否有事件，然后立刻返回；
3. 当 timeout->tv_sec 和 timeout->tv_usec 之和大于 0 时，select 函数检测到绑定其上的 socket 有时间才会返回或者阻塞时长为 timeout->tv_sec + timeout->tv_usec 。

poll 和 epoll_wait 函数的超时时间为毫秒，设置为 0，和 select 函数一样，检测一下绑定其上的 socket 是否有事件，然后立即返回。

**为什么使用epoll时候需要将socket设置成阻塞的？**

首先epoll 模型通常用于服务端，那讨论的 socket 只有 listenfd 和 clientfd 了。

对于listenfd，可以阻塞可以非阻塞。有很多的服务器程序结构确实采用的就是阻塞的 listenfd，为了不让 accept 函数在没有连接时阻塞对程序其他逻辑执行流造成影响，我们通常将 accept 函数放在一个独立的线程中。但是如果不在一个独立线程中获得listenfd的话，如果默认一个监听socket是阻塞的话，有如下场景：客户端通过connect向服务器发起三次握手，三次握手后触发select或者epoll上的事件，但是呢此时客户端发送过来RST报文取消了连接，而此时服务器端调用了accept接收了次连接区去内核队列中取时内核队列中是空的（因为该客户端连接被取消），那么服务器就会阻塞在accept调用，无法响应其他就绪的监听socket，所以我们要吧监听socket即listenfd也设置为阻塞的。

对于clientfd，主要涉及到的是读写的问题。当读取的数据很小，比如有个buffer是1024字节，读取的数据小于1024的话，水平边缘触发搭配阻塞和非阻塞其实都一样。那么很多时候我们接受的数据都很大，一个buffer装不下，就需要while循环多次读。那么这种情况水平触发模式显得很鸡肋，阻塞和非阻塞效果都一样。所以我们主要讨论的是边缘触发情况下clientfd的阻塞和非阻塞。首先是ET+阻塞的情况，当最后一个数据读取完后，程序是无法立刻跳出while循环的，因为阻塞IO会在 while(true){ int len=recv(); }这里阻塞住，除非对方关闭连接或者recv出错，这样程序就无法继续往下执行，因为我就绪的文件描述符都在等着处理，这一次的epoll_wait没有办法处理其它的连接，会造成延迟、并发度下降。其次的话select或者epoll返回可读，和recv去读，这是两个独立的系统调用，两个操作之间是有窗口的，也就是说 select 返回可读，紧接着去 read，不能保证一定可读。man select中说了数据到达了但是可能error checksum或者discard了，如果你用阻塞的，就阻塞了进行不下去，这显然不行。如果是ET+非阻塞IO的话，当读取完数据后，recv会立即返回-1，并将errno设置为EAGAIN或EWOULDBLOCK,这就表示数据已经读取完成，已经没有数据了，可以退出循环了。这样就不会像阻塞IO一样卡在那里，这就减少了不必要的等待时间，性能自然更高。





# 用过哪些linux命令？

## top

top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。

常用命令如下：

1. P：按%CPU使用率排行
2. M：按%MEM排行
3. T： 根据时间/累计时间进行排序。 

## scp

用于不同linux主机之间复制文件的

```shell
scp  local_file    remote_username@remote_ip:remote_file 
```

## find

找文件名

```shell
find . -name '[A-Z]*.txt' -print 
```

## sar

`sar`（System Activity Reporter 系统活动情况报告）是目前 Linux 上最为全面的系统性能分析工具之一，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘 I/O、CPU 效率、内存使用状况、进程活动及 IPC 有关的活动等。我们可以使用`sar`命令来获得整个系统性能的报告。这有助于我们定位系统性能的瓶颈，并且有助于我们找出这些烦人的性能问题的解决方法。

[参考](https://shockerli.net/post/linux-tool-sar/)

## tar

## df

用来检查linux服务器的文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。

## free

显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。在Linux系统监控的工具中，free命令是最经常使用的命令之一。

total:总计物理内存的大小。

used:已使用多大。

free:可用有多少。

## netstat

Netstat 命令用于显示各种网络相关信息，如网络连接，路由表，实际的网络连接以及每一个网络接口设备的状态信息。Netstat用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。

- 直接使用netstat

  输出结果可以分为两个部分：一个是Active Internet connections，称为有源TCP连接，其中"Recv-Q"和"Send-Q"指%0A的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。
  Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。

- 列出所有端口 #netstat -a

- 列出所有 tcp 端口 #netstat -at

- 列出所有 udp 端口 #netstat -au

## traceroute

追踪网络数据包的路由途径，预设数据包大小是40Bytes。

## route

跟路由表相关的命令

可以查看（route），增加（route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0），删除（route del -net 224.0.0.0 netmask 240.0.0.0）

## ip

linux的ip命令和ifconfig类似，但前者功能更强大，并旨在取代后者。使用ip命令，只需一个命令，你就能很轻松地执行一些网络管理任务。ifconfig是net-tools中已被废弃使用的一个命令，许多年前就已经没有维护了。iproute2套件里提供了许多增强功能的命令，ip命令即是其中之一。



# Linux惊群效应详解

[参考链接](https://mp.weixin.qq.com/s?__biz=MzU1ODEzNjI2NA==&mid=2247487207&idx=1&sn=08d1a44dcfe978bd97e6735e8e044d06&source=41#wechat_redirect)

**定义：**惊群效应（thundering herd）是指多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），如果等待的这个事件发生，那么他就会唤醒等待的所有进程（或者线程），但是最终却只能有一个进程（线程）获得这个时间的“控制权”，对该事件进行处理，而其他进程（线程）获取“控制权”失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群效应。

**危害：**

1. Linux 内核对用户进程（线程）频繁地做无效的调度、上下文切换等使系统性能大打折扣。上下文切换（context switch）过高会导致 cpu 像个搬运工，频繁地在寄存器和运行队列之间奔波，更多的时间花在了进程（线程）切换，而不是在真正工作的进程（线程）上面。直接的消耗包括 cpu 寄存器要保存和加载（例如程序计数器）、系统调度器的代码需要执行。间接的消耗在于多核 cache 之间的共享数据。
2. 为了确保只有一个进程（线程）得到资源，需要对资源操作进行加锁保护，加大了系统的开销。目前一些常见的服务器软件有的是通过锁机制解决的，比如 Nginx（它的锁机制是默认开启的，可以关闭）；还有些认为惊群对系统性能影响不大，没有去处理，比如 lighttpd

**Linux 解决方案之 Accept**

Linux 2.6 版本之前，监听同一个 socket 的进程会挂在同一个等待队列上，当请求到来时，会唤醒所有等待的进程。Linux 2.6 版本之后，通过引入一个标记位 WQ_FLAG_EXCLUSIVE，解决掉了 Accept 惊群效应。



# pthread_cond_wait 为什么需要传递 mutex 参数？

本质上这个问题想问这个锁是用来保护什么的？其实这个互斥锁不是用来保护条件变量的内部状态的，而是用来保护外部条件的，就是那个while()循环中的判断。

游双书里面说"pthread_cond_wait函数用于等待目标条件变量，mutex是保护条件变量的互斥锁，以确保pthread_cond_wait的原子性。"在看完这个回答你就该知道，**pthread_cond_wait的原子性指的是while条件判断成立和这个线程调用wait函数进入唤醒队列的原子性。**

- 错误写法

  ```c
  //threadA
  pthread_mutex_lock(&mutex);
  while (false == ready) {
     pthread_cond_wait(&cond, &mutex);
  }
  pthread_mutex_unlock(&mutex);
  
  //threadB
  ready = true;
  pthread_cond_signal(&cond);
  ```

  这个写法为什么有错误？如图：

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203181035470.jpeg" alt="img" style="zoom:80%;float:left" />

  ThreadA进入while循环后，准备进入唤醒队列，此时ThreadB进来横插一脚，把`ready`改成`true`然后提前唤醒，这个时候线程A还没有进入唤醒队列，因此A会丢失唤醒条件进而永久wait

- 正确写法

  ```c
  //Thread A
  pthread_mutex_lock(&mutex);
  while (false == ready) {
      pthread_cond_wait(&cond, &mutex);
  }
  pthread_mutex_unlock(&mutex);
  
  //Thread B
  pthread_mutex_lock(&mutex);
  ready = true;
  pthread_mutex_unlock(&mutex);
  pthread_cond_signal(&cond);
  ```


[参考链接](https://zhuanlan.zhihu.com/p/55123862)



# 什么是虚假唤醒？

一般来说我们要在等待wait的时候用while循环。因为会产生虚假唤醒。

pthread 的条件变量等待 `pthread_cond_wait` 是使用阻塞的系统调用实现的（比如 Linux 上的 `futex`），这些阻塞的系统调用在进程被信号中断后，通常会中止阻塞、直接返回 EINTR 错误。同样是阻塞系统调用，你从 `read` 拿到 EINTR 错误后可以直接决定重试，因为这通常不影响它本身的语义。而条件变量等待则不能，因为本线程拿到 EINTR 错误和重新调用 `futex` 等待之间，可能别的线程已经通过 `pthread_cond_signal` 或者 `pthread_cond_broadcast`发过通知了。所以，虚假唤醒的一个可能性是条件变量的等待被信号中断。

在多核处理器下，pthread_cond_signal可能会激活多于一个线程（阻塞在条件变量上的线程）。结果是，当一个线程调用pthread_cond_signal()后，因为多个线程都被唤醒了，很可能其中一个唤醒的线程，先一步改变的condition. 此时另一个线程的condition已经不满足，因此需要加Where再次判断。这种效应成为”**虚假唤醒**”(spurious wakeup)。所以我们把判断条件从if改成while，pthread_cond_wait中的while()不仅仅在等待条件变量**前**检查条件变量，实际上在等待条件变量**后**也检查条件变量。



# 套接字文件描述符和端口号的关系

个socket句柄代表两个地址对 “本地ip:port”--“远程ip:port”

在windows下叫句柄，在linux下叫文件描述符

socket为内核对象，由操作系统内核来维护其缓冲区，引用计数，并且可以在多个进程中使用。



# 进程线程协程

[参考链接](https://www.cnblogs.com/Survivalist/p/11527949.html#%E5%8D%8F%E7%A8%8B)



# linux栈大小

用命令ulimit -s查看

8M左右



# 服务器集群





# Linux进程、进程组、会话、僵尸

> 研究 Linux 之前，首先要对进程、进程组、会话，线程有个整体的了解：一个会话包含多个进程组，一个进程组包含多个进程，一个进程包含多个线程。

**进程：**

进程是 Linux 操作系统环境的基础，它控制着系统上几乎所有的活动。每个进程都有自己唯一的标识：进程 ID，也有自己的生命周期。进程都有父进程，父进程也有父进程，从而形成了一个以 init 进程 （PID = 1）为根的家族树。除此以外，进程还有其他层次关系：进程组和会话。

有几种比较特殊的进程：

1. 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被 init 进程(进程号为1)所收养，并由 init 进程对它们完成状态收集工作。
2. 僵尸进程：一个进程使用 fork 创建子进程，如果子进程先退出，而父进程并没有调用 wait 或 waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。
3. 守护进程：（英语：daemon）是一种在后台执行的程序。此类程序会被以**进程**的形式初始化。**守护进程**程序的名称通常以字母“d”结尾：例如，syslogd 就是指管理系统日志的守护进程。

**进程ID：**

Linux每个进程都会有一个非负整数表示的唯一进程 ID，简称 pid。Linux 提供了getpid 函数来获取进程的 pid，同时还提供了 getppid 函数来获取父进程的 pid。

**进程组：**

进程组的概念并不难理解，可以将人与人之间的关系做类比。一起工作的同事，自然比毫不相干的路人更加亲近。shell 中协同工作的进程属于同一个进程组，就如同协同工作的人属于同一个部门一样。引入了进程组的概念，可以更方便地管理这一组进程了。比如这项工作放弃了，不必向每个进程一一发送信号，可以直接将信号发送给进程组，进程组内的所有进程都会收到该信号。

**会话(session)：**

一般是指 shell session。Shell session 是终端中当前的状态，在终端中只能有一个 session。当我们打开一个新的终端时，总会创建一个新的 shell session。

就进程间的关系来说，session 由一个或多个进程组组成。我们可以通过下图来理解进程、进程组和 session 之间的关系：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/952033-20200103182042686-2100862807.png" alt="img" style="float: left;" />





# 守护进程

**概念：**

守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。守护进程是一种很有用的进程。 Linux的大多数服务器就是用守护进程实现的。比如，Internet服务器inetd，Web服务器httpd等。同时，守护进程完成许多系统任务。 比如，作业规划进程crond，打印进程lpd等。守护进程的编程本身并不复杂，复杂的是各种版本的Unix的实现机制不尽相同，造成不同 Unix环境下守护进程的编程规则并不一致。

当我们在命令行提示符后输入类似./helloworld程序时，在程序运行时终端被占用，此时无法执行其它操作。即使使用./helloworld &方式后台运行，当连接终端的网络出现问题，那么也会导致运行程序中断。这些因素对于长期运行的服务来说很不友好，而「守护进程」可以很好的解决这个问题。

**特性：**

守护进程最重要的特性是后台运行。其次，守护进程必须与其运行前的环境隔离开来。这些环境包括未关闭的文件描述符，控制终端，会话和进程组，工作目录以及文件创建掩模等。这些环境通常是守护进程从执行它的父进程（特别是shell）中继承下来的。最后，守护进程的启动方式有其特殊之处。它可以在Linux系统启动时从启动脚本/etc/rc.d中启动，可以由作业规划进程crond启动，还可以由用户终端（通常是 shell）执行。总之，除开这些特殊性以外，守护进程与普通进程基本上没有什么区别。因此，编写守护进程实际上是把一个普通进程按照上述的守护进程的特性改造成为守护进程。如果对进程有比较深入的认识就更容易理解和编程了。

**编程：**

setsid()函数主要是重新创建一个session,子进程从父进程继承了SessionID、进程组ID和打开的终端,子进程如果要脱离父进程，不受父进程控制，我们可以用这个setsid命令。想脱离父进程，自己自由自在的活着，就要用这个命令执行后面的操作，简单粗暴。

编写守护进程过程如下：

1. 创建子进程，父进程退出

   进程 fork 后，父进程退出。这么做的原因有 2 点：

   - 如果守护进程是通过 Shell 启动，父进程退出，Shell 就会认为任务执行完毕，这时子进程由 init 收养
   - 子进程继承父进程的进程组 ID，保证了子进程不是进程组组长，因为后边调用setsid()要求必须不是进程组长
2. 子进程创建新会话

​		调用setsid()创建一个新的会话，并成为新会话组长。这个步骤主要是要与继承父进程的会话、进程组、终端脱离关系。fork()的目的是想成功调用setsid()来建		立新会话，子进程有单独的sid，并且成为新进程组的组长，不关联任何终端。

3. 禁止子进程重新打开终端

   此刻子进程是会话组长，为了防止子进程重新打开终端，再次 fork 后退出父进程，也就是此子进程。这时子进程 2 不再是会话组长，无法再打开终端。其实这一步骤不是必须的，不过加上这一步骤会显得更加严谨。

4. 设置当前目录为根目录

   如果守护进程的当前工作目录是/usr/home目录，那么管理员在卸载/usr分区时会报错的。为了避免这个问题，可以调用chdir()函数将工作目录设置为根目录/。

5. 设置文件权限掩码

   文件权限掩码是指屏蔽掉文件权限中的对应位。由于使用 fork()函数新建的子进程继承了父进程的文件权限掩码，这就给该子进程使用文件带来了诸多的麻烦。因此，把文件权限掩码设置为 0，可以大大增强该守护进程的灵活性。通常使用方法是umask(0)。

6. 关闭文件描述符

   子进程会继承已经打开的文件，它们占用系统资源，且可能导致所在文件系统无法卸载。此时守护进程与终端脱离，常说的输入、输出、错误描述符也应该关闭。


```c++
pid_t pid, sid;
int i;
pid = fork(); // 第1步
if (pid < 0) 
    exit(-1);
else if (pid > 0) 
    exit(0);  // 父进程第一次退出

if ((sid = setsid()) < 0)  // 第2步
{
    syslog(LOG_ERR, "%s\n", "setsid");
    exit(-1);
}

// 第3步 第二次父进程退出
if ((pid = fork()) > 0) 
    exit(0);
if ((sid = chdir("/")) < 0) // 第4步
{
    syslog(LOG_ERR, "%s\n", "chdir");
    exit(-1);
}

umask(0); // 第5步

// 第6步：关闭继承的文件描述符
for(i = 0; i < getdtablesize(); i++)
{
    close(i);
}
while(1)
{
    do_something();
}
closelog();
exit(0);
```



# 系统调用的详细过程

**系统调用：**系统调用是操作系统为用户提供的一系列API；系统调用将用户的请求发给内核，内核执行完以后，将结果返回给用户；

[参考](https://blog.csdn.net/Agoni_xiao/article/details/79034290)



# 进程和线程的区别和联系

**概念上**

最开始就是一个进程跑完再跑另一个进程，后来有多道程序分派之后，我们可以利用进程调度算法来在一个电脑上跑多个程序，在我们用户看来这些程序是一起运行的。随着技术的发展，多核处理器的实现使得线程越来越普及，因此我们计算机就可以适配多核出现了线程。

**进程：**进程是系统中正在运行的程序。是计算机分配资源的单位，每一个进程都会有属于自己独立的内存空间，磁盘空间，I\O设备等等。比如说windows中的任务管理器，每一行都是一个进程。在同一进程中还是在不同进程中时系统功能划分的重要决策点。

> 可以把进程比做一个人。每个人都有自己的记忆（内存），人与人通过谈话（消息传递）来交流，谈话既可以面谈（同一个电脑），也可以远程谈（不同服务器，网络通信）。面谈和远程的区别在于，面谈的话可以立刻知道对方死没死（SIGCHILD信号），而远程只能通过周期性的信条来判断对方是否活着。

**线程：**线程是任务调度的基本单元。（现在来看这局话其实就是正在运行的一个程序有很多任务，而线程是将任务呈现出细粒度，更精确了）其实我觉得线程主要扮演的角色就是如何利用cpu处理代码，完成当前进程中的各个子任务。各个子线程之间共享父进程的代码空间和全局变量，但是每个进程都有自己独立的堆栈，即局部变量对于线程来说是私有的。因此创建多进程代价有点大，在一个进程中创建多线程代价要小很多。

线程大概93年出现的，有SUN Solaris操作系统使用的线程叫做**UNIX International线程**，现在一直用的POSIX线程（POSIX threads），Pthreads线程的头文件是`<pthread.h>`，Win32线程是Windows API的一部分。

线程的特点就是共享地址空间，从而可以高效的共享数据。多线程的价值在于更好的发挥了多核处理器的效能，在单核时代多线程没啥用，因为就一个核心，一个执行单元，按状态机的思路去写程序是最高效的。 

**内核实现上**

进程和线程的相同点要远远大于不同点。主要依据就是在 Linux 中，无论进程还是线程，都是抽象成了 task 任务，在源码里都是用 task_struct 结构来实现的。

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/202210121007426.png" alt="图片" style="zoom:67%;float:left" />

对于线程来讲，所有的字段都是和进程一样的（本来就是一个结构体来表示的）。包括状态、pid、task 树关系、地址空间、文件系统信息、打开的文件信息等等字段，线程也都有。在 Linux 下的线程还有另外一个名字，叫轻量级进程。

**进程中**pid 就是我们平时常说的进程 pid，在 Linux 中，每一个 task_struct 都需要被唯一的标识，它的 pid 就是唯一标识号。

**对于线程来说**，我们假如一个进程下创建了多个线程出来。那么每个线程的 pid 都是不同的。但是我们一般又需要记录线程是属于哪个进程的。这时候，tgid 就派上用场了，通过 tgid 字段来表示自己所归属的进程 ID。

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/202210121011428.png" alt="图片" style="zoom:80%;float:left" />

事实上，进程线程创建的时候，使用的函数看起来不一样。但实际在底层实现上，最终都是使用同一个函数来实现的。

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/202210121013610.png" alt="图片" style="zoom:67%;float:left" />

创建进程时使用的 fork 系统调用，创建线程的 clone 系统调用几乎和 fork 差不多，也一样使用的是内核里的 do_fork 函数，最后走到 copy_process 来完整创建。不过创建过程的区别是二者在调用 do_fork 时传入的 clone_flags 里的标记不一样！。

- 创建进程时的 flag：仅有一个 SIGCHLD
- 创建线程时的 flag：包括 CLONE_VM、CLONE_FS、CLONE_FILES、CLONE_SIGNAL、CLONE_SETTLS、CLONE_PARENT_SETTID、CLONE_CHILD_CLEARTID、CLONE_SYSVSEM。

> - CLONE_VM: 新 task 和父进程共享地址空间
> - CLONE_FS：新 task 和父进程共享文件系统信息
> - CLONE_FILES：新 task 和父进程共享文件描述符表

进程和线程创建都是调用内核中的 do_fork 函数来执行的。在 do_fork 的实现中，核心是一个 copy_process 函数，它以拷贝父进程（线程）的方式来生成一个新的 task_struct 出来。copy_process 先是复制了一个新的 task_struct 出来，然后调用 copy_xxx 系列的函数对 task_struct 中的各种核心对象进行拷贝处理，还申请了 pid 。

对于线程来讲，其地址空间 mm_struct、目录信息 fs_struct、打开文件列表 files_struct 都是和创建它的任务共享的。如图：

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/202210121018707.png" alt="图片" style="zoom: 67%;float:left" />

对于进程来讲，地址空间 mm_struct、挂载点 fs_struct、打开文件列表 files_struct 都要是独立拥有的，都需要去申请内存并初始化它们。如图：

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/202210121018755.png" alt="图片" style="zoom:67%;float:left" />

在 Linux 内核中并没有对线程做特殊处理，还是由 task_struct 来管理。从内核的角度看，用户态的线程本质上还是一个进程。只不过和普通进程比，稍微“轻量”了那么一些。那么线程具体能轻量多少呢？我之前曾经做过一个进程和线程的上下文切换开销测试。进程的测试结果是一次上下文切换平均 2.7 - 5.48 us 之间。线程上下文切换是 3.8 us左右。总的来说，进程线程切换还是没差太多。

**比喻**

做个简单的比喻：进程=火车，线程=车厢

1. 线程在进程下行进（单纯的车厢无法运行）
2. 一个进程可以包含多个线程（一辆火车可以有多个车厢）
3. 不同进程间数据很难共享（一辆火车上的乘客很难换到另外一辆火车，比如站点换乘）
4. 同一进程下不同线程间数据很易共享（A车厢换到B车厢很容易）
5. 进程要比线程消耗更多的计算机资源（采用多列火车相比多个车厢更耗资源）
6. 进程间不会相互影响，一个线程挂掉将导致整个进程挂掉（不一定）（一列火车不会影响到另外一列火车，但是如果一列火车上中间的一节车厢着火了，将影响到所有车厢）
7. 线程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。（比如火车上的洗手间）－"互斥锁"

>  所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。所以，对于线程和进程，我们可以这么理解： - 当进程只有一个线程时，可以认为进程就等于线程。 - 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。 - 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。



# 线程调度为什么比进程调度更少开销？ 

## 进程与线程的差异

从概念上来讲，线程是进程的一部分，只是任务调度相关的部分，所以我们才说，“线程是调度的最小单位”。进程拥有着资源，这些资源不属于某一个特定线程，因为所有线程共享进程拥有的资源，所以我们才说，“进程是资源分配的最小单位”。

我们fork一个新的进程时，实际上“伴生”了一个线程，而这个唯一的线程，实际上代表了这个进程参与到任务调度。在linux中，不管进程还是线程，都用`struct task_struct`描述。`struct mm_struct *mm`，这是一个指针，指向实际的内存资源。同一个进程内的所有线程，他们都使用相同的资源，只需要把对应的资源指针指向相同的地址。

Linux内核就好像淡化了“线程”的概念，每一个线程描述都是`struct task_struct`，他们都是一个独立的“进程”，都有着自己的进程号，都参与任务调度，只不过指向相同的进程资源。

## 任务调度的开销

**任务调度的主要开销**

1. CPU执行任务调度的开销，主要是进程上下文切换的开销 
2. 任务调度后，CPU Cache/TLB不命中，导致缺页中断的开销

对于第1点的开销，不管是进程调度还是线程调度都是必须的，所以，两者的差异体现在第2点。既然线程调度的`struct task_struct`都使用相同的资源，是不是就意味着，我即使切换到了其他的线程，CPU Cache/TLB命中的概率会高很多？相反，进程调度使用的是不同的资源，每次换了个进程，就意味着原有的Cache就不适用了，没命中，就触发更多的缺页中断，开销自然就更多。

linux中，线程都是独立的`struct task_struct`，都参与任务调度，那这里说的线程调度和进程调度怎么区分？

线程调度：使用相同资源的`struct task_struct`之间的调度 

进程调度：使用不同资源的`struct task_struct`之间的调度





# 线程和进程之前共享那些资源？

同一进程的所有线程共享以下资源：

1. 堆。堆是在进程空间内开辟的，所以被共享
2. 全局变量。与某一函数无关，与特定线程无关
3. 静态变量。静态变量存放位置和全局变量一样，都存在于堆中开辟的.bss和.data段，是共享的
4. 其他一些共用资源，比如文件。

同一进程的所有线程独享以下资源：

1. 栈。
2. 寄存器。
3. 程序计数器

**线程运行的本质就是函数的执行**，而函数的执行总会有一个源头，这个源头叫做入口函数，cup从入口函数开始一步一步向下执行，这个过程就叫做线程。由于函数运行时信息是保存在栈中的，比如返回值，参数，局部变量等等，所以栈是私有的。

cpu执行指令的信息会保存在寄存器中，这个寄存器叫做程序计数器。由于操作系统可以随时终止线程的运行，所以保存和恢复程序计数器的值就知道线程从哪里暂停的以及从哪里开始运行。



# 进程间通信方式

每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，内核是可以共享的。在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为**进程间通信（IPC，InterProcess Communication）**

- **管道**

  管道允许进程以先进先出的方式传送数据，是半双工的，意味着数据只能往一个方向流动。因此当双方通信时，必须建立两个管道。

  管道的实质就是在内核中创建一个缓冲区，管道一端的进程进入管道写数据，另一端的进程进入管道读取数据。

  管道分为pipe和FIFO两种

  - pipe：用于相关联的进程，比如父进程和子进程之间的通信。
  - FIFO：命名管道，即任何进程可以根据管道的文件名将其打开和读写。

  缺点：管道本质上是通过内核交换数据的，因此通信效率很低，不适合频繁交换数据的情况。

  匿名管道的周期随着进程的创建而创建，销毁而销毁。

- **消息队列**

  消息队列是保存在内核中的链表，由一个个独立的数据块组成，消息的接收方和发送方要约定具体的消息类型。当进程从消息队列中读取了相关数据块，则内核会将该数据块删除。跟管道相比，消息队列不一定按照先进先出的方式读取，也可以按照消息类型进行兑取。

  消息队列的生命周期与内核相关，如果不显示的删除消息队列，则消息队列会一直存在

  消息队列这种通信方式，跟收发邮件类似。两个进程你来我往的进行沟通

  缺点：不能实现实时通信。数据块是有大小限制的。**消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销**，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。

- **共享内存**

  共享内存技术就是要解决用户态和内核态之间频繁发生拷贝过程的。现代操作系统对于内存管理普遍采用的是虚拟内存技术，每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存空间映射到不同的物理内存中。

  数据不需要在不同进程之间进行复制，这是最快的一种IPC

  共享内存技术的实质就是拿出一块虚拟地址空间，映射到相同的物理内存中。这样的好处是一个进程写入数据后另一个进程可以立刻看到，不用进行拷贝。效率很高。

- **信号**

  上面那几种进程间通信，都是常规状态下的。异常状态下的需要用信号来通知进程。

  信号和信号量就像雷锋和雷峰塔的区别。

  可以在任何时刻给进程发送信号，信号是进程间通信或操作的一种异步通信机制。

  收到信号后进程对信号的处理有三种方式

  1. 如果是系统定义的信号函数，执行默认操作。

     >**SIGINT：**程序终止信号。程序运行过程中，按`Ctrl+C`键将产生该信号。
     >
     >**SIGQUIT：**程序退出信号。程序运行过程中，按`Ctrl+\\`键将产生该信号。
     >
     >**SIGALRM：**定时器信号。
     >
     >**SIGTERM：**结束进程信号。shell下执行`kill 进程pid`发送该信号。

  2. 捕捉信号。用户可以给信号定义信号处理函数，表示收到信号后该进程该怎么做。

  3. 忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程。

- **unix域套接字**

  具体指unix域间套接字。socket API原本是为网络通讯设计的，但后来在socket的框架上发展出一种IPC机制，就是UNIX Domain Socket。虽然网络socket也可用于同一台主机的进程间通讯（通过loopback地址127.0.0.1），但是UNIX Domain Socket用于IPC更有效率：不需要经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等，只是将应用层数据从一个进程拷贝到另一个进程。**UNIX域套接字与TCP套接字相比较，在同一台主机的传输速度前者是后者的两倍。**这是因为，IPC机制本质上是可靠的通讯，而网络协议是为不可靠的通讯设计的。UNIX Domain Socket也提供面向流和面向数据包两种API接口，类似于TCP和UDP，但是面向消息的UNIX Domain Socket也是可靠的，消息既不会丢失也不会顺序错乱。

- **信号量**（同步原语，并不叫IPC）

  **本质是一个计数器，用于为多个进程提供对共享对象的访问**

  共享内存在效率高的同时也带来了新的问题，即如果多个进程同时对一个共享内存进行操作，会产生冲突造成不可预计的后果。

  为了不冲突，共享内存在一个时间段只能有一个进程访问，就出现了信号量。

  信号量其实是一个计数器，用于实现进程间的互斥和同步。

  **信号量表示资源的数量。** **P操作** 会把信号量-1，-1之后如果信号量的值<0，则表示资源已经被占用，进程需要阻塞等待。如果信号量-1后>= 0，表明进程可以正常执行。**V操作**跟P操作正好相反。

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210819115755.png" alt="img" style="zoom:50%;float:left" />

  1. 进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。

  2. 若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。

  3. 直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。

     > **信号量与互斥量之间的区别：**
     >
     > （1）互斥量用于线程的互斥，信号量用于线程的同步。这是互斥量和信号量的根本区别，也就是互斥和同步之间的区别。
     >
     > **互斥：**是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。
     >
     > **同步：**是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。
     >
     > （2）互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。



# 进程同步

在多道程序环境下，当程序并发执行时候，由于资源共享和进程间相互协作的关系，同一个系统中的诸进程之间会存在一下两种相互制约的关系：

1. 间接相互制约。主要是资源共享这种情况
2. 直接相互制约。源于进程间的相互合作，例如A进程向B进程提供数据，当A缓存没数据的时候B就阻塞，A缓存满时A就阻塞。

进程同步首先要搞明白临界区

- 临界区

  许多硬件资源如打印机，磁带机等，都属于临界资源，诸进程应该采取互斥方式，实现对这种资源的共享。人们把在每个进程中访问临界资源的那段代码成为临界区，显然，若能保证诸进程互斥地进入自己的临界区，便可实现诸进程对临界资源的互斥访问。

- 同步机制遵循的原则

  1. 空闲让进，当无进程处于临界区时，表明临界资源处于空闲状态，应允许一个请求进入临界区的进程立即进入自己的临界区，以有效的利用临界资源。
  2. 忙则等待，当已有进程进入临界区时，表明临界资源正在被访问，因而其他视图进入临界区的进程必须等待，以保证对临界资源的互斥访问。
  3. 有限等待，对要求访问临界资源的进程 ，应保证在有限时限内能进入自己的临界区，以免陷入死等状态。
  4. 让权等待，当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入忙等状态。

- 进程同步实现机制

  1. 提高临界区代码执行中断的优先级

     在传统操作系统中，打断进程对临界区代码的执行只有中断请求、中断一旦被接受，系统就有可能调用其它进程进入临界区，并修改此全局数据库。所以用提高临界区中断优先级方法就可以屏蔽了其它中断，保证了临界段的执行不被打断，从而实现了互斥。

  2. 自旋锁

     内核（处理器也如此）被保持在过渡状态“旋转”，直到它获得锁，“自旋锁”由此而得名。
     自旋锁像它们所保护的数据结构一样，储存在共用内存中。为了速度和使用任何在处理器体系下提供的锁定机构，获取和释放自旋锁的代码是用汇编语言写的。

  3. 信号量机制

     跟进程同步信号量机制一样

- 经典进程同步问题

  [具体参考](#经典的进程间通信(同步)问题)

  1. 生产者——消费者问题
  2. 哲学家进餐问题
  3. 读者——写者问题



# 经典的进程间通信(同步)问题

> P是减小
>
> V是增加

## 生产者—消费者

> **问题描述：**两个进程（生产者和消费者）共享一个公共的固定大小的缓冲区。生产者将数据放入缓冲区，消费者从缓冲区中取数据。也可以扩展成m个生产者和n个消费者。当缓冲区空的时候，消费者因为取不到数据就会睡眠，知道缓冲区有数据才会被唤醒。当缓冲区满的时候，生产者无法继续往缓冲区中添加数据，就会睡眠，当缓冲区不满的时候再唤醒。
>
> **出现的问题：**为了时刻监视缓冲区大小，需要有一个变量count来映射。但是这个变量就是映射的共享内存，生产者消费者都可以修改这个变量。由于这里面对count没有加以限制会出现竞争。比如当缓冲区为空时，count=0，消费者读取到count为0，这个时候cpu的执行权限突然转移给了生产者。然后生产者发现count=0，就会马上生产一个数据放到缓冲区中，此时count=1，接着会发送一个wakeup信号给消费者，因为由于之前count=0，生产者以为消费者进入了阻塞状态。但事实上我们知道消费者还没有进入阻塞状态，因此生产者的这个wakeup信号会丢失。接着CPU执行权限有转移到消费者这里，消费者查看自己的进程表项中存储的信息发现count=0然后进入阻塞，永远不去取数据。这个时候生产者迟早会把缓冲区填满，然后生产者也会进入阻塞，然后两个进程都在阻塞下去，出现了问题。

这个模型涉及到了两种关系：

1. 生产者和消费者之间的同步关系。当缓冲区满时，必须等消费者先行动。当缓冲区空时，必须等生产者先行动。
2. 生产者和消费者之间的互斥关系。就是刚才提到的问题，对缓冲区的操作必须与其他进程互斥才行。不然很容易死锁。

解决方案：

```c
pthread_mutex_t mutex;  
pthread_cond_t producter;  
pthread_cond_t consumer;
count = pool.size()

producer(){
    while(1){
      pthread_mutex_lock(&mutex);
      pool++;
      while(pool == full){
          pthread_cond_wait(&producter, &mutex);
      }
      pthread_cond_signal(&consumer, &mutex);
      pthread_mutex_unlock(&mutex);
    }
}
consumer(){
    while(1){
      pthread_mutex_lock(&mutex);
      pool--;
      while(pool == 0){
          pthread_cond_wait(&consumer, &mutex);
      }
      pthread_cond_signal(&producter, &mutex);
      pthread_mutex_unlock(&mutex);
    }
}
```

注意不能先执行P(mutex)再执行P(empty)，这样生产者阻塞了消费者也阻塞了。

## 哲学家就餐问题

> **问题描述：**如下图所示
>
> <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/1858706-20191207225016969-138155882.png" alt="img" style="zoom: 67%;float:left" />
>
> 哲学家只有两件事情，吃饭和思考。每个哲学家的两边都有叉子，只有当拥有左面和右面的叉子时候才能吃饭，吃完饭后放下叉子思考。
>
> **出现问题：**一下两种情况会产生死锁。第一种情况是五位哲学家同时拿起左边的叉子，就没有人能够拿到右面的叉子造成死锁。第二种情况是拿起左边叉子，然后查看右边有没有叉子，没有就放下左边叉子，有就拿起右边叉子吃饭。这样也会造成死锁，五个人还是同时拿左边的叉子，然后放下这样会永远重复。第三种情况就是哲学家拿起左边叉子然后随机等待一段时间，有右边叉子就拿没有就放下左边叉子。但是当对于核电站中的安全系统时候，随机数不可靠。

整个模型中有五个进程，互相之间是互斥的关系。解决方法是：

1. 同时拿到两个筷子
2. 对每个哲学家的动作制定规则，避免饥饿或者死锁。

> 解决方法是设置一个互斥信号量组用于对进程之间的互斥访问chopstick=[1,1,1,1,1]
>
> ```c
> semaphore chopstick[5] = {1,1,1,1,1}; //定义信号量数组mutex[5],并初始化
> Pi(){  //i号哲学家的进程
> do{
>   P (chopstick[i] ) ; //取左边筷子
>   P (chopstick[(i+1) %5] ) ；  //取右边篌子
>   eat;  //进餐
>   V(chopstick[i]) ; //放回左边筷子
>   V(chopstick[(i+l)%5]);  //放回右边筷子
>   think;  //思考
> } while (1);
> }
> ```
>
> 这个算法存在以下问题：**同时就餐拿起左边的筷子会产生死锁**

改进：

> 对哲学家进程施加一些限制条件，比如至多允许四个哲学家同时进餐;仅当一个哲学家左右两边的筷子都可用时才允许他抓起筷子
>
> ```c
> semaphore chopstick[5] = {1,1,1,1,1}; //初始化信号量
> semaphore mutex=l;  //设置取筷子的信号量
> Pi(){ //i号哲学家的进程
> do{
>   P (mutex) ; //在取筷子前获得互斥量
>   P (chopstick [i]) ; //取左边筷子
>   P (chopstick[ (i+1) %5]) ;  //取右边筷子
>   V (mutex) ; //释放取筷子的信号量
>   eat;  //进餐
>   V(chopstick[i] ) ;  //放回左边筷子
>   V(chopstick[ (i+l)%5]) ;  //放回右边筷子
>   think;  // 思考
> }while(1);
> }
> ```

## 读写问题

> **问题描述：**有读者和写者**两组**并发进程，共享一个文件，当两个或以上的读进程同时访问共享数据时不会产生副作用，但是如果有写进程在修改数据库的时候不能有其他读进程或写进程访问数据库。因此要求：①允许多个读者可以同时对文件执行读操作；②只允许一个写者往文件中写信息；③任一写者在完成写操作之前不允许其他读者或写者工作；④写者执行写操作前，应让已有的读者和写者全部退出。

问题中的三个关系：

1. 读者和写者是互斥关系
2. 写者和写者是互斥关系
3. 读者和读者不存在互斥关系

> **分析：**
>
> 1. 写者好分析，他和任意进程互斥，用互斥信号量操作就行
> 2. 读者问题比较复杂。读者必须实现和写者的互斥，而且要实现和其他读者的同步。
>
> 因此用到一个计数器，判断当前有多少读者在读文件。
>
> 当有读者的时候不能写入文件，当没有读者的时候写者才会写入文件。
>
> 同时计数器也是公共内存，对计数器的访问也应该是互斥的
>
> ```c
> int count=0;  //用于记录当前的读者数量
> semaphore mutex=1;  //用于保护更新count变量时的互斥
> semaphore rw=1;  //用于保证读者和写者互斥地访问文件
> 
> //可以看到writer比较简单
> writer () {  //写者进程
>     while (1){
>         P(rw); // 互斥访问共享文件
>         Writing;  //写入
>         V(rw) ;  //释放共享文件
>     }
> }
> 
> reader () {  // 读者进程
>     while(1){
>         P (mutex) ;  //互斥访问count变量
>         if (count==0)  //当第一个读进程读共享文件时
>             P(rw);  //阻止写进程写
>         count++;  //读者计数器加1
>         V (mutex) ;  //释放互斥变量count
> 
>         reading;  //读取
> 
>         P (mutex) ;  //互斥访问count变量
>         count--; //读者计数器减1
>         if (count==0)  //当最后一个读进程读完共享文件
>             V(rw) ;  //允许写进程写
>         V (mutex) ;  //释放互斥变量 count
>     }
> }
> ```



# CPU调度算法（进程调度算法）

进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。

调度分为两大类：抢占式调度和非抢占式调度。抢占式调度说明程序正在运行时可以被打断，把CPU让给其他进程。非抢占式调度表示一个进程正在运行当进程完成或者阻塞的时候把CPU让出来。

调度的的话有很多进程都会等待这调度，那么就有一些调度算法：

- **先来先服务调度算法**

  每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。

  这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。

  FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。

- **最短作业优先调度算法**

  优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。

  这显然对长作业不利，很容易造成一种极端现象。比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。

- **高响应比优先调度算法**

  前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。

  每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：

  优先权=（等待时间+服务时间）/ 服务时间。

- **时间片轮转调度算法**

  每个进程被分配一个时间段，称为时间片（\*Quantum\*），即允许该进程在该时间段中运行。

  如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。

- **最高优先级调度算法**

  对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法。

  非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。

  抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

- **多级反馈队列调度算法**

  多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。

  多级表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。

  反馈表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203181732936.jpeg" alt="多级反馈队列" style="zoom: 67%;float:left" />

  其工作流程如下：

  1. 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短；
  2. 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
  3. 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；



# 操作系统是如何做到进程阻塞的？

- 什么是阻塞

  正在运行的进程由于提出系统服务请求（如I/O操作），但因为某种原因未得到操作系统的立即响应，或者需要从其他合作进程获得的数据尚未到达等原因，该进程只能调用阻塞原语把自己阻塞，等待相应的事件出现后才被唤醒。

  进程并不总是可以立即运行的，一方面是 CPU 资源有限，另一方面则是进程时常需要等待外部事件的发生，例如 I/O 事件、定时器事件等。

- 如何做到进程阻塞

  操作系统为了支持多任务，实现了进程调度的功能，会把进程分为“运行”和“等待”等几种状态。操作系统会分时执行各个运行状态的进程，由于速度很快，看上去就像是同时执行多个任务，这里用到了时间片轮转技术，如果在时间片结束时进程还在运行，则CPU使用权将被剥夺并分配给另一个进程。**如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。**

  当CPU从一个进程跑到了别的进程之后，肯定还需要跑回来，因此就有工作队列和等待队列。

  假如现在进程 A 里跑的程序有一个对象执行了某个方法将当前进程阻塞了，内核会立刻将进程A从工作队列中移除，同时创建等待队列，并新建一个引用指向进程A。这时进程A被排在了工作队列之外，不受系统调度了，这就是我们常说的被操作系统“挂起”。这也提现了阻塞和挂起的关系。阻塞是人为安排的，让你程序走到这里阻塞。而阻塞的实现方式是系统将进程挂起。

  当这个对象受到某种“刺激”（某事件触发）之后， 操作系统将该对象等待队列上的进程重新放回到工作队列上就绪，等待时间片轮转到该进程。所以，操作系统不会去尝试运行被阻塞的进程，而是由对象去等待某种“刺激”，喜欢被动。

  （要点：时间片轮转，工作队列和等待队列）

- 进程阻塞不消耗CPU资源，但是会消耗系统资源。因此系统资源不仅包含CPU，还有内存、磁盘I/O等等



# 线程间通信的方式

线程间很多资源都是共享的，所以线程间没有像进程间那样有许多数据交换机制。**线程间通信主要目的是为了线程同步。**

- **锁机制**

  - 互斥锁。确保同一时间内只有一个线程能访问共享资源。当资源被占用时其他试图加锁的线程会进入阻塞状态。当锁释放后，哪个线程能上锁取决于内核调度。
  - 读写锁。当以写模式加锁的时候，任何其他线程不论以何种方式加锁都会处以阻塞状态。当以读模式加锁时，读状态不阻塞，但是写状态阻塞。“读模式共享，写模式互斥”
  - 自旋锁。上锁受阻时线程不阻塞而是在循环中轮询查看能否获得该锁，没有线程的切换因而没有切换开销，不过对CPU的霸占会导致CPU资源的浪费。
- **posix信号量机制**

  信号量本质上是一个计数器，可以有PV操作，来控制多个进程或者线程对共享资源的访问。

  信号量API有两组，第一组就是System V IPC信号量用于进程间通信的，另外一组就是POSIX信号量，信号量原理都是一样的

- **条件变量**

  条件变量提供了线程间的通知机制：当某个共享数据到达某个值的时候，唤醒等待这个共享数据的线程。

  条件变量要结合互斥锁使用，如下图代码：

  ```c
  pthread_mutex_lock(&mutex);　
  　　while(条件为假)
  　　　　pthread_cond_wait(&cond,&mutex);　　
  　　执行某种操作
  pthread_mutex_unlock(&mutex);
  ```

  也就是说，一个线程要等到临界区的共享数据达到某种状态时再进行某种操作，而这个状态的成立，则是由另外一个进程/线程来完成后发送信号来通知的。



# 线程是如何实现的？

这个看《操作系统》总结的也有

实现线程主要有三种方式：（1）使用内核线程实现，（2）使用用户线程实现（3）使用用户线程加轻量级进程混合实现。

- 内核线程实现

  内核线程（Kernel-Level Thread,KLT）就是直接由操作系统内核支持的线程，内核通过操纵调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身，这种操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核。

  程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口：轻量级进程（Light Weight Process ，LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。

- 用户线程实现

  从广义上讲，一个线程只要不是内核线程，就可以认为是用户线程（User Thread，UT）。而狭义上的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。使用用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理。线程的创建、切换和调度都是需要考虑的问题，因此比较难。

- 用户线程加轻量级进程混合实现

  线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用户线程一起使用的实现方式。在这种混合实现下，既存在用户线程，也存在轻量级进程。



# 线程调度

- 协同式调度

  使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的工作执行完了之后，要主动通知系统切换到另一个线程上。协同式多线程的最大好处是实现简单，不会有线程同步问题。缺点是线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程切换，那么程序就会一直阻塞在那里。

- 抢占式调度

  使用抢占式调度的多线程系统，每个线程将由系统来分配执行时间，线程的切换不由线程本身来决定。在这种实现线程调度的方式下，线程的执行时间是系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢占式调度。



# **进程阻塞为什么不占用cpu资源？**

因为阻塞了得不到cpu，怎么占用CPU资源



# linux内核的同步方式

首先要明确，同步和互斥是计算机系统中，用于控制进程对某些特定资源访问的机制。同步指的是进程按照一定的顺序和规则访问资源，互斥则是控制资源某一时刻只能由一个进程访问。这样看来互斥是同步的一种情况。

在现代操作系统里，同一时间可能有多个内核执行流在执行，因此内核其实象多进程多线程编程一样也需要一些同步机制来同步各执行单元对共享数据的访问。尤其是在多处理器系统上，更需要一些同步机制来同步不同处理器上的执行单元对共享的数据的访问。在主流的Linux内核中包含了几乎所有现代的操作系统具有的同步机制，**这些同步机制包括：原子操作、信号量（semaphore）、读写信号量 （rw_semaphore）、spinlock、BKL(Big Kernel Lock)、rwlock、brlock（只包含在2.4内核中）、RCU（只包含在2.6内核中）和seqlock（只包含在2.6内核中）。**

> linux会因为三种机制而产生并发，需要进行同步。
>
> 1. **中断。**中断就是操作系统随时可以打断正在执行的代码。当进程访问某个临界资源发生中断，会进入中断处理程序。中断处理程序也可能访问该临界资源。
> 2. **内核抢占式调度。**内核中正在执行的任务被另外一个任务抢占。
> 3. **多处理器并发。**每个处理器都可以调度一个进程，多个进程可能会造成并发。

- **禁用中断**

  对于单处理器不可抢占系统来说，系统并发源主要是中断处理。因此在进行临界资源访问时，进行禁用/使能中断即可以达到消除异步并发源的目的。

- **原子操作**

  原子操作保证指令在运行时候不会被任何事物或者事件打断，把读和写的行为包含在一步中执行，避免竞争。

- **内存屏障(memory barrier)**

  程序在运行时内存实际的访问顺序和程序代码编写的访问顺序不一定一致，这就是内存乱序访问。内存乱序访问行为出现的理由是为了提升程序运行时的性能。内存乱序访问主要发生在两个阶段：

  1. 编译时，编译器优化导致内存乱序访问（指令重排）
  2. 运行时，多 CPU 间交互引起内存乱序访问

- **自旋锁(spin lock)**

  对于复杂的操作原子操作是不能的。比如从一种数据结构中读取数据，写入到另一种数据结构中。自旋锁是linux内核中最常见的一种锁。自旋锁只能被一个可执行线程所拥有，如果有线程要抢占一个已经被占有的自旋锁，则其会一直进行循环来等待锁重新可用。当锁被释放后，请求锁的执行线程便能立刻得到它。其实就是忙等自旋锁只适用于那些在临界区停留很短时间的加锁操作。因为线程在等待锁期间会一直占据处理器，如果长时间等待锁会导致处理器效率降低。而如果线程占用锁只需要短暂的执行一下，那么使用自旋锁更优，因为不需要进行上下文的切换。

- **信号量**

  可以理解为一种“睡眠锁”

  自旋锁是“忙等”机制，在临界资源被锁定的时间很短的情况下很有效。但是在临界资源被持有时间很长或者不确定的情况下，忙等机制则会浪费很多宝贵的处理器时间。

  而信号量机制在进程无法获取到临界资源的情况下，立即释放处理器的使用权，并睡眠在所访问的临界资源上对应的等待队列上；在临界资源被释放时，再唤醒阻塞在该临界资源上的进程。信号量适用于长时间占用锁的情形。

- **读-写自旋锁**

  具体就是在读写场景中了，为读和写提供不同的锁机制。

  当一个或者多个读任务时可以并发的持有读锁，但是写锁只能被一个人物所持有的。即对写者共享对读者排斥

- **读写信号量**

  这个和读写自旋锁的思想是一样的。

- **mutex体制**

  也是一种睡眠锁，是实现互斥的特定睡眠锁。是一种互斥信号

  使用mutex有很多限制，不像信号量那样想用就用

  1. 任何时刻只有一个任务可以持有mutex，引用计数只能是1
  2. 给mutex上锁必须给其解锁，严格点就是必须在同一上下文中上锁和解锁
  3. 持有mutex的进程不能退出
  4. 等等

- **完成变量(completion variable)**

  内核中一个任务需要发出信号通知另一个任务发生了某个特定事件，利用完成变量使得两个任务实现同步

- **BLK：大内核锁**

  属于混沌时期的产物，是一个全局的自旋锁

  这个东西是早期linux不支持线程的时候用的，和自旋锁差不多的思想。

  现在一般不鼓励使用这个了

- **顺序锁**

  这种锁用于读写共享数据。

  实现这个机制主要依靠序列计数器，当写数据时，会得到一个锁，序列值会增加。在读取数据前后这两个时间内，序列值都会被读取

  如果读取的序列号值相同，表明读操作在进行的过程中没有被写操作打断，

- **关闭内核抢占**

  内核是抢占性的，因此内核中的进程在任何时候都可能停下来以便让另一个具有更高优先级的进程运行。但是一个任务和被抢占的任务可能在同一个临界区运行。为了避免上述情况，当使用自旋锁时这个区域被标记为非抢占的，一个自旋锁被持有表示内核不能抢占调度。

  但是在一些情况下，就算不用自旋锁，也要关闭内核抢占。

  比如，对于只有一个处理器能够访问到数据，原理上是没有必要加自旋锁的，因为在任何时刻数据的访问者永远只有一位。但是，如果内核抢占没有关闭，则可能一个新调度的任务就可能访问同一个变量。
  
  所以这时候害怕的不是多个任务访问同问同一个变量，而是一个任务的访问还没有完成就转到了另一个任务。
  
- **RCU(Read, Copy, Update)**

  RCU(Read, Copy, Update)是一组Linux内核API，实现了一种同步机制，允许多个读者与写者并发操作而不需要任何锁，这种同步机制可以用于保护通过指针进行访问的数据。比较适合用在读操作很多而写操作极少的情况，可以用来替代读写锁。

  一个典型场景就是内核路由表，路由表的更新是由外部触发的，外部环境的延迟远比内核更新延迟高，在内核更新路由表前实际已经向旧路径转发了很多数据包，RCU读者按照旧路径再多转发几个数据包是完全可以接受的，而且由于RCU的无锁特性，实际上相比有锁的同步机制，内核可以更早生效新的路由表。路由表这个场景，以系统内部短时间的不一致为代价，降低了系统内部与外部世界的不一致时间，同时降低了读者成本。

  > Q: **为什么只能保护通过指针访问的数据？**
  >
  > A: 任何CPU架构下的Linux都可以保证指针操作的原子性，这是无锁并发的前提。也就是说，假设CPU A在修改指针，无论何时CPU B读取该指针，都可以保证读取到的数据要么是旧的值，要么是新的值，绝不会是混合新旧值不同bit位的无意义值。因此使用RCU对更复杂的数据结构的保护都是基于对指向该数据结构的指针的保护。



# 死锁

  > 概念：由于操作系统会产生并发，那会产生一个问题，就是多个进程因为争夺资源而互相陷入等待。

  - **死锁产生的原因**

    1. 资源分配不当
    2. 进程运行的顺序不合理

  - **产生死锁的必要条件****

    1. 互斥。某个资源只允许一个进程访问，如果已经有进程访问该资源，则其他进程就不能访问，直到该进程访问结束。
    2. 占有的同时等待。一个进程占有其他资源的同时，还有资源未得到，需要其他进程释放该资源。
    3. 不可抢占。别的进程已经占有某资源，自己不能去抢。
    4. 循环等待。存在一个循环，每个进程都需要下一个进程的资源。

    以上四个条件均满足必然会造成死锁。会导致cpu吞吐量下降，死锁会浪费系统资源造成计算机性能下降。

  - **避免死锁的方法**

    我们要尽量避免四个条件同时产生，因此就要破坏。由于互斥条件是必须的，必须要保证的，因此从后面三条下手。

    1. 破坏“占有且等待条件”。

       ①所有进程在开始运行之前，一次性申请到所有所需要的资源。

       ②进程用完的资源释放掉，然后再去请求新的资源，提高利用率。

    2. 破坏“不可抢占”条件。

       当进程提出在得到一些资源时候不被满足的情况下，必须释放自己已经保存的资源。

    3. 破坏“循环等待”。

       实现资源有序分配策略，所有进程申请资源必须按照顺序执行。

    4. 银行家算法
    
       [参考链接](https://www.cnblogs.com/wkfvawl/p/11929508.html)
       
       银行家算法的实质就是即每当进程提出资源请求且系统的资源能够满足该请求时，系统将判断满足此次资源请求后系统状态是否安全（安全状态是非死锁状态，而不安全状态并不一定是死锁状态。即系统处于安全状态一定可以避免死锁，而系统处于不安全状态则仅仅可能进入死锁状态。），如果判断结果为安全，则给该进程分配资源，否则不分配资源，申请资源的进程将阻塞。
       
       银行家算法的执行有个前提条件，即要求进程预先提出自己的最大资源请求，并假设系统拥有固定的资源总量。
       
       <img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/1358881-20191125165114981-1954446360.png" alt="img" style="zoom:80%;float:left" />



# 虚拟内存

## 为什么需要虚拟内存？内存技术发展历程

- 1、无存储器抽象

  早期计算机没有存储器抽象，每一个程序都是直接访问物理内存。这种情况下在内存中同时运行两个程序是不可能的，因为如果第一个程序比如在内存2000的位置写入一个新的值，那么第二个程序运行的时候就会擦掉第一个程序的值。

  但是即使没有抽象概念，运行两个程序也是可能的。。。

  操作系统把当前内存中的内容保存在磁盘文件中，然后把下一个程序读入到内存中再运行就行，即某个时间内内存只有一个程序在运行就不会发生冲突。（最早期的交换的概念）

  还有就是借助硬件来实现并发运行多个程序，比如IBM360中内存被划分为2KB的块，每个块有一个4位的保护键，保护键存储在CPU的特殊寄存器中。一个运行中的程序如果访问的保护键与操作系统中保存的不相符，则硬件会捕获到该异常，由于只有操作系统可以修改保护键，因此这样就可以防止用户进程之间、用户进程和操作系统间的干扰。

- 2、地址空间（存储抽象）

  > 把物理地址暴露给进程会带来几个问题：
  >
  > 1. 如果用户进程可以寻址内存中的每一个字节，就可以很容易的破坏操作系统，从而时电脑出故障。
  > 2. 想要同时运行多个程序比较困难

  在之前所说的解决多个程序在内存中互不影响的办法主要有两个：保护和重定位，也就是说并不是所有内存你都能访问，因此出现了地址空间的概念。

  **地址空间**是一个进程可用于寻址内存的一套地址的集合。每个进程都有自己的地址空间，并且这个地址空间独立于其他进程的地址空间

  最开始的地址空间的解决办法是动态重定位，就是简单地把每个进程的地址空间映射到物理内存的不同部分。但是也有问题，即每个进程都有内存，如果同时运行多个进程，那所需要的内存是很庞大的，这个ram数远远超过存储器支持的。比如在Linux和Windows中，计算机完成引导后会启动50-100个进程，那你需要的空间可大了去了。

  处理上述内存超载问题有两个办法，就是交换技术和虚拟内存。

  交换技术就是把一个进程完整的调入内存，使得该进程完整运行一段时间后在调入磁盘。但是这样的话，你把一个完整的进程调入进去，可能很大程度只会使用一部分内存，这样是不划算的。

  所以有了虚拟内存，每个进程的一部分调入内存。

- 3、虚拟内存

  这个要重点说

## 什么是虚拟内存

根据上面所说，虚拟内存就是来解决“**程序大于内存的问题**”，即如何不把程序内存全部装进去。

**虚拟内存的基本思想是每个程序都拥有自己的地址空间，这些空间被分割成多个块儿。每一块儿被称作一页或者页面。每一个页面有连续的地址范围。这些页面被映射到物理内存，但是并不是一个程序的所有的页面都必须在内存中才能运行**。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻执行映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失部分装入物理内存并重新执行指令。

**虚拟内存** 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。

## 第一阶段：分段

程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段的形式

分段机制下的虚拟地址由两部分组成，**段选择子**和**段内偏移量**。

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/aHR0cHM6Ly9zdGF0aWMwMS5pbWdrci5jb20vdGVtcC8zYTk5NGVmMGY0M2M0NmE4YjY1OWQ0MjY5NTBmYmRlMy5wbmc" alt="内存分段-寻址的方式" style="zoom: 33%;float:left" />

- 段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。
- 虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/aHR0cHM6Ly9zdGF0aWMwMS5pbWdrci5jb20vdGVtcC8yYjEzOGRjZWI0OTI0YTE3ODQ1ZGE2ZjAzNDlhMjE0Ny5wbmc" alt="内存分段-虚拟地址与物理地址" style="zoom:50%;float:left" />

如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。

分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：

1. 第一个就是内存碎片的问题。
   - 外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载；
   - 内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；
2. 第二个就是内存交换的效率低的问题。

解决外部内存碎片的问题就是内存交换。这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。对于多进程的系统来说，用分段的方式，内存碎片是很容易产生的，产生了内存碎片，那不得不重新 `Swap` 内存区域，这个过程会产生性能瓶颈。因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。所以，**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**为了解决内存分段的内存碎片和内存交换效率低的问题，就出现了内存分页。

## 第二阶段：分页

在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字。在使用虚拟内存的情况下，虚拟地址不是直接被送到内存总线上的，而是被送往内存管理单元MMU，然后MMU把虚拟地址映射为物理内存地址

> <img src="https://s2.loli.net/2022/01/09/1NDpgGZf6xSyVjA.png" alt="img" style="zoom: 40%;float:left" />
>
> 在这里MMU是作为CPU芯片的一部分，通常就是这样的。



**具体页表中虚拟地址与物理内存地址之间的映射关系如下：**

> <img src="https://s2.loli.net/2022/01/09/Tiycz1fOpubvhZk.png" alt="img" style="zoom: 33%;float:left" />
>
> 上图可以看到虚拟地址被划分成多个页面组成的单位，而物理内存地址中对应的是页框的概念。页面和页框的大小通常是一样的，在这里是4KB作为例子，实际系统中可能是512KB-1GB。上图虚拟地址空间有64KB，物理内存有32KB，因此由16个虚拟页面和8个页框。请记住，ram和也磁盘之间的交换总是以整个页面为单位进行的。
>
> 比如当程序访问地址0的时候，其实是访问虚拟地址，然后将虚拟地址0送到MMU，MMU根据映射关系发现虚拟地址0在页面0-4095这个页面上，然后根据映射找到实际物理内存地址是第二个页框，即8192，然后把地址8192送到总线上。内存对MMU是一无所知的，他只看到了一个读写8192的请求并执行。
>
> 当程序访问了一个未被映射的页面，即虚拟地址没有对应的页框索引。此时MMU注意到该页面没有映射，使CPU陷入到操作系统，即缺页中断或者缺页错误（page fault）。随后操作系统找到了一个很少使用的页框并把该页框内容写入磁盘，然后把需要访问的页面读到刚才被回收的那个页框上，修改映射关系，重新启动引起中断的指令就好。
>
> 例如如果操作系统放弃页框1，即重新映射页框1，那么重新改变映射关系，将页面8装入物理地址4096（页框1），并且对MMU映射做两处修改：①由于页框1之前被页面1映射，因此要将页面1标记为未映射，使得以后对页面1的访问都将导致缺页中断。②把虚拟页面8的叉号改为1，表明虚拟页面8映射到页框1上去，当指令重新启动时候就会产生新的映射。



**MMU的内部操作：**

> <img src="https://s2.loli.net/2022/01/09/kZnBWuoVwvmclsF.png" alt="img" style="zoom:33%;float:left" />
>
> 输入虚拟地址8196的二进制在最底下即0010000000000100，用MMU映射机进行映射，这16位虚拟地址被分解成4位的页号+12位的偏移量。4位页号表示16个页面，是页面的索引，12位的位偏移可以为一页内的全部4096个字节编址。



## 第二阶段：分表

虚拟地址到物理地址的映射可以概括如下：虚拟地址被分成虚拟页号+偏移量。虚拟页号是一个页表的索引，可以有该索引即页面号找到对应的页框号，然后将该页框号放到16位地址的前4位，替换掉虚拟页号，就形成了送往内存的地址。可以参考上面那个图中，两个二进制字符串的替换形式。如下图：

<img src="https://s2.loli.net/2022/01/09/JTyb39umxQ6Zhtg.png" alt="img" style="zoom:40%;float:left" />

页表的目的是将虚拟页面映射为页框，从数学角度说页表是一个函数，输入参数是虚拟页号，输出结果是物理页框号。

页表的结构如下：

<img src="https://s2.loli.net/2022/08/14/bxrp8vDNqh4TfyM.png" alt="img" style="zoom:40%;float:left" />

页表项中最重要的字段就是`页框号(Page frame number)`。毕竟，页表到页框最重要的一步操作就是要把此值映射过去。下一个比较重要的就是`在/不在`位，如果此位上的值是 1，那么页表项是有效的并且能够被`使用`。如果此值是 0 的话，则表示该页表项对应的虚拟页面`不在`内存中，访问该页面会引起一个`缺页异常(page fault)`。`保护位(Protection)` 告诉我们哪一种访问是允许的，啥意思呢？最简单的表示形式是这个域只有一位，**0 表示可读可写，1 表示的是只读**。`修改位(Modified)` 和 `访问位(Referenced)` 会跟踪页面的使用情况。当一个页面被写入时，硬件会自动的设置修改位。修改位在页面重新分配页框时很有用。如果一个页面已经被修改过（即它是 `脏` 的），则必须把它写回磁盘。如果一个页面没有被修改过（即它是 `干净`的），那么重新分配时这个页框会被直接丢弃，因为磁盘上的副本仍然是有效的。这个位有时也叫做 `脏位(dirty bit)`，因为它反映了页面的状态。`访问位(Referenced)` 在页面被访问时被设置，不管是读还是写。这个值能够帮助操作系统在发生缺页中断时选择要淘汰的页。不再使用的页要比正在使用的页更适合被淘汰。这个位在后面要讨论的`页面置换`算法中作用很大。最后一位用于禁止该页面被高速缓存，这个功能对于映射到设备寄存器还是内存中起到了关键作用。通过这一位可以禁用高速缓存。具有独立的 I/O 空间而不是用内存映射 I/O 的机器来说，并不需要这一位。

## 分页带来的问题

分页系统中要考虑两个问题：

1. 虚拟地址到物理地址的映射必须非常快（速度问题）

   由于每次访问内存都需要进行虚拟地址到物理地址的映射，所有的指令最终都必须来自内存，并且很多指令也会访问内存中的操作数。因此每条指令进行多次页表访问是必要的。如果执行一条指令需要1ns，则页表查询必须在0.2ns之内完成，以避免映射成为主要的瓶颈。

2. 如果虚拟地址空间很大，页表也会很大（空间问题）

   现代计算机使用的虚拟地址至少为32位，而且越来越多的64位。假设一个页面大小为4KB，则32位的地址空间将有100万页，那么64位地址空间更多了。一个页表有100万条表项，你个存储开销就很大。而且每个进程都有自己的页表还

所以我们接下来主要解决的就是这两个问题。

## 解决速度问题

大多数优化技术都是从内存中的页表开始的，因为这里面会存在这有巨大影响的问题。比如一条1字节指令要把一个寄存器中的数据复制到另一个寄存器，在不分页的情况下这条指令只访问一次内存。有了分页机制之后，会因为要访问页表而引起多次的内存访问。同时，CPU的执行速度会被内存中取指令执行和取数据的速度拉低，所以会使性能下降。解决方案如下：

由于大多数程序总是对少量页面进行多次访问，因此只有很少的页表项会被反复读取，而其他页表项很少会被访问。针对这个问题，为计算机设置一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必再去访问页表通过MMU得到物理地址，这个设备叫做**转换检测缓冲区**又叫做**快表（TLB）**。通常在MMU中，包含少量的表项，实际中应该有256个，每一个表项都记录了一个页面相关信息，即虚拟页号、修改为、保护码、对应的物理页框号，如下表所示：

| 有效位 | 虚拟页面号 | 修改位 | 保护位 | 页框号 |
| :----: | :--------: | :----: | :----: | :----: |
|   1    |    140     |   1    |   RW   |   31   |
|   1    |     20     |   0    |  R X   |   38   |
|   1    |    130     |   1    |   RW   |   29   |
|   1    |    129     |   1    |   RW   |   62   |
|   1    |     19     |   0    |  R X   |   50   |
|   1    |     21     |   0    |  R X   |   45   |
|   1    |    860     |   1    |   RW   |   14   |
|   1    |    861     |   1    |   RW   |   75   |

TLB 其实就是一种内存缓存，用于减少访问内存所需要的时间，它就是 MMU 的一部分，TLB 会将虚拟地址到物理地址的转换存储起来，通常可以称为`地址翻译缓存(address-translation cache)`。TLB 通常位于 CPU 和 CPU 缓存之间，它与 CPU 缓存是不同的缓存级别。下面我们来看一下 TLB 是如何工作的。

当一个 MMU 中的虚拟地址需要进行转换时，硬件首先检查虚拟页号与 TLB 中所有表项进行并行匹配，判断虚拟页是否在 TLB 中。如果找到了有效匹配项，并且要进行的访问操作没有违反保护位的话，则将页框号直接从 TLB 中取出而不用再直接访问页表。如果虚拟页在 TLB 中但是违反了保护位的权限的话（比如只允许读但是是一个写指令），则会生成一个`保护错误(protection fault)` 返回。上面探讨的是虚拟地址在 TLB 中的情况，那么如果虚拟地址不再 TLB 中该怎么办？如果 MMU 检测到没有有效的匹配项，就会进行正常的页表查找，然后从 TLB 中逐出一个表项然后把从页表中找到的项放在 TLB 中。当一个表项被从 TLB 中清除出，将修改位复制到内存中页表项，除了访问位之外，其他位保持不变。当页表项从页表装入 TLB 中时，所有的值都来自于内存。

下面给出流程图：

<img src="https://s2.loli.net/2022/08/14/dWTfKnlxpzNi8hP.png" alt="img" style="zoom: 33%; float: left;" />

**软件 TLB 管理**

直到现在，我们假设每台电脑都有可以被硬件识别的页表，外加一个 TLB。在这个设计中，TLB 管理和处理 TLB 错误完全由硬件来完成。仅仅当页面不在内存中时，才会发生操作系统的`陷入(trap)`。

但是有些机器几乎所有的页面管理都是在软件中完成的。

在这些计算机上，TLB 条目由操作系统显示加载。当发生 TLB 访问丢失时，**不再是由 MMU 到页表中查找并取出需要的页表项，而是生成一个 TLB 失效并将问题交给操作系统解决**。操作系统必须找到该页，把它从 TLB 中移除（移除页表中的一项），然后把新找到的页放在 TLB 中，最后再执行先前出错的指令。然而，所有这些操作都必须通过少量指令完成，因为 TLB 丢失的发生率要比出错率高很多。

无论是用硬件还是用软件来处理 TLB 失效，常见的方式都是找到页表并执行索引操作以定位到将要访问的页面，在软件中进行搜索的问题是保存页表的页可能不在 TLB 中，这将在处理过程中导致其他 TLB 错误。改善方法是可以在内存中的固定位置维护一个大的 TLB 表项的高速缓存来减少 TLB 失效。通过首先检查软件的高速缓存，`操作系统` 能够有效的减少 TLB 失效问题。

TLB 软件管理会有两种 TLB 失效问题，当一个页访问在内存中而不在 TLB 中时，将产生 `软失效(soft miss)`，那么此时要做的就是把页表更新到 TLB 中（我们上面探讨的过程），而不会产生磁盘 I/O，处理仅仅需要一些机器指令在几纳秒的时间内完成。然而，当页本身不在内存中时，将会产生`硬失效(hard miss)`，那么此时就需要从磁盘中进行页表提取，硬失效的处理时间通常是软失效的百万倍。在页表结构中查找映射的过程称为 `页表遍历(page table walk)`。如图：

<img src="https://s2.loli.net/2022/08/14/D49RITltVkQBxL3.png" alt="img" style="zoom:33%;float:left" />

上面的这两种情况都是理想情况下出现的现象，但是在实际应用过程中情况会更加复杂，未命中的情况可能既不是硬失效又不是软失效。一些未命中可能更`软`或更`硬`。比如，如果页表遍历的过程中没有找到所需要的页，那么此时会出现三种情况：

1. 所需的页面就在内存中，但是却没有记录在进程的页表中，这种情况可能是由其他进程从磁盘掉入内存，这种情况只需要把页正确映射就可以了，而不需要在从硬盘调入，这是一种软失效，称为 `次要缺页错误(minor page fault)`。
2. 基于上述情况，如果需要从硬盘直接调入页面，这就是`严重缺页错误(major page falut)`。
3. 还有一种情况是，程序可能访问了一个非法地址，根本无需向 TLB 中增加映射。此时，操作系统会报告一个 `段错误(segmentation fault)` 来终止程序。只有第三种缺页属于程序错误，其他缺页情况都会被硬件或操作系统以降低程序性能为代价来修复

## 解决内存太大问题

上面引入TLB加快虚拟地址到物理地址的转换，另一个要解决的问题就是处理巨大的虚拟空间，有两种解决方法：多级页表和倒排页表。

#### 多级页表

> 从整体来过一遍虚拟地址的概念，虚拟存储器的基本思想是：程序、数据和堆栈的总大小可能超过可用的物理内存的大小。由操作系统把程序当前使用的那些部分保留在主存中，而把其他部分保存在磁盘上。例如，对于一个16MB的程序，通过仔细地选择在每个时刻将哪4MB内容保留在内存中，并在需要时在内存和磁盘间交换程序的片段，这样这个程序就可以在一个4MB的机器上运行。
>
> 由程序产生的地址被称为虚拟地址，它们构成了一个虚拟地址空间。在使用虚拟存储器的情况下，虚拟地址不是被直接送到内存总线上，而且是被送到内存管理单元(Memory  Management Unt,MMU)，MMU把虚拟地址映射为物理内存地址。
>
> 虚拟地址空间以页面为单位划分。在物理内存中对应的单位称为页帧。页面和页帧的大小总是一样的。

- **页表在哪儿**

  任何进程的切换都会更换活动页表集，Linux中为每一个进程维护了一个tast_struct结构体（进程描述符PCB），其中tast_struct->mm_struct结构体成员用来保存该进程页表。在进程切换的过程中，内核把新的页表的地址写入CR3控制寄存器。CR3中含有页目录表的物理内存基地址，如下图：

  <img src="https://s2.loli.net/2022/08/14/eBafURrZNoKQGWT.jpg" alt="img" style="float: left;" />

- **为什么省空间？**

  假如每个进程都有4GB的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到4GB，何必去映射不可能用到的空间呢？一级页表覆盖了整个4GB虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。

  如果每个页表项都存在对应的映射地址那也就算了，但是，绝大部分程序仅仅使用了几个页，也就是说，只需要几个页的映射就可以了，如下图（左），进程1的页表，只用到了0,1,1024三个页，剩下的1048573页表项是空的，这就造成了巨大的浪费，为了避免内存浪费，计算机系统开发人员想出了一个方案，多级页表。

  <img src="https://s2.loli.net/2022/01/11/cvkzM8LfD1ZWmVF.png" alt="页表是啥以及为啥多级页表能够节省空间_页表项" style="zoom: 33%;" /><img src="https://s2.loli.net/2022/08/14/P7wSgfFzGpeUyHC.png" alt="02" style="zoom: 50%;" />

  下面计算一下上图（右）的内存占用情况，对于一级页表来说，假设一个表项是4B，则

  一级页表占用：1024 * 4 B= 4K

  2级页表占用 = (1024 * 4 B) * 2 = 8K。

  总共的占用情况是 12K，相比只有一个页表 4M，节省了99.7%的内存占用。

  **因此引入多级页表的原因就是避免把全部页表一直保存在内存中。**

- **《深入理解计算机操作系统》 中的解释**

  <img src="https://s2.loli.net/2022/08/14/zfxEt5rRb47YVqh.png" alt="img" style="zoom: 80%;float:left" />

  假设32位的虚拟地址被划分为10位的PT1域、10位的PT2域和12位的偏移量域，工作过程如下：当一个虚拟地址被送到MMU时，MMU首先提取PT1域并把该值作为访问顶级页表的索引。由于虚拟空间为32G，顶级页表有2^10(PT1)^=1024个表项，则二级页表有2^10(PT2)^=1024个表项，每一个二级页表都含有虚拟地址对应物理地址的页框号，该页框号与偏移量结合便形成物理地址，放到地址总线送入内存中。

  如果没有多级页表，则32位虚拟内存应该有100万个页面，这个存储开销是很大的，而有了多级页表，则实际只需要4个页表，顶级页表、0、1、1024这四个，顶级页表中的其他表项的“在/不在”为被设置为0，访问他们是强制产生一个缺页中断。

#### 倒排页表

针对不断分级的页表的替代方案是**倒排页表**，实际内存中的每个页框对应一个表项，而不是每个虚拟页面对应一个表项。

对于64位虚拟地址，4KB的页，4GB的RAM，一个倒排页表仅需要1048576个表项。

由于4KB的页面，因此需要2^64^/2^12^=2^52^个页面，但是1GB物理内存只能有2^18^个4KB页框

> 虽然倒排页表节省了大量的空间，但是它也有自己的缺陷：那就是从虚拟地址到物理地址的转换会变得很困难。当进程 n 访问虚拟页面 p 时，硬件不能再通过把 p 当作指向页表的一个索引来查找物理页。而是必须搜索整个倒排表来查找某个表项。另外，搜索必须对每一个内存访问操作都执行一次，而不是在发生缺页中断时执行。解决这一问题的方式时使用 TLB。当发生 TLB 失效时，需要用软件搜索整个倒排页表。一个可行的方式是建立一个散列表，用虚拟地址来散列。当前所有内存中的具有相同散列值的虚拟页面被链接在一起。如下图所示
>
> 如果散列表中的槽数与机器中物理页面数一样多，那么散列表的冲突链的长度将会是 1 个表项的长度，这将会大大提高映射速度。一旦页框被找到，新的（虚拟页号，物理页框号）就会被装在到 TLB 中。
>
> <img src="https://s2.loli.net/2022/08/14/TujXUp9YxwOdDGe.png" alt="img" style="zoom: 47%;float:left" />
>
> 
>
> 



# 逻辑地址到物理地址的转换

页式存储管理的逻辑地址分为两部分：页号和页内地址。物理地址分为两部分：块号＋页内地址；

逻辑地址＝　页号＋页内地址

物理地址＝　块号＋页内地址；

**举例子**

某虚拟存储器的用户编程空间共32个页面，每页为1KB，内存为16KB。假定某时刻一用户页表中已调入内存的页面的页号和物理块号的对照表如下，则逻辑地址0A5C(H)所对应的物理地址是什么？要求：写出主要计算过程。 

| 页号 | 物理块号 |
| ---- | -------- |
| 0    | 3        |
| 1    | 7        |
| 2    | 11       |
| 3    | 8        |

**解答**

用户编程空间共32个页面，$2^5 = 32$得知页号部分占５位，由“每页为1KB”，$1K=2^{10}$，可知内页地址占10位。

由“内存为16KB”，$2^4 = 16$得知块号占4位。

然后找页号部分，转换成二进制查表，得到物理块号，然后转为二进制拼接页内地址就ok了。

逻辑地址0A5C（H）所对应的二进制表示形式是：００００１０１００１０１１１００，后十位１００１０１１１００是页内地址，

０００１０为为页号，页号化为十进制是２，在对照表中找到２对应的物理块号是１１,１１转换二进制是１０１１，即可求出物理地址为１０１１１００１０１１１００，化成十六进制为２Ｅ５Ｃ；

即则逻辑地址0A5C(H)所对应的物理地址是２Ｅ５Ｃ；



# 页面置换算法

**缺页中断：**一个进程所有地址空间里的页面不必全部常驻内存，在执行一条指令时，如果发现他要访问的页没有在内存中（即存在位为0），那么停止该指令的执行，并产生一个页不存在的异常，对应的故障处理程序可通过从物理内存加载该页的方法来排除故障，之后，原先引起的异常的指令就可以继续执行，而不再产生异常。

- 最佳页面置换算法（*OPT*）（理想算法）

  最佳页面置换算法基本思路是，置换在「未来」最长时间不访问的页面。所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。

- 先进先出置换算法（*FIFO*）

  选择在内存驻留时间很长的页面进行中置换

- 最近最久未使用的置换算法（*LRU*）

  发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。

  虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。

- 时钟页面置换算法（*Lock*）

  把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。

  当发生缺页中断时，算法首先检查表针指向的页面：

  - 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
  - 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

- 最不常用置换算法（*LFU*）

  当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。

  要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。



# 对缺页中断的处理

1. 硬件陷入内核，在堆栈中保存程序计数器。大多数机器将当前的指令，各种状态信息保存在特殊的CPU寄存器中。

2. 启动一个汇编代码保存通用寄存器和其他易失信息，防止被操作系统破坏

3. 当操作系统收到缺页中断信号后，定位到需要的虚拟页面。

4. 找到发生缺页中断的虚拟地址，操作系统检查这个地址是否有效，并检查存取与保护是否一致。

   如果不一致则杀掉该进程

   如果地址有效且没有保护错误发生，系统会检查是否有空闲页框。如果没有空闲页框就执行页面置换算法淘汰一个页面。

5. 如果选择的页框对应的页面发生了修改，即为“脏页面”，需要写回磁盘，并发生一次上下文切换，挂起产生缺页中断的进程，让其他进程运行直至全部把内容写到磁盘。

6. 一旦页框是干净的，则OS会查找要发生置换的页面对应磁盘上的地址，通过磁盘操作将其装入。在装入该页面的时候，产生缺页中断的进程仍然被挂起，运行其他可运行的进程

7. 当发生磁盘中断时表明该页面已经被装入，页表已经更新可以反映其位置，页框也被标记为正常状态。

8. 恢复发生缺页中断指令以前的状态，程序计数器重新指向引起缺页中断的指令

9. 调度引发缺页中断的进程

10. 该进程恢复寄存器和其他状态信息，返回用户空间继续执行。



# Linux可执行文件如何装载进虚拟内存

源代码通过预处理，编译，汇编，链接后形成可执行文件，因为计算机的操作系统的启动程序是写死在硬件上的，每次计算机上电时，都将自动加载启动程序，之后的每一个程序，每一个应用，都是不断的 fork 出来的新进程。那么我们的可执行文件，以linux 系统为例，也是由shell 进程 fork 出一个新进程，在新进程中调用exec函数装载我们的可执行文件并执行。

1. execve()。当shell中敲入执行程序的指令之后，shell进程获取到敲入的指令，并执行execve()函数，该函数的参数是敲入的可执行文件名和形参，还有就是环境变量信息。execve()函数对进程栈进行初始化，即压栈环境变量值，并压栈传入的参数值，最后压栈可执行文件名。初始化完成后调用 sys_execve()

2. sys_execve()。该函数进行一些参数的检查与复制，而后调用 do_execve()

3. do_execve()。该函数在当前路径与环境变量的路径中寻找给定的可执行文件名，找到文件后读取该文件的前128字节。读取这128个字节的目的是为了判断文件的格式，每个文件的开头几个字节都是魔数，可以用来判断文件类型。读取了前128字节的文件头部后，将调用 search_binary_handle()

4. search_binary_handle()。该函数将去搜索和匹配合适的可执行文件装载处理程序。Linux 中所有被支持的可执行文件格式都有相应的装在处理程序。以Linux 中的ELF 文件为例，接下来将会调用elf 文件的处理程序：load_elf_binary()

5. load_elf_binary()。

   该函数执行以下三个步骤:

   a）创建虚拟地址空间：实际上指的是建立从虚拟地址空间到物理内存的映射函数所需要的相应的数据结构。（即创建一个空的页表）

   b）读取可执行文件的文件头，建立可执行文件到虚拟地址空间之间的映射关系

   c）将CPU指令寄存器设置为可执行文件入口（虚拟空间中的一个地址）

   load_elf_binary()函数执行完毕，事实上装载函数执行完毕后，可执行文件真正的指令和数据都没有被装入内存中，只是建立了可执行文件与虚拟内存之间的映射关系，以及分配了一个空的页表，用来存储虚拟内存与物理内存之间的映射关系。

6. 程序返回到execve()中。此时从内核态返回到用户态，且寄存器的地址被设置为了ELF 的入口地址，于是新的程序开始启动，发现程序入口对应的页面并没有加载（因为初始时是空页面），则此时引发一个缺页错误，操作系统根据可执行文件和虚拟内存之间的映射关系，在磁盘上找到缺的页，并申请物理内存，将其加载到物理内存中，并在页表中填入该虚拟内存页与物理内存页之间的映射关系。之后程序正常运行，直至结束后回到shell 父进程中，结束回到 shell。



# 说一说内存对齐

- 由一个例子引出内存对齐

  ```c
  //32位系统
  #include<stdio.h>
  struct{
      int x;
      char y;
  }s;
  
  int main()
  {
      printf("%d\n",sizeof(s);  // 输出8
      return 0;
  }
  ```

  上述代码实际得到的值是8byte，这就是内存对齐所导致的。

  > 从理论上来讲，任何类型的变量可以从任意地址开始存放。但是实际上计算机对基本数据类型在内存中的存放位置有限制，会要求数据首地址的值是某个数（通常是4或8）的整数倍，这就是内存对齐。

- 为什么要内存对齐呢？

  计算机的内存是以字节为单位的，但是大部分处理器并不是按照字节块来存取内存的。计算机有个内存存取粒度的概念，就是说一般以2字节，4字节，8字节这样的单位来存取内存。

  性能原因：加入没有内存对齐机制，数据可以任意存放。地址排列为01234567现在读取一个int型变量，这个变量存放地址从1开始，那我们从0字节开始找，找到1后读取第一个4字节，把0扔掉，然后从地址4开始读下4个字节，扔掉567地址，int变量就存储在1234这里，可以看到这样很浪费开销，因为访问了两次内存。

- 内存对齐的规则

  对其规则如下：

  1. 基本类型的对齐值就是sizeof值。如果该成员是c++自带类型如int、char、double等，那么其对齐字节数=该类型在内存中所占的字节数；如果该成员是自定义类型如某个class或者struct，那个它的对齐字节数 = 该类型内最大的成员对齐字节数
  2. 结构体。结构体本身也要对齐，按照最大成员长度来参照的。
  3. 编译器可以设置最大对齐值，gcc中默认是#pragma pack(4)。但是类型的实际对齐值与默认对齐值取最小值来
  3. 如果设置了对齐字节数，就另说。①如果定义的字节数为1，就是所有默认字节数直接相加。②定义的字节数大于任何一个成员大小时候，不产生任何效果。如果定义的对齐字节数大于结构体内最小的，小于结构体内最大的话，就按照定义的字节数来计算



# 内存空间的堆和栈的区别是什么？

- 程序内存布局场景下，堆与栈表示两种内存管理方式；

  - 栈是由操作系统自动分配的，用于存放函数参数值，局部变量。存储在栈中的数据的生命周期随着函数的执行结束而结束。栈的内存生长方向与堆相反，由高到低，按照变量定义的先后顺序入栈。

  - 堆是由用户自己分配的。如果用户不回收，程序结束后由操作系统自动回收。堆的内存地址生长方向与栈相反，由低到高。

    > **堆上分配内存的过程：**
    >
    > 操作系统有一个记录空闲内存地址的链表，当系统收到程序的开辟内存申请时候，会遍历该链表，寻找第一个空间大于所申请内存空间的节点。接着把该节点从空闲链表中删除，同时将该空间分配出去给程序使用。同时大多数系统会在内存空间中的首地址记录此次分配的大小，这样delete才能正确释放内存空间。由于找到的节点所对应的内存大小不一定正好等于申请内存的大小，OS会自动的将多余的部分放入空闲链表。

  - 堆与栈区别的总结

    1. 管理方式不同
    2. 空间大小不同
    3. 分配方式不同。堆都是动态分配。栈的静态分配由操作系统完成，回收也是自动的。栈的动态分配有alloca函数分配，由操作系统自动回收。
    4. 分配效率不同。栈由操作系统自动分配，会在硬件层级对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是由C/C++提供的库函数或运算符来完成申请与管理，实现机制较为复杂，频繁的内存申请容易产生内存碎片。显然，堆的效率比栈要低得多。

- 数据结构场景下，堆与栈表示两种常用的数据结构。

  栈是线性结构

  堆是一种特殊的完全二叉树

**内存为什么要分堆栈在编程里，要是全部只用堆或者全部只用栈可以吗**

程序的结构是前部是栈，中部是程序体，后部是堆。前部和中部是链接的时候由编译器算好了的，执行过程中是固定不变的。而后部则可以随着程序的执行而改变长度。

栈是用来存储程序初期设定的变量的，这些变量在程序执行之前就要准备好。因此栈要放在程序的前部并且固定位置，否则程序就不知道该到那里去找这些变量。而程序的运行结果往往是不能预先确定的，所以把堆放在后部以便可以提供足够的内存保存运算结果。



# 进程虚拟空间是怎么布局的？进程内存模型

linux进程在32位处理器下的虚拟空间内存布局，从高地址到低地址

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210831210023.png" alt="img" style="zoom:87%;float:left" />

- 内核空间，从C000000-FFFFFFFF

- 栈区。有以下用途

  1. 存储函数局部变量
  2. 记录函数调用过程的相关信息，成为栈帧，主要包括函数返回地址，一些不适合放在寄存器中的函数参数。
  3. 临时存储区，暂存算术表达式的计算结果和allocation函数分配的栈内存。

- 内存映射段（mmap）。内核将硬盘文件的内容直接映射到内存，是一种方便高校的文件I/O方式，用于装在动态共享库。

- 堆。分配的堆内存是经过字节对齐的空间，以适合原子操作。堆管理器通过链表管理每个申请的内存，由于堆申请和释放是无序的，最终会产生内存碎片。堆内存一般由应用程序分配释放，回收的内存可供重新使用。若程序员不释放，程序结束时操作系统可能会自动回收。

- BSS段。通常存放以下内容：

  1. 未初始化的全局变量和静态局部变量
  2. 初始化值为0的全局变量和静态局部变量
  3. 未定义且初值不为0的符号

- 数据段。通常存放程序中已经初始化且初值不为0的全局变量。数据段属于静态存储区，可读可写。

  数据段和BSS段的区别如下：

  1. BSS段不占用物理文件尺寸，但占用内存空间（不在可执行文件中）。数据段在可执行文件中，也占用内存空间。
  2. 当程序读取数据段的数据时候，系统会发生缺页故障，从而分配物理内存。当程序读取BSS段数据的时候，内核会将其转到一个全零页面，不会发生缺页故障，也不会为期分配物理内存。
  3. bss是不占用.exe文件（可执行文件）空间的，其内容由**操作系统初始化**（清零）；而data却需要占用，其内容由**程序初始化**，因此造成了上述情况。

- 代码段。代码段也称正文段或文本段，通常用于存放程序执行代码(即CPU执行的机器指令)。一般C语言执行语句都编译成机器代码保存在代码段。通常代码段是可共享的，因此频繁执行的程序只需要在内存中拥有一份拷贝即可。

- 保留区。位于虚拟地址空间的最低部分，未赋予物理地址。任何对它的引用都是非法的，用于捕捉使用空指针和小整型值指针引用内存的异常情况。



# 系统调用和进程上下文切换的区别

系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。这跟我们通常所说的进程上下文切换是不一样的：

进程上下文切换，是指从一个进程切换到另一个进程运行；而系统调用过程中一直是同一个进程在运行。

# 上下文切换

>  **CPU 寄存器和程序计数器就是 CPU 上下文，因为它们都是 CPU 在运行任何任务前，必须的依赖环境。**
>
>  - CPU 寄存器是 CPU 内置的容量小、但速度极快的内存。
>  - 程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。

## 什么是CPU上下文切换

就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

## CPU 上下文切换的类型

- **进程上下文切换**

  1. .切换页目录以使用新的地址空间
  2. 切换内核栈
  3. 切换硬件上下文
  4. 刷新TLB
  5. 系统调度器的代码执行

  

- **线程上下文切换** 

  **两个线程属于不同进程**
  
  前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。
  
  **两个线程属于相同进程**
  
  线程上下文切换和进程上下文切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，
  但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。
  内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。
  
  另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。
      简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。
  
- **中断上下文切换**

  为了快速响应硬件的事件,中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。

  **中断上下文切换并不涉及到进程的用户态**。即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。只需要关注内核资源就行，CPU寄存器，内核堆栈，硬件中断参数啥的。

- **进程上下文切换的场景：**

  1. 时间片轮转技术下，该进程分配到的时间片耗尽，就会被系统挂起，切换到其他进程
  2. 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。
  3. 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。
  4. 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行
  5. 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。



# 什么是大端字节，什么是小端字节？如何转换字节序？

大端序，小端序是计算机存储数据的两种方式。

大端字节序：高位字节在前，低位字节在后，符合人类读写数值的习惯（参考普通的十进制数）

小端字节序：低位字节在前，高位字节在后。

- 为什么要有大小端字节序？统一不行吗？

  答：①内存的低地址处存放低字节，所以在强制转换数据时不需要调整字节的内容（注解：比如把int的4字节强制转换成short的2字节时，就直接把int数据存储的前两个字节给short就行，因为其前两个字节刚好就是最低的两个字节，符合转换逻辑）；②CPU做数值运算时从内存中依顺序依次从低位到高位取数据进行运算，直到最后刷新最高位的符号位，这样的运算方式会更高效。但是大端序更符合人类的习惯，主要用在网络传输和文件存储方面，符号位在所表示的数据的内存的第一个字节中，便于快速判断数据的正负和大小。

  其各自的优点就是对方的缺点，正因为两者彼此不分伯仲，再加上一些硬件厂商的坚持，因此在多字节存储顺序上始终没有一个统一的标准

- 转换字节序

  主要是针对主机字节序和网络字节序来说的。我们用的x86架构的处理器一般都是小端序存储数据，但是网络字节序是TCP/IP中规定好的数据表示格式，RFC1700规定使用“大端”字节序为网络字节序，独立于处理器操作系统。

  在Linux网络编程中，会使用下列C标准库函数进行字节之间的转换

  ```c
  #include <arpa/inet.h>
  
  uint32_t htonl(uint32_t hostlong);		//把uint32_t类型从主机序转换到网络序
  uint16_t htons(uint16_t hostshort);		//把uint16_t类型从主机序转换到网络序
  uint32_t ntohl(uint32_t netlong);		//把uint32_t类型从网络序转换到主机序
  uint16_t ntohs(uint16_t netshort);		//把uint16_t类型从网络序转换到主机序
  ```

- 如何判断本机是大端序还是小端序？

  ```c
  int i=1;   
  char *p=(char *)&i;   
  if(*p == 1)     
      printf("小端模式"); //小端序是低位字节在前，高位字节在后
  else // (*p == 0)
      printf("大端模式");
  ```



# 操作系统是怎么进行进程管理的？

![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210901111845.jpeg)

如果问到进程管理，就从进程通信，同步和死锁三大块来说！

- [进程间通信](# 进程间通信方式)
- [进程同步](#进程同步)
- [死锁](#死锁)
- [进程调度](#CPU调度算法（进程调度算法）)



# mmap（内存映射）

## 什么是mmap？

mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203181050391.png" alt="img" style="float: left;" />

## mmap的过程—原理

1. 进程启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域
2. 调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系
3. 进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝

## mmap和常规文件操作的区别

常规文件的操作如下：

1. 进程发起读文件请求。
2. 内核查找文件描述符，定位到内核已打开的文件信息，找到文件的inode。
3. 查看文件页是否在缓存中，如果存在则直接返回这片页面
4. 如果不存在，缺页中断，需要定位到该文件的磁盘地址处，将数据从磁盘复制到页缓存中，然后发起页面读写过程，将页缓存中的数据发送给用户

常规文件需要先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，通过了两次数据拷贝过程，才能完成进程对文件内容的获取任务。

而使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。





# 共享内存的原理

共享内存可以说是最有用的进程间通信方式，也是最快的IPC形式。两个不同进程A、B共享内存的意思是，同一块物理内存被映射到进程A、B各自的进程地址空间。进程A可以即时看到进程B对共享内存中数据的更新，反之亦然。由于多个进程共享同一块内存区域，必然需要某种同步机制，互斥锁和信号量都可以。

这种 IPC 机制无需内核介入！

采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝(用户空间buf到内核，内核把数据拷贝到内存，内存拷贝到内核，内核到用户空间)，而共享内存则只拷贝两次数据(一次从输入文件到共享内存区，另一次从共享内存区到输出文件。)

实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。

**共享内存位于进程空间的什么位置？**

不同进程之间共享的内存通常为同一段物理内存。进程可以将同一段物理内存连接到他们自己的地址空间中，所有的进程都可以访问共享内存中的地址。

**共享内存段最大限制是多少？**

单个共享内存段最大字节数，一般为32M

共享内存段最大个数，一般为4096

系统中共享内存页总数默认值：2097152*4096=8GB

**共享内存不保证同步，可以使用信号量来保证共享内存同步**

> 注意共享内存和内存映射是不同的

[参考](https://www.colourso.top/linux-mmapshm/)



# 共享内存和内存映射的区别

1. 共享内存可以直接创建，内存映射需要磁盘文件（匿名映射除外）

2. 共享内存效率更高

3. 内存。

   共享内存，所有的进程操作的是同一块共享内存。

   内存映射，每个进程在自己的虚拟地址空间中有一个独立的内存。

4. 数据安全

   进程突然退出时，共享内存还存在，内存映射区消失

   运行进程的电脑死机，宕机时。在共享内存中的数据会消失。内存映射区的数据 ，由于磁盘文件中的数据还在，所以内存映射区的数据还存在。

5. 生命周期

   内存映射区：进程退出，内存映射区销毁

   共享内存：进程退出，共享内存还在，标记删除（所有的关联的进程数为0），或者关机
   如果一个进程退出，会自动和共享内存进行取消关联。



# malloc是如何实现内存管理的

[参考链接](https://jacktang816.github.io/post/mallocandfree/)

C语言中使用malloc可以分配一段连续的内存空间。在c/c++开发中，因为malloc属于C标准库函数，经常会使用其分配内存。malloc是在堆中分配一块可用内存给用户。作为一个使用频繁的基础函数，理解清楚其实现原理很有必要，因此本文主要探讨malloc的具体实现原理，以及在linux系统中这该函数的实现方式。

## 内存分配涉及到的系统调用

**跟brk/sbrk/mmap这三个系统调用函数有关**

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203181113652.png" style="zoom:80%;float:left" />

上图是一个堆内存的分布，其实在堆内存有三段空间，第一段是映射好的，指针可以访问的；第二段是未映射的地址空间，访问这段空间会报错；第三段是无法使用的空间。其中映射好的空间和未映射的空间由一个brk指针分割。所以如果要增加实际堆的可用大小，就可以移动brk指针。

**brk()和sbrk()** 

要增加一个进程实际的可用堆大小，就需要将break指针向高地址移动。Linux通过**brk和sbrk系统调用**操作break指针。两个系统调用的原型如下：

```c+
#include <unistd.h>
int brk(void *addr);
void *sbrk(intptr_t increment);
```

brk函数将break指针直接设置为某个地址，而sbrk将break指针从当前位置移动increment所指定的增量。所以我们使用sbrk获得brk的地址。brk在执行成功时返回0，否则返回-1并设置errno为ENOMEM；sbrk成功时返回break指针移动之前所指向的地址，否则返回(void *)-1。

**mmap函数：**mmap函数第一种用法是映射磁盘文件到内存中；而malloc使用的mmap函数的第二种用法，即匿名映射，匿名映射不映射磁盘文件，而是向映射区申请一块内存。当申请小内存的时，malloc使用sbrk分配内存；当申请大内存时，使用mmap函数申请内存；但是这只是分配了虚拟内存，还没有映射到物理内存，当访问申请的内存时，才会因为缺页异常，内核分配物理内存。

##  malloc实现方案

由于brk/sbrk/mmap属于系统调用，如果每次申请内存，都调用这三个函数中的一个，那么每次都要产生系统调用开销（即cpu从用户态切换到内核态的上下文切换，这里要保存用户态数据，等会还要切换回用户态），这是非常影响性能的；其次，这样申请的内存容易产生碎片，因为堆是从低地址到高地址，如果低地址的内存没有被释放，高地址的内存就不能被回收。鉴于此，**malloc采用的是内存池的实现方式**，malloc内存池实现方式更类似于STL分配器和memcached的内存池，先申请一大块内存，然后将内存分成不同大小的内存块，然后用户申请内存时，直接从内存池中选择一块相近的内存块即可。

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/bins.png" alt="img" style="float: left;" />

如上图，内存池保存在bins这个长128的数组中，每个元素都是一双向个链表。

malloc将内存分成了大小不同的chunk，然后通过bins来组织起来。malloc将相似大小的chunk（图中可以看出同一链表上的chunk大小差不多）用双向链表链接起来，这样一个链表被称为一个bin。malloc一共维护了128个bin，并使用一个数组来存储这些bin。数组中第一个为**unsorted bin**，数组编号前2到前64的bin为**small bins**，同一个small bin中的chunk具有相同的大小，两个相邻的small bin中的chunk大小相差8bytes。small bins后面的bin被称作**large bins**。large bins中的每一个bin分别包含了一个给定范围内的chunk，其中的chunk按大小序排列。large bin的每个bin相差64字节。

malloc除了有unsorted bin，small bin，large bin三个bin之外，还有一个**fast bin**。一般的情况是，程序在运行时会经常需要申请和释放一些较小的内存空间。当分配器合并了相邻的几个小的 chunk 之后，也许马上就会有另一个小块内存的请求，这样分配器又需要从大的空闲内存中切分出一块，这样无疑是比较低效的，故而，malloc 中在分配过程中引入了 fast bins，不大于 max_fast(默认值为 64B)的 chunk 被释放后，首先会被放到 fast bins中，fast bins 中的 chunk 并不改变它的使用标志 P。这样也就无法将它们合并，当需要给用户分配的 chunk 小于或等于 max_fast 时，malloc 首先会在 fast bins 中查找相应的空闲块，然后才会去查找 bins 中的空闲 chunk。在某个特定的时候，malloc 会遍历 fast bins 中的 chunk，将相邻的空闲 chunk 进行合并，并将合并后的 chunk 加入 unsorted bin 中，然后再将 unsorted bin 里的 chunk 加入 bins 中。

unsorted bin 的队列使用 bins 数组的第一个，如果被用户释放的 chunk 大于 max_fast，或者 fast bins 中的空闲 chunk 合并后，这些 chunk 首先会被放到 unsorted bin 队列中，在进行 malloc 操作的时候，如果在 fast bins 中没有找到合适的 chunk，则malloc 会先在 unsorted bin 中查找合适的空闲 chunk，然后才查找 bins。如果 unsorted bin 不能满足分配要求。 malloc便会将 unsorted bin 中的 chunk 加入 bins 中。然后再从 bins 中继续进行查找和分配过程。从这个过程可以看出来，**unsorted bin 可以看做是 bins 的一个缓冲区，增加它只是为了加快分配的速度。**（其实感觉在这里还利用了局部性原理，常用的内存块大小差不多，从unsorted bin这里取就行了，这个和TLB之类的都是异曲同工之妙啊！）

除了上述四种bins之外，malloc还有三种内存区。

- 当fast bin和bins都不能满足内存需求时，malloc会设法在**top chunk**中分配一块内存给用户；top chunk为在mmap区域分配一块较大的空闲内存模拟sub-heap。（比较大的时候） >top chunk是堆顶的chunk，堆顶指针brk位于top chunk的顶部。移动brk指针，即可扩充top chunk的大小。当top chunk大小超过128k(可配置)时，会触发malloc_trim操作，调用sbrk(-size)将内存归还操作系统。
- 当chunk足够大，fast bin和bins都不能满足要求，甚至top chunk都不能满足时，malloc会从mmap来直接使用内存映射来将页映射到进程空间，这样的chunk释放时，直接解除映射，归还给操作系统。（极限大的时候）
- Last remainder是另外一种特殊的chunk，就像top chunk和mmaped chunk一样，不会在任何bins中找到这种chunk。当需要分配一个small chunk,但在small bins中找不到合适的chunk，如果last remainder chunk的大小大于所需要的small chunk大小，last remainder chunk被分裂成两个chunk，其中一个chunk返回给用户，另一个chunk变成新的last remainder chunk。（这个应该是fast bins中也找不到合适的时候，用于极限小的）

由之前的分析可知malloc利用chunk结构来管理内存块，malloc就是由不同大小的chunk链表组成的。malloc会给用户分配的空间的前后加上一些控制信息，用这样的方法来记录分配的信息，以便完成分配和释放工作。chunk指针指向chunk开始的地方,图中的mem指针才是真正返回给用户的内存指针。

## malloc 内存分配流程

1. 如果分配内存<512字节，则通过内存大小定位到smallbins对应的index上(floor(size/8))
   - 如果smallbins[index]为空，进入步骤3
   - 如果smallbins[index]非空，直接返回第一个chunk
2. 如果分配内存>512字节，则定位到largebins对应的index上
   - 如果largebins[index]为空，进入步骤3
   - 如果largebins[index]非空，扫描链表，找到第一个大小最合适的chunk，如size=12.5K，则使用chunk B，剩下的0.5k放入unsorted_list中
3. 遍历unsorted_list，查找合适size的chunk，如果找到则返回；否则，将这些chunk都归类放到smallbins和largebins里面
4. index++从更大的链表中查找，直到找到合适大小的chunk为止，找到后将chunk拆分，并将剩余的加入到unsorted_list中
5. 如果还没有找到，那么使用top chunk
6. 或者，内存<128k，使用brk；内存>128k，使用mmap获取新内存

此外，调用free函数时，它将用户释放的内存块连接到空闲链上。到最后，空闲链会被切成很多的小内存片段，如果这时用户申请一个大的内存片段，那么空闲链上可能没有可以满足用户要求的片段了。于是，malloc函数请求延时，并开始在空闲链上翻箱倒柜地检查各内存片段，对它们进行整理，将相邻的小空闲块合并成较大的内存块。

## 内存碎片

free释放内存时，有两种情况：

1. chunk和top chunk相邻，则和top chunk合并
2. chunk和top chunk不相邻，则直接插入到unsorted_list中

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/topChunk.png" alt="img" style="float: left;" />

如上图示: top chunk是堆顶的chunk，堆顶指针brk位于top chunk的顶部。移动brk指针，即可扩充top chunk的大小。当top chunk大小超过128k(可配置)时，会触发malloc_trim操作，调用sbrk(-size)将内存归还操作系统。

以上图chunk分布图为例，按照glibc的内存分配策略，我们考虑下如下场景(假设brk其实地址是512k)：

malloc 40k内存，即chunkA，brk = 512k + 40k = 552k malloc 50k内存，即chunkB，brk = 552k + 50k = 602k malloc 60k内存，即chunkC，brk = 602k + 60k = 662k free chunkA。

此时，由于brk = 662k，而释放的内存是位于[512k, 552k]之间，无法通过移动brk指针，将区域内内存交还操作系统，因此，在[512k, 552k]的区域内便形成了一个内存空洞即内存碎片。 按照glibc的策略，free后的chunkA区域由于不和top chunk相邻，因此，无法和top chunk 合并，应该挂在unsorted_list链表上。



# 信号量和互斥量的区别？

我觉得主要区别在两方面：**第一方面是所有权的概念，第二个方面是用途。**

- 先说第一个所有权。

  解铃还须系铃人，一个锁住临界区的锁必须由上锁的线程解开，因此mutex的功能也就限制在了构造临界区上。

  对于信号量来说，任意多线程都可以对信号量执行PV操作。

- 第二个是用途

  也就是同步和互斥的用处。

  互斥很好说了，当我占有使用权的时候别人不能进入，独占式访问某段程序和内存。

  同步就是**调度线程**，即一些线程生产一些线程消费，让生产和消费线程保持合理执行顺序。因为semaphore本意是信号灯，含量了通知的意味，只要是我的信号量值大于等于1，那么就可以有线程或者进程来使用。

  『同步』这个词也可以拆开看，一侧是等待数据的『事件』或者『通知』，一侧是保护数据的 『临界区』，所以同步也即**同步+互斥**。信号量可以满足这两个功能，但是可以注意到两个功能的应用场景还是蛮大的，有 **do one thing and do it best** 的空间。linux 内核曾将 semaphore 作为同步原语，后面代码变得较难维护，刷了一把 mutex 变简单了不少还变快了，需要『通知』 的场景则替换为了 completion variable。

- 举个例子

  公司的咖啡机，互斥就是我一个人独占咖啡机，做完了咖啡然后撤走，咖啡机可以被别人使用。

  信号量是同步+互斥，有一个人不停地生产咖啡，每个人排队拿，如果有了就拿，没有了就阻塞等待。等有咖啡了唤醒阻塞的线程拿咖啡。

  所以更像是mutex+condition_variable

- 英文的解释

  > A [mutex](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Mutex)
  > is essentially the same thing as a binary semaphore and sometimes uses
  > the same basic implementation. The differences between them are in how
  > they are used. While a binary semaphore may be used as a mutex, a mutex
  > is a more specific use-case, in that only the thread that locked the
  > mutex is supposed to unlock it. This constraint makes it possible to
  > implement some additional features in mutexes:
  >
  > 1. Since only the thread that locked the mutex is supposed to unlock
  >    it, a mutex may store the id of thread that locked it and verify the
  >    same thread unlocks it.
  > 2. Mutexes may provide [priority inversion](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Priority_inversion)
  >    safety. If the mutex knows who locked it and is supposed to unlock it,
  >    it is possible to promote the priority of that thread whenever a
  >    higher-priority task starts waiting on the mutex.
  > 3. Mutexes may also provide deletion safety, where the thread holding the mutex cannot be accidentally deleted.
  > 4. Alternately, if the thread holding the mutex is deleted (perhaps due
  >    to an unrecoverable error), the mutex can be automatically released.
  > 5. A mutex may be recursive: a thread is allowed to lock it multiple times without causing a deadlock.



# 写时拷贝底层原理

在 Linux 系统中，调用 fork 系统调用创建子进程时，并不会把父进程所有占用的内存页复制一份，而是与父进程共用相同的内存页，而当子进程或者父进程对内存页进行修改时才会进行复制 —— 这就是著名的 写时复制 机制。如果有多个调用者同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。

传统的fork系统调用直接把所有资源复制给新创建的进程，这种实现过于简单并且效率低下，如果父进程中有很多数据的话依次复制个子进程，那么fork函数肯定是非常慢的。因此使用写时拷贝会快很多。

**原理**

首先要了解一下内存共享机制。不同进程的 虚拟内存地址 映射到相同的 物理内存地址，那么就实现了共享内存的机制。我们可以用用这种思想来实现写时拷贝。fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。这样父进程和子进程都有了属于自己独立的页。

子进程可以执行exec()来做自己想要的功能。



# 栈区分配内存快还是堆区分配内存快 ？

[参考链接](https://mp.weixin.qq.com/s/6I5TTh7zJ4NAn8YALUEtuw)

毫无疑问，显然从栈上分配内存更快，因为从栈上分配内存仅仅就是栈指针的移动而已

在堆区上申请与释放内存是一个相对复杂的过程，因为堆本身是需要程序员(内存分配器实现者)自己管理的，而栈是编译器来维护的，堆区的维护同样涉及内存的分配与释放，但这里的内存分配与释放显然不会像栈区那样简单，一句话，这里是**按需进行内存的分配与释放**，**本质在于堆区中每一块被分配出去的内存其生命周期都不一样**，这是由程序员决定的，我倾向于把内存动态分配释放想象成去停车场找停车位。



# 申请内存时底层发生了什么？

就是malloc如何实现内存管理的



# Cache

[参考链接](https://blog.csdn.net/wyttRain/article/details/110925923)

## 什么是cache

Cache存储器，是位于CPU和主存储器DRAM之间的一块高速缓冲存储器，规模较小，但是速度很快，通常由SRAM（静态存储器）组成。Cache的功能是提高CPU数据输入输出的速率。Cache容量小但速度快，内存速度较低但容量大，通过优化调度算法，可以让系统的性能大大改善，感觉就像是有了主存储器的内存，又有了Cache的访问速度。

## 工作方式

CPU在访问存储器的时候，会同时把虚拟地发送给MMU中的TLB以及Cache，CPU会在TLB中查找最终的RPN（Real Page Number），也就是真实的物理页面，如果找到了，就会返回相应的物理地址。同时，CPU通过cache编码地址中的Index，也可以很快找到相应的Cache line组，但是这个cache line 中存储的数据不一定是CPU所需要的，需要进一步检查，前面我们说了，如果TLB命中后，会返回一个真实的物理地址，将cache line中存放的地址和这个转换出来的物理地址进行比较，如果相同并且状态位匹配，那么就会发生cache命中。如果cache miss，那么CPU就需要重新从存储器中获取数据，然后再将其存放在cache line中。

## 多级cache存储结构

cache的速度在一定程度上同样影响着系统的性能。一般情况下cache的速度可以达到1ns，几乎可以和CPU寄存器速度媲美。但是，这就满足了人们对性能的追求了吗？并没有。当cache中没有缓存我们想要的数据的时候，依然需要漫长的等待从主存中load数据。为了进一步提升性能，引入多级cache。前面提到的cache，称为L1 cache（第一级cache）。我们在L1 cache后面连接L2 cache，在L2 cache和主存之间连接L3 cache。等级越高，速度越慢，容量越大。 但是速度和主存相比而言，依然很快。



# 内存屏障

[参考链接](https://blog.csdn.net/wyttRain/article/details/114520547?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_antiscanv2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_antiscanv2&utm_relevant_index=2)

现在大多数现代计算机为了提高性能而采取乱序执行，这可能会导致程序运行不符合我们预期，内存屏障就是一类同步屏障指令，是CPU或者编译器在对内存随机访问的操作中的一个同步点，只有在此点之前的所有读写操作都执行后才可以执行此点之后的操作。



# Fork函数相关知识

fork（）函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。

 一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。

**返回值**

fork调用的一个奇妙之处就是它仅仅被调用一次，却能够返回两次，它可能有三种不同的返回值：

1. 在父进程中，fork返回新创建子进程的进程ID；
2. 在子进程中，fork返回0；
3. 如果出现错误，fork返回一个负值；

**包含内容**

fork时子进程获得父进程数据空间、堆和栈的复制，所以变量的地址（当然是虚拟地址）也是一样的。

子进程与父进程之间除了代码是共享的之外，堆栈数据和全局数据均是独立的。

**写时复制**

fork子进程完全复制父进程的栈空间，也复制了页表，但没有复制物理页面，所以这时虚拟地址相同，物理地址也相同，但是会把父子共享的页面标记为“只读”（类似mmap的private的方式），如果父子进程一直对这个页面是同一个页面，知道其中任何一个进程要对共享的页面“写操作”，这时内核会复制一个物理页面给这个进程使用，同时修改页表。而把原来的只读页面标记为“可写”，留给另外一个进程使用。

**执行顺序**

fork之后内核会通过将子进程放在队列的前面，以让子进程先执行，以免父进程执行导致写时复制，而后子进程执行exec系统调用，因无意义的复制而造成效率的下降。

。正因为fork采用了这种写时复制的机制，所以fork出来子进程之后，父子进程哪个先调度呢？内核一般会先调度子进程，因为很多情况下子进程是要马上执行exec，会清空栈、堆。。这些和父进程共享的空间，加载新的代码段。。。，这就避免了“写时复制”拷贝共享页面的机会。如果父进程先调度很可能写共享页面，会产生“写时复制”的无用功。所以，一般是子进程先调度滴。





# fork复制内部，为什么fork返回0？

[参考链接](https://juejin.cn/post/6909074860761169933)

fork宏函数展开后代码

```c
int fork(void) \
{ \
    long __res; \
    __asm__ volatile ("int $0x80" \
        : "=a" (__res) \
        : "0" (__NR_fork)); \
    if (__res >= 0) \
        return (type) __res; \
    errno = -__res; \
    return -1; \
}
```

fork是一个宏，内部关键指令就是0x80中断，调用中断就会执行相应的中断服务程序 `kernel/sched.c`中的`sched_init`方法中就对0x80号中断进行了配置,就是说发生该中断就会调用`system_call`方法。会进入system_cal这个函数，然后有一个`sys_cal_table`。这个表就是一个系统调用函数表，存的都是函数指针。

```c
//sys_call_table位于linux/sys.h
fn_ptr sys_call_table[] = { sys_setup, sys_exit, sys_fork, ... };
```

根据索引找到sys_fork这个函数，能找到这个函数就是因为由寄存器eax传过来个值2，__NR_fork = 2,， 索引为2的函数指针就是sys_fork。

```c
sys_fork:
	call find_empty_process
	testl %eax,%eax             # 在eax中返回进程号pid。若返回负数则退出。
	js 1f
	push %gs
	pushl %esi
	pushl %edi
	pushl %ebp
	pushl %eax
	call copy_process
	addl $20,%esp               # 丢弃这里所有压栈内容。
1:	ret
```

 首先`find_empty_process`找到一个可用的进程id，这个可用的进程id在`%eax`里面，接者调用`copy_process`

```c
int copy_process(int nr,long ebp,long edi,long esi,long gs,long none,
		long ebx,long ecx,long edx,
		long fs,long es,long ds,
		long eip,long cs,long eflags,long esp,long ss)
{
	struct task_struct *p;
	int i;
	struct file *f;

    // 首先为新任务数据结构分配内存。如果内存分配出错，则返回出错码并退出。
    // 然后将新任务结构指针放入任务数组的nr项中。其中nr为任务号，由前面
    // find_empty_process()返回。接着把当前进程任务结构内容复制到刚申请到
    // 的内存页面p开始处。
	p = (struct task_struct *) get_free_page();
	if (!p)
		return -EAGAIN;
	task[nr] = p;
	*p = *current;	/* NOTE! this doesn't copy the supervisor stack */
    // 随后对复制来的进程结构内容进行一些修改，作为新进程的任务结构。先将
    // 进程的状态置为不可中断等待状态，以防止内核调度其执行。然后设置新进程
    // 的进程号pid和父进程号father，并初始化进程运行时间片值等于其priority值
    // 接着复位新进程的信号位图、报警定时值、会话(session)领导标志leader、进程
    // 及其子进程在内核和用户态运行时间统计值，还设置进程开始运行的系统时间start_time.
	p->state = TASK_UNINTERRUPTIBLE;
	p->pid = last_pid;              // 新进程号。也由find_empty_process()得到。
	p->father = current->pid;       // 设置父进程
	p->counter = p->priority;       // 运行时间片值
	p->signal = 0;                  // 信号位图置0
	p->alarm = 0;                   // 报警定时值(滴答数)
	p->leader = 0;		/* process leadership doesn't inherit */
	p->utime = p->stime = 0;        // 用户态时间和和心态运行时间
	p->cutime = p->cstime = 0;      // 子进程用户态和和心态运行时间
	p->start_time = jiffies;        // 进程开始运行时间(当前时间滴答数)
    // 再修改任务状态段TSS数据，由于系统给任务结构p分配了1页新内存，所以(PAGE_SIZE+
    // (long)p)让esp0正好指向该页顶端。ss0:esp0用作程序在内核态执行时的栈。另外，
    // 每个任务在GDT表中都有两个段描述符，一个是任务的TSS段描述符，另一个是任务的LDT
    // 表描述符。下面语句就是把GDT中本任务LDT段描述符和选择符保存在本任务的TSS段中。
    // 当CPU执行切换任务时，会自动从TSS中把LDT段描述符的选择符加载到ldtr寄存器中。
	p->tss.back_link = 0;
	p->tss.esp0 = PAGE_SIZE + (long) p;     // 任务内核态栈指针。
	p->tss.ss0 = 0x10;                      // 内核态栈的段选择符(与内核数据段相同)
	p->tss.eip = eip;                       // 指令代码指针
	p->tss.eflags = eflags;                 // 标志寄存器
	p->tss.eax = 0;                         // 这是当fork()返回时新进程会返回0的原因所在
	p->tss.ecx = ecx;
	p->tss.edx = edx;
	p->tss.ebx = ebx;
	p->tss.esp = esp;
	p->tss.ebp = ebp;
	p->tss.esi = esi;
	p->tss.edi = edi;
	p->tss.es = es & 0xffff;                // 段寄存器仅16位有效
	p->tss.cs = cs & 0xffff;
	p->tss.ss = ss & 0xffff;
	p->tss.ds = ds & 0xffff;
	p->tss.fs = fs & 0xffff;
	p->tss.gs = gs & 0xffff;
	p->tss.ldt = _LDT(nr);                  // 任务局部表描述符的选择符(LDT描述符在GDT中)
	p->tss.trace_bitmap = 0x80000000;       // 高16位有效
    // 如果当前任务使用了协处理器，就保存其上下文。汇编指令clts用于清除控制寄存器CRO中
    // 的任务已交换(TS)标志。每当发生任务切换，CPU都会设置该标志。该标志用于管理数学协
    // 处理器：如果该标志置位，那么每个ESC指令都会被捕获(异常7)。如果协处理器存在标志MP
    // 也同时置位的话，那么WAIT指令也会捕获。因此，如果任务切换发生在一个ESC指令开始执行
    // 之后，则协处理器中的内容就可能需要在执行新的ESC指令之前保存起来。捕获处理句柄会
    // 保存协处理器的内容并复位TS标志。指令fnsave用于把协处理器的所有状态保存到目的操作数
    // 指定的内存区域中。
	if (last_task_used_math == current)
		__asm__("clts ; fnsave %0"::"m" (p->tss.i387));
    // 接下来复制进程页表。即在线性地址空间中设置新任务代码段和数据段描述符中的基址和限长，
    // 并复制页表。如果出错(返回值不是0)，则复位任务数组中相应项并释放为该新任务分配的用于
    // 任务结构的内存页。
	if (copy_mem(nr,p)) {
		task[nr] = NULL;
		free_page((long) p);
		return -EAGAIN;
	}
    // 如果父进程中有文件是打开的，则将对应文件的打开次数增1，因为这里创建的子进程会与父
    // 进程共享这些打开的文件。将当前进程(父进程)的pwd，root和executable引用次数均增1.
    // 与上面同样的道理，子进程也引用了这些i节点。
	for (i=0; i<NR_OPEN;i++)
		if ((f=p->filp[i]))
			f->f_count++;
	if (current->pwd)
		current->pwd->i_count++;
	if (current->root)
		current->root->i_count++;
	if (current->executable)
		current->executable->i_count++;
    // 随后GDT表中设置新任务TSS段和LDT段描述符项。这两个段的限长均被设置成104字节。
    // set_tss_desc()和set_ldt_desc()在system.h中定义。"gdt+(nr<<1)+FIRST_TSS_ENTRY"是
    // 任务nr的TSS描述符项在全局表中的地址。因为每个任务占用GDT表中2项，因此上式中
    // 要包括'(nr<<1)'.程序然后把新进程设置成就绪态。另外在任务切换时，任务寄存器tr由
    // CPU自动加载。最后返回新进程号。
	set_tss_desc(gdt+(nr<<1)+FIRST_TSS_ENTRY,&(p->tss));
	set_ldt_desc(gdt+(nr<<1)+FIRST_LDT_ENTRY,&(p->ldt));
	p->state = TASK_RUNNING;	/* do this last, just in case */
	return last_pid;
}
```

`copy_process`定义在`kernel/fork.c`里面，就是把父进程资源复制到子进程中，设置子进程的内存页等信息，如果父进程调用fork结束，就会返回`__res`,因为`__res`与`%eax`寄存器是绑定的，寄存器里面存的就是进程的pid，因为`copy_process`的返回值就是`last_pid`，也就是子进程pid，注意这里是父进程返回，子进程还没执行呢，但是子进程也会返回`__res`，`__res`的值就是寄存器`%eax`的值。 睁大眼睛看代码力里有这么一段`p->tss.eax = 0;`,父进程已经把子进程`%eax`寄存器中的值设置为0了。明白为什么使用fork时，返回0就代表是子进程了吧。

通俗的解释，可以这样看待：“其实就相当于链表，进程形成了链表，父进程的fork函数返回的值指向子进程的进程id, 因为子进程没有子进程，所以其fork函数返回的值为0.

**为什么子进程先运行?**

[参考链接](https://www.zhihu.com/question/59296096)该连接中说在多核是可以同时执行的，单核的话不确定，但是从cow来说确实应该子进程先执行。

复制进程的函数是`copy_process`，如果`copy_process`调用成功的话，那么系统会有意让新开辟的进程运行，这是因为子进程一般都会马上调用exec()函数来执行其他的任务，这样就可以避免写是复制造成的开销，或者从另一个角度说，如果其首先执行父进程，而父进程在执行的过程中，可能会向地址空间中写入数据，那么这个时候，系统就会为子进程拷贝父进程原来的数据，而当子进程调用的时候，其紧接着执行拉exec()操作，那么此时，系统又会为子进程拷贝新的数据，这样的话，相比优先执行子程序，就进行了一次“多余”的拷贝。



# 锁是什么？

**本质思想**

并发编程中，为了保证数据操作的一致性，操作系统引入了锁机制，为了保证临界区代码的安全。锁其实是一种思想

锁的本质就是计算机中的一块内存。当这块内存空间被赋值为1的时候表示加锁了，当被赋值为0的时候表示解锁了，当然这块内存空间在哪里并不重要。多个线程抢占一个锁，就是要把这块内存赋为1。

在单核的情况下，关闭 CPU 中断，使其不能暂停当前请求而处理其他请求，从而达到赋值“锁”对应的内存空间的目的。

在多核的情况下，使用锁总线和缓存一致性技术（详情看这里），可以实现在单一时刻，只有某个CPU里面某一个核能够赋值“锁”对应的内存空间，从而达到锁的目的。

> 锁总线和缓存一致性
>
> 随着多核时代的到来，并发操作已经成了很正常的现象，操作系统必须要有一些机制和原语，以保证某些基本操作的原子性，比如处理器需要保证读一个字节或写一个字节是原子的，那么它是如何实现的呢？有两种机制：**总线锁定、缓存一致性**。
>
> CPU 和物理内存之间的通信速度远慢于 CPU 的处理速度，所以 CPU 有自己的内部缓存，根据一些规则将内存中的数据读取到内部缓存中来，以加快频繁读取的速度。那么这样就会造成cpu寄存器中的值和内存中的值出现不匹配的现象。（比如两核，i=0，第一个核i+1，第二个核取i的时候i还是0）
>
> **总线锁定机制：**在 CPU1 要做 i++ 操作的时候，其在总线上发出一个 LOCK 信号，其他处理器就不能操作缓存了该变量内存地址的缓存，也就是阻塞了其他CPU，使该处理器可以独享此共享内存。
>
> **缓存一致性：**当某块 CPU 对缓存中的数据进行操作了之后，就通知其他 CPU 放弃储存在它们内部的缓存，或者从主内存中重新读取



# 锁的开销

[参考](https://www.cnblogs.com/cposture/p/10761396.html)

**所有锁的本质：**

我们针对的是多线程环境下的锁机制，基于linux做测试。每种编程语言提供的锁机制都不太一样，不过无论如何，最终都会落实到两种机制上，**一是处理器提供的原子操作指令（现在一般是CAS—compare and swap），处理器会用轮询的方式试图获得锁，在处理器（包括多核）架构里这是必不可少的机制；二是内核提供的锁系统调用，在被锁住的时候会把当前线程置于睡眠（阻塞）状态。**

实际上我们在编程的时候并不会直接调用这两种机制，而是使用编程语言所带函数库里的锁方法，锁方法内部混合使用这两种机制。以pthread库（NPTL）的pthread_mutex来举例，一把锁本质上只是一个int类型的变量，占用4个字节内存并且内存边界按4字节对齐。加锁的时候先用trylock方法（内部使用的是CAS指令）来尝试获得锁，如果无法获得锁，则调用系统调用sys_futex来试图获得锁，这时候如果还不能获得锁，当前线程就会被阻塞。(**futex的知识**)

**所以很容易得到一个结论，如果锁不存在冲突，每次获得锁和释放锁的处理器开销仅仅是CAS指令的开销，在x86-64处理器上，这个开销只比一次内存访问（无cache）高一点（大概是1.3倍）。一般的电脑上一次没有缓存的内存访问大概是十几纳秒**

**测试：**

无冲突的时候：运行了 10 亿次，平摊到每次加锁/解锁操作大概是 14ns 

锁冲突的情况：运行的结果是双核机器上消耗大约3400ns，所以锁冲突的开销大概是不冲突开销的两百倍了，相差出乎意料的大。

**锁的开销**

总结：锁的开销有好几部分，分别是：线程上下文切换的开销，调度器开销（把线程从睡眠改成就绪或者把就运行态改成阻塞），还有后续上下文切换带来的缓存不命中开销，跨处理器调度的开销等等。

**锁的优化：**

从上面可以知道，真正消耗时间的不是上锁的次数，而是锁冲突的次数。减少锁冲突的次数才是提升性能的关键。使用更细粒度的锁，可以减少锁冲突。这里说的粒度包括时间和空间，比如哈希表包含一系列哈希桶，为每个桶设置一把锁，空间粒度就会小很多－－哈希值相互不冲突的访问不会导致锁冲突，这比为整个哈希表维护一把锁的冲突机率低很多。减少时间粒度也很容易理解，加锁的范围只包含必要的代码段，尽量缩短获得锁到释放锁之间的时间，最重要的是，绝对不要在锁中进行任何可能会阻塞的操作。使用读写锁也是一个很好的减少冲突的方式，读操作之间不互斥，大大减少了冲突。

假设单向链表中的插入/删除操作很少，主要操作是搜索，那么基于单一锁的方法性能会很差。在这种情况下，应该考虑使用读写锁，即 pthread_rwlock_t，这么做就允许多个线程同时搜索链表。插入和删除操作仍然会锁住整个链表。假设执行的插入和搜索操作数量差不多相同，但是删除操作很少，那么在插入期间锁住整个链表是不合适的，在这种情况下，最好允许在链表中的分离点（disjoint point）上执行并发插入，同样使用基于读写锁的方式。在两个级别上执行锁定，链表有一个读写锁，各个节点包含一个互斥锁，在插入期间，写线程在链表上建立读锁，然后继续处理。在插入数据之前，锁住要在其后添加新数据的节点，插入之后释放此节点，然后释放读写锁。删除操作在链表上建立写锁。不需要获得与节点相关的锁；互斥锁只建立在某一个操作节点之上，大大减少锁冲突的次数。

锁本身的行为也存在进一步优化的可能性，sys_futex系统调用的作用在于让被锁住的当前线程睡眠，让出处理器供其它线程使用，既然这个过程的消耗很高，也就是说如果被锁定的时间不超过这个数值的话，根本没有必要进内核加锁——释放的处理器时间还不够消耗的。sys_futex的时间消耗够跑很多次 CAS 的，也就是说，对于一个锁冲突比较频繁而且平均锁定时间比较短的系统，一个值得考虑的优化方式是先循环调用 CAS 来尝试获得锁（这个操作也被称作自旋锁），在若干次失败后再进入内核真正加锁。当然这个优化只能在多处理器的系统里起作用（得有另一个处理器来解锁，否则自旋锁无意义）。在glibc的pthread实现里，通过对pthread_mutex设置PTHREAD_MUTEX_ADAPTIVE_NP属性就可以使用这个机制。

读多写一的情况用double buffer

> 注：CAS指令是线程数据同步的原子指令。



# 什么是futex

linux的pthreads mutex采用futex实现

Futex 是 Fast Userspace Mutexes 的缩写，现在锁的机制一般使用这个，内核态和用户态的混合机制。其设计思想其实不难理解。

在传统的 Unix 系统中，System V IPC（inter process communication），如 semaphores，msgqueues，sockets 等进程间同步机制都是对一个**内核对象**操作来完成的，这个内核对象对要同步的进程都是可见的，其提供了共享的状态信息和原子操作，用来管理互斥锁并且通知阻塞的进程。当进程间要同步的时候必须要通过系统调用（如semop()）在内核中完成。比如进程A要进入临界区，先去内核查看这个对象，有没有别的进程在占用这个临界区，出临界区的时候，也去内核查看这个对象，有没有别的进程在等待进入临界区，然后根据一定的策略唤醒等待的进程。同时经研究发现，很多同步是无竞争的，即某个进程进入互斥区，到再从某个互斥区出来这段时间，常常是没有进程也要进这个互斥区或者请求同一同步变量的。但是在这种情况下，这个进程也要陷入内核去看看有没有人和它竞争，退出的时侯还要陷入内核去看看有没有进程等待在同一同步变量上，有的话需要唤醒等待的进程。这些不必要的系统调用(或者说内核陷入)造成了大量的性能开销。为了解决这个问题，Futex就应运而生。

为了解决上述这个问题，Futex 就应运而生，Futex 是一种用户态和内核态混合的同步机制。首先，同步的进程间通过 mmap 共享一段内存，futex 变量就位于这段共享的内存中且操作是原子的，当进程尝试进入互斥区或者退出互斥区的时候，先去查看共享内存中的 futex 变量，如果没有竞争发生，就不用再执行系统调用了。当通过访问 futex 变量后进程发现有竞争发生，则还是得执行系统调用去完成相应的处理（wait 或者 wake up）。简单的说，futex 就是通过在用户态的检查，（motivation）如果了解到没有竞争就不用陷入内核了，大大提高了 low-contention 时候的效率。

mutex 是在 futex 的基础上用的内存共享变量来实现的，如果共享变量建立在进程内，它就是一个线程锁，如果它建立在进程间共享内存上，那么它是一个进程锁。pthread_mutex_t 中的 `_lock` 字段用于标记占用情况，先使用CAS判断`_lock`是否占用，若未占用，直接返回。否则，通过`__lll_lock_wait_private` 调用`SYS_futex `系统调用迫使线程进入沉睡。 CAS是用户态的 CPU 指令，若无竞争，简单修改锁状态即返回，非常高效，只有发现竞争，才通过系统调用陷入内核态。所以，FUTEX是一种用户态和内核态混合的同步机制，它保证了低竞争情况下的锁获取效率。



# 中断

[参考链接](https://www.zhihu.com/question/21440586/answer/2623632047)

## 中断基本原理

### 中断定义

中断机制：CPU在执行指令时，收到某个中断信号转而去执行预先设定好的代码，然后再返回到原指令流中继续执行，这就是中断机制。

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/v2-984a49f70998a485499a461af510d93f_720w.jpg" alt="img" style="zoom:58%;float:left" />

### 中断作用

**外设异步通知CPU：**外设发生了什么事情或者完成了什么任务或者有什么消息要告诉CPU，都可以异步给CPU发通知。例如，网卡收到了网络包，磁盘完成了IO任务，定时器的间隔时间到了，都可以给CPU发中断信号。

**CPU之间发送消息：**在SMP系统中，一个CPU想要给另一个CPU发送消息，可以给其发送IPI(处理器间中断)。

**处理CPU异常：**CPU在执行指令的过程中遇到了异常会给自己发送中断信号来处理异常。例如，做整数除法运算的时候发现被除数是0，访问虚拟内存的时候发现虚拟内存没有映射到物理内存上。

**实现系统调用：**早期的系统调用就是靠中断指令来实现的，后期虽然开发了专用的系统调用指令，但是其基本原理还是相似的。

### 中断产生

中断信号的产生有以下4个来源：

**1.外设。**外设产生的中断信号是异步的，一般也叫做硬件中断(注意硬中断是另外一个概念)。硬件中断按照是否可以屏蔽分为可屏蔽中断和不可屏蔽中断。例如，网卡、磁盘、定时器都可以产生硬件中断。

**2.CPU。**这里指的是一个CPU向另一个CPU发送中断，这种中断叫做IPI(处理器间中断)。IPI也可以看出是一种特殊的硬件中断，因为它和硬件中断的模式差不多，都是异步的

**3.CPU异常。**CPU在执行指令的过程中发现异常会向自己发送中断信号，这种中断是同步的，一般也叫做软件中断(注意软中断是另外一个概念)。CPU异常按照是否需要修复以及是否能修复分为3类：1.陷阱(trap)，不需要修复，中断处理完成后继续执行下一条指令，2.故障(fault)，需要修复也有可能修复，中断处理完成后重新执行之前的指令，3.中止(abort)，需要修复但是无法修复，中断处理完成后，进程或者内核将会崩溃。例如，缺页异常是一种故障，所以也叫缺页故障，缺页异常处理完成后会重新执行刚才的指令。

**4.中断指令。**直接用CPU指令来产生中断信号，这种中断和CPU异常一样是同步的，也可以叫做软件中断。例如，中断指令int 0x80可以用来实现系统调用。

中断信号的4个来源正好对应着中断的4个作用。前两种中断都可以叫做硬件中断，都是异步的；后两种中断都可以叫做软件中断，都是同步的。很多书上也把硬件中断叫做中断(异步中断)，把软件中断叫做异常(同步中断)。

> **硬件中断、软件中断，硬中断、软中断是不同的概念，分别指的是中断的来源和中断的处理方式。**

### 中断处理

有了中断之后，CPU就分为两个执行场景了，进程执行场景(process context)和中断执行场景(interrupt context)。进程的执行是进程执行场景，同步中断的处理也是进程执行场景，异步中断的处理是中断执行场景。可能有的人会对同步中断的处理是进程执行场景感到疑惑，但是这也很好理解，因为同步中断处理是和当前指令相关的，可以看做是进程执行的一部分。而异步中断的处理和当前指令没有关系，所以不是进程执行场景。

进程执行场景和中断执行场景有两个区别：一是进程执行场景是可以调度、可以休眠的，而中断执行场景是不可以调度不可用休眠的；二是在进程执行场景中是可以接受中断信号的，而在中断执行场景中是屏蔽中断信号的。所以如果中断执行场景的执行时间太长的话，就会影响我们对新的中断信号的响应性，所以我们需要尽量缩短中断执行场景的时间。

由于同步中断是软件产生的因此可以看做是进程执行的一部分，但是硬件中断在执行中断处理程序的时候会屏蔽其他中断序号，因此需要①立即快速处理。②如果比较耗时可以先预处理然后再完全处理。

### 中断向量号

不同的中断信号需要有不同的处理方式，那么系统是怎么区分不同的中断信号呢？是靠中断向量号。每一个中断信号都有一个中断向量号，中断向量号是一个整数。CPU收到一个中断信号会根据这个信号的中断的向量号去查询中断向量表，根据向量表里面的指示去调用相应的处理函数。

中断信号和中断向量号是如何对应的呢？对于CPU异常来说，其向量号是由CPU架构标准规定的。对于外设来说，其向量号是由设备驱动动态申请的。对于IPI中断和指令中断来说，其向量号是由内核规定的。

### 中断框架结构

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/v2-04deecf318b2d29bc93f4761458767b7_720w.jpg" alt="img" style="float: left;" />





## 中断流程

### 保存现场

CPU收到中断信号后会首先把一些数据push到内核栈上，保存的数据是和当前执行点相关的，这样中断完成后就可以返回到原执行点。如果CPU当前处于用户态，则会先切换到内核态，把用户栈切换为内核栈再去保存数据

###  查找向量表

保存完被中断程序的信息之后，就要去执行中断处理程序了。CPU会根据当前中断信号的向量号去查询中断向量表找到中断处理程序。CPU是如何获得当前中断信号的向量号的呢，如果是CPU异常可以在CPU内部获取，如果是指令中断，在指令中就有向量号，如果是硬件中断，则可以从中断控制器中获取中断向量号。那CPU又是怎么找到中断向量表呢，是通过IDTR寄存器。如下

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/v2-ecb600122a69838ebe4d08cbf1e39b51_720w.jpg" alt="img" style="zoom:50%;Float:left" />

CPU现在已经把被中断的程序现场保存到内核栈上了，又得到了中断向量号，然后就根据中断向量号从中断向量表中找到对应的门描述符，对描述符做一番安全检查之后，CPU就开始执行中断处理函数。



## 中断处理

### 硬中断(hardirq)

硬件中断的中断处理和软件中断有一部分是相同的，有一部分却有很大的不同。对于IPI中断和per CPU中断，其设置是和软件中断相同的，都是一步到位设置到具体的处理函数。但是对于余下的外设中断，只是设置了入口函数，并没有设置具体的处理函数，而且是所有的外设中断的处理函数都统一到了同一个入口函数。然后在这个入口函数处会调用相应的irq描述符的handler函数，这个handler函数是中断控制器设置的。中断控制器设置的这个handler函数会处理与这个中断控制器相关的一些事物，然后再调用具体设备注册的irqaction的handler函数进行具体的中断处理。

对于外设中断为什么要采取这样的处理方式呢？有两个原因，1是因为外设中断和中断控制器相关联，这样可以统一处理与中断控制器相关的事物，2是因为外设中断的驱动执行比较晚，有些设备还是可以热插拔的，直接把它们放到中断向量表上比较麻烦。有个irq_desc这个中间层，设备驱动后面只需要调用函数request_irq来注册ISR，只处理与设备相关的业务就可以了，而不用考虑和中断控制器硬件相关的处理。

###  软中断(softirq)

软中断是把中断处理程序分成了两段：前一段叫做硬中断，执行驱动的ISR，处理与硬件密切相关的事，在此期间是禁止中断的；后一段叫做软中断，软中断中处理和硬件不太密切的事物，在此期间是开中断的，可以继续接受硬件中断。软中断的设计提高了系统对中断的响应性。下面我们先说软中断的执行时机，然后再说软中断的使用接口。

软中断也是中断处理程序的一部分，是在ISR执行完成之后运行的，在ISR中可以向软中断中添加任务，然后软中断有事要做就会运行了。有些时候当软中断过多，处理不过来的时候，也会唤醒ksoftirqd/x线程来执行软中断。

所有软中断的处理函数都是在系统启动的初始化函数里面用open_softirq接口设置的。raise_softirq一般是在硬中断或者软中断中用来往软中断上push work使得软中断可以被触发执行或者继续执行。

# Linux零拷贝技术

splice( )函数

tee( )函数

## **概述：**

零拷贝（Zero-Copy）是一种 `I/O` 操作优化技术，可以快速高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间。其在 `FTP` 或者 `HTTP` 等协议中可以显著地提升性能。

## **由来：**

如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间的复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。其过程如下图所示：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203231452388.webp" alt="img" style="zoom: 50%;Float:left" />

可以想想一下这个过程。服务器读从磁盘读取文件的时候，发生一次系统调用，产生用户态到内核态的转换，将磁盘文件拷贝到内核的内存中。然后将位于内核内存中的文件数据拷贝到用户的缓冲区中。用户应用缓冲区需要将这些数据发送到socket缓冲区中，进行一次用户态到内核态的转换，复制这些数据。此时这些数据在内核的socket的缓冲区中，在进行一次拷贝放到网卡上发送出去。

所以整个过程一共进行了四次拷贝，四次内核和用户态的切换。这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。

## 零拷贝原理

零拷贝主要是用来解决操作系统在处理 I/O 操作时，频繁复制数据的问题。关于零拷贝主要技术有 `mmap+write`、`sendfile`和`splice`等几种方式。

> DMA 技术很容易理解，本质上，DMA 技术就是我们在主板上放一块独立的芯片。在进行内存和 I/O 设备的数据传输的时候，我们不再通过 CPU 来控制数据传输，而直接通过 DMA 控制器（DMA Controller，简称 DMAC）。这块芯片，我们可以认为它其实就是一个协处理器（Co-Processor）。DMAC 的价值在如下情况中尤其明显：当我们要传输的数据特别大、速度特别快，或者传输的数据特别小、速度特别慢的时候。

看完下图会发现其实零拷贝就是少了CPU拷贝这一步，磁盘拷贝还是要有的

- mmap/write 方式

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203231457223.webp" alt="image" style="zoom:80%;float:left" />

  把数据读取到内核缓冲区后，应用程序进行写入操作时，直接把内核的`Read Buffer`的数据复制到`Socket Buffer`以便写入，这次内核之间的复制也是需要CPU的参与的。

- sendfile 方式

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203231500195.webp" alt="image" style="zoom:80%;float:left" />

  可以看到使用sendfile后，没有用户空间的参与，一切操作都在内核中进行。但是还是需要1次拷贝

- 带有 scatter/gather 的 sendfile方式

  Linux 2.4 内核进行了优化，提供了带有 `scatter/gather` 的 sendfile 操作，这个操作可以把最后一次 `CPU COPY` 去除。其原理就是在内核空间 Read BUffer 和 Socket Buffer 不做数据复制，而是将 Read Buffer 的内存地址、偏移量记录到相应的 Socket Buffer 中，这样就不需要复制。其本质和虚拟内存的解决方法思路一致，就是内存地址的记录。

  **注意： sendfile适用于文件数据到网卡的传输过程，并且用户程序对数据没有修改的场景；**

- splice 方式

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203231510067.png" style="zoom:80%; float:left" />

  其实就是CPU 在内核空间的读缓冲区（read buffer）和网络缓冲区（socket buffer）之间建立管道（pipeline）直接把数据传过去了，不去要CPU复制了

## 常见的零拷贝实现

### mmap + write

mmap 将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射，从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程，整个拷贝过程会发生 4 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝。

###  sendfile()

通过 sendfile 系统调用，数据可以直接在内核空间内部进行 I/O 传输，从而省去了数据在用户空间和内核空间之间的来回拷贝，sendfile 调用中 I/O 数据对用户空间是完全不可见的，整个拷贝过程会发生 2 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝。

### splice()

在内核空间的读缓冲区（read buffer）和网络缓冲区（socket buffer）之间建立管道（pipeline），从而避免了两者之间的 CPU 拷贝操作，2 次上下文切换，0 次 CPU 拷贝以及 2 次 DMA 拷贝。

### 写时复制

通过尽量延迟产生私有对象中的副本，写时复制最充分地利用了稀有的物理资源。

### 写时拷贝底层原理

在 Linux 系统中，调用 fork 系统调用创建子进程时，并不会把父进程所有占用的内存页复制一份，而是与父进程共用相同的内存页，而当子进程或者父进程对内存页进行修改时才会进行复制 —— 这就是著名的 写时复制 机制。如果有多个调用者同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。

传统的fork系统调用直接把所有资源复制给新创建的进程，这种实现过于简单并且效率低下，如果父进程中有很多数据的话依次复制个子进程，那么fork函数肯定是非常慢的。因此使用写时拷贝会快很多。

**原理**

首先要了解一下内存共享机制。不同进程的 虚拟内存地址 映射到相同的 物理内存地址，那么就实现了共享内存的机制。我们可以用用这种思想来实现写时拷贝。fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。这样父进程和子进程都有了属于自己独立的页。

子进程可以执行exec()来做自己想要的功能。

# 什么是DMA？

# 冯.诺依曼结构

冯.诺依曼提出了计算机“存储程序”的计算机设计理念，即将计算机指令进行编码后存储在计算机的存储器中，需要的时候可以顺序地执行程序代码，从而控制计算机运行，这就是冯.诺依曼计算机体系的开端。

核心设计思想主要体现在如下三个方面：

- 程序、数据的最终形态都是二进制编码，程序和数据都是以二进制方式存储在存储器中的，二进制编码也是计算机能够所识别和执行的编码。（可执行二进制文件：.bin文件）
- 程序、数据和指令序列，都是事先存在主（内）存储器中，以便于计算机在工作时能够高速地从存储器中提取指令并加以分析和执行。
- 确定了计算机的五个基本组成部分：运算器、控制器、存储器、输入设备、输出设备

# Linux内存管理

[参考链接](https://mp.weixin.qq.com/s/nlMGEhuaDUYqV6r8A4cRlA)

## CPU访问内存的过程

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/202210121543281.png" alt="img" style="zoom:80%;float:left" />







# Linux任务调度

https://ty-chen.github.io/linux-kernel-schedule/

# DMA等

# MySQL

## 什么是数据库？

首先数据库不仅仅是一堆数据的集合，实际上比这个复杂的多。

有两个重要组成部分：数据库和实例。

1. 数据库：物理操作文件系统或者其他文件形式的集合
2. 实例：后台进程和共享内存区组成的运行态

在 MySQL 中，实例和数据库往往都是一一对应的，而我们也无法直接操作数据库，而是要通过数据库实例来操作数据库文件，可以理解为数据库实例是数据库为上层提供的一个专门用于操作的接口。在 Unix 上，启动一个 MySQL 实例往往会产生两个进程，`mysqld` 就是真正的数据库服务守护进程，而 `mysqld_safe` 是一个用于检查和设置 `mysqld` 启动的控制程序，它负责监控 MySQL 进程的执行，当 `mysqld` 发生错误时，`mysqld_safe` 会对其状态进行检查并在合适的条件下重启。



## 什么是SQL？什么是MySQL？

sql是一种结构化查询语言，用于在数据库中存储，查询和删除数据用的。

mysql是一个数据库管理系统，开源免费。

[参考链接](https://draveness.me/mysql-innodb/)



## MySQL都有哪些存储引擎？说一说InnoDB



<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203111336301.png" alt="img_009790b51a88771c9d9d3a4ebd577f16.png" style="zoom: 50%; float: left;" />



### MySQL存储架构

<img src="https://s2.loli.net/2022/03/11/TlkW6FZCePBjIHu.jpg" alt="Logical-View-of-MySQL-Architecture" style="zoom: 33%;float:left" />

第一层用于连接、线程处理的部分并不是 MySQL 『发明』的，很多服务都有类似的组成部分；

第二层中包含了大多数 MySQL 的核心服务，包括了对 SQL 的解析、分析、优化和缓存等功能，存储过程、触发器和视图都是在这里实现的；

第三层就是 MySQL 中真正负责数据的存储和提取的存储引擎，例如：[InnoDB](https://en.wikipedia.org/wiki/InnoDB)、[MyISAM](https://en.wikipedia.org/wiki/MyISAM) 等，文中对存储引擎的介绍都是对 InnoDB 实现的分析。



### innoDB引擎存储结构

在 InnoDB 存储引擎中，所有的数据都被**逻辑地**存放在表空间中，表空间（tablespace）是存储引擎中最高的存储逻辑单位，在表空间的下面又包括段（segment）、区（extent）、页（page）：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203111411301.png" style="zoom: 33%; float: left;" />

同一个数据库实例的所有表空间都有相同的页大小；默认情况下，表空间中的页大小都为 16KB，当然也可以通过改变 `innodb_page_size` 选项对默认大小进行修改，需要注意的是不同的页大小最终也会导致区大小的不同：

<img src="https://s2.loli.net/2022/03/11/FJWSP4floqdGVwL.jpg" style="float: left;" />

从图中可以看出，在 InnoDB 存储引擎中，一个区的大小最小为 1MB，页的数量最少为 64 个。

### 如何存储？

MySQL 使用 InnoDB 存储表时，会将**表的定义**和**数据，索引**等信息分开存储，其中前者存储在 `.frm` 文件中，后者存储在 `.ibd` 文件中，这一节就会对这两种不同的文件分别进行介绍。

**.frm 文件**

无论在 MySQL 中选择了哪个存储引擎，所有的 MySQL 表都会在硬盘上创建一个 `.frm` 文件用来描述表的格式或者说定义；`.frm` 文件的格式在不同的平台上都是相同的。

**.ibd 文件**

储了当前表的数据和相关的索引数据。

**如何存储?**

与现有的大多数存储引擎一样，InnoDB 使用页作为磁盘管理的最小单位；数据在 InnoDB 存储引擎中都是按行存储的，每个 16KB 大小的页中可以存放 2-200 行的记录。



## 数据库的三大范式？

一范式就是属性不可分割。第一范式是关系型数据库的基本要求，表示每一列都是不可分割的基本数据项。比如数据库中的“地址”属性，如果要经常访问地址中的"所在城市"，就要把“地址”属性分割成“省份”、“城市”、“街道”等基本项

二范式就是要有主键,其他字段都依赖于主键。就是说一张表的每一列都和主键相关，而不能只与主键的某一部分相关，不能把多种数据保存到同一张表中。

三范式就是要消除传递依赖,消除冗余,就是各种信息只在一个地方存储,不出现在多张表中（很多时候会牺牲第三范式）。比如下图这样：

<img src="https://cdn.learnku.com/uploads/images/201910/28/47109/Xbpo9xTUFe.png!large" alt="MySQL 三大范式" style="float: left;" />

第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。



## 什么是存储过程？有哪些优缺点？

**定义：** 就是数据库 SQL 语言层面的代码封装与重用。存储过程是数据库系统中为了完成特定功能的SQL语句集合，经编译后保存在数据库中。普通的SQL语句我们都是保存到其他地方，每次需要编译后才能执行，效率比较的低。而有了存储过程后，第一次编译后再次调用不需要再次编译，用户通过存储过程的名字来调用。

- 优点
  1. 效率高。编译一次后，就会存到数据库，每次调用时都直接执行。而普通的sql语句我们要保存到其他地方（记事本 ），都要先分析编译才会执行。
  2. 维护方便。当发生改动时候，修改之前的存储过程比较容易
  3. 复用性高。存储过程往往针对特定功能编写的，因此可以重复调用
  4. 安全性高。使用的时候有身份限制，只能特定用户使用
  4. 降低网络流量。存储过程编译好会放在数据库，我们在远程调用时，不会传输大量的字符串类型的sql语句。
- 缺点
  1. 不同厂商数据库系统之间不兼容。



## mysql索引是什么？有哪几种类型？优缺点？

### 索引的定义

**MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。**是加快检索表中数据的方法。对于一张表来说，如果不加索引的话就要从表的第一行开始查找，如果一个表有百万行的话效率会非常低。如果有了索引，利用数据结构就可以快速查找。

### 优缺点

- 索引的优点
  1. 加快数据的检索速度
- 索引的缺点
  1. 创建和维护高效的索引表比较麻烦
  2. 占用物理空间

### 索引的类型

- 索引的类型

  - 字段类型分类：
    1. 普通索引。没有任何约束，**允许空值和重复值，纯粹为了提高查询效率而存在**。
    2. 唯一索引。在普通索引上加上数据不允许重复，允许为null
    3. 主键索引。在唯一索引上加上不允许为null，一个表只能有一个主键
    4. 全文索引。没见过。
  - 按数据结构分类可分为：
    1. **B+tree索引**
    2. **Hash索引**
    3. **Full-text索引**
  - 其他
    1. 聚簇索引
    2. 非聚簇索引


### 算法原理

  

## 数据库事务

> 事务是并发控制的基本单位。事务他是一个操作序列，这些操作要么都执行，要么都不执行，是一个不可分割的单位。最简单的例子就是银行转账了，从一个账户汇钱到另一个账户，两个操作要么都执行要么都不执行。

- 数据库中的事务有以下四个特征：
  	
  1. 原子性。事务中的操作被看成一个逻辑单元，这个逻辑单元的操作要么全做，要么全部做。
  2. 一致性。当对数据进行更改后，如果回滚会回到最初状态。
     
  3. 隔离性。允许多个用户对同一个数据进行并发访问同时不破坏数据的完整性和正确性。同时并行事务的修改必须和其他并行事务独立。
  4.  持久性。事务结束后，结果必须能持久保存。
- 事务的语句
  1. 开始事务。`BEGIN TRANSACTION`
  2. 提交事务。`COMMIT TRANSACTION`
  3. 回滚事务。`ROLLBACK TRANSACTION`



## 数据库锁机制

### 并发控制机制

并发控制的任务就是保证多个事务存取数据统一数据时候不破坏事务的隔离性和统一性。乐观锁和悲观锁其实都是并发控制的机制，同时它们在原理上就有着本质的差别：

- 悲观锁

  定义：悲观锁顾名思义，认为当前操作的数据会被外界其他事务所修改，因此在整个数据处理过程中，将数据锁定，屏蔽一切可能违反事务性质的操作。因此每次获取数据的时候都会进行加锁操作，防止外界修改。由于该数据加锁，因此对改数据进行读写操作的其他进程会进入等待状态。**悲观锁的实现需要数据库的锁机制来完成**，只有数据库系统的锁机制才能保证访问的排他性。

  评价：效率上，加锁会让数据库产生额外的开销，同时还有增加死锁的机会。另外，如果是只读型事务的话，加锁是没必要的，因此频繁写入的业务可能需要。而且一旦某数据被加锁了，其它数据必须等待才行。

- 乐观锁

  定义：乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。

  实现方式：**使用版本号实现乐观锁**，**版本号的实现方式有两种，一个是数据版本机制，一个是时间戳机制。具体如下。**
  
  1. 为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。
  2. 时间戳机制，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。

**乐观锁和悲观锁在本质上并不是同一种东西，一个是一种思想，另一个是一种真正的锁，但是它们都是一种并发控制机制。**

乐观锁不会存在死锁的问题，但是由于更新后验证，所以当**冲突频率**和**重试成本**较高时更推荐使用悲观锁，而需要非常高的**响应速度**并且**并发量**非常大的时候使用乐观锁就能较好的解决问题，在这时使用悲观锁就可能出现严重的性能问题；在选择并发控制机制时，需要综合考虑上面的四个方面（冲突频率、重试成本、响应速度和并发量）进行选择。

### 锁的种类

对数据的操作其实只有两种，也就是读和写，而数据库在实现锁时，也会对这两种操作使用不同的锁；InnoDB 实现了标准的行级锁，也就是共享锁（Shared Lock）和互斥锁（Exclusive Lock）

- **共享锁（读锁）**：允许事务对一条行数据进行读取；
- **互斥锁（写锁）**：允许事务对一条行数据进行删除或更新；

而它们的名字也暗示着各自的另外一个特性，共享锁之间是兼容的，而互斥锁与其他任意锁都不兼容：稍微对它们的使用进行思考就能想明白它们为什么要这么设计，因为共享锁代表了读操作、互斥锁代表了写操作，所以我们可以在数据库中**并行读**，但是只能**串行写**，只有这样才能保证不会发生线程竞争，实现线程安全。

### 锁的粒度

无论是共享锁还是互斥锁其实都只是对某一个数据行进行加锁

InnoDB 支持多种粒度的锁，也就是**行锁**和**表锁**；为了支持多粒度锁定，InnoDB 存储引擎引入了意向锁（Intention Lock），意向锁就是一种表级锁。

- 行锁

  行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突，提高并发度。其加锁粒度最小，但加锁的开销也最大，还会出现死锁。行级锁分为共享锁和排他锁。

- 表锁

  级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。表级锁分为共享锁和排他锁。开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。

- 意向锁

  为了支持多粒度锁定，InnoDB 存储引擎引入了意向锁（Intention Lock）

  1. **意向共享锁**：事务想要在获得表中某些记录的共享锁，需要在表上先加意向共享锁；
  2. **意向互斥锁**：事务想要在获得表中某些记录的互斥锁，需要在表上先加意向互斥锁；

  意向锁其实不会阻塞全表扫描之外的任何请求，它们的主要目的是为了表示**是否有人请求锁定表中的某一行数据**。

  > 有的人可能会对意向锁的目的并不是完全的理解，我们在这里可以举一个例子：如果没有意向锁，当已经有人使用行锁对表中的某一行进行修改时，如果另外一个请求要对全表进行修改，那么就需要对所有的行是否被锁定进行扫描，在这种情况下，效率是非常低的；不过，在引入意向锁之后，当有人使用行锁对表中的某一行进行修改之前，会先为表添加意向互斥锁（IX），再为行记录添加互斥锁（X），在这时如果有人尝试对全表进行修改就不需要判断表中的每一行数据是否被加锁了，只需要通过等待意向互斥锁被释放就可以了。

### 锁的算法

介绍三种锁的算法：Record Lock、Gap Lock 和 Next-Key Lock。

- Record Lock记录锁

  通过索引建立的 B+ 树找到行记录并添加锁。但是如果InnoDB 不知道待修改的记录具体存放的位置，也无法对将要修改哪条记录提前做出判断就会锁定整个表。

- Gap Lock间隙锁

  记录锁是在存储引擎中最为常见的锁，除了记录锁之外，InnoDB 中还存在间隙锁（Gap Lock），间隙锁是对索引记录中的一段连续区域的锁；

  当使用类似 `SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE;` 的 SQL 语句时，就会阻止其他事务向表中插入 `id = 15` 的记录，因为整个范围都被间隙锁锁定了。

- Next-Key Lock

  Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身

  当我们更新一条记录，比如 `SELECT * FROM users WHERE age = 30 FOR UPDATE;`，InnoDB 不仅会在范围 `(21, 30]` 上加 Next-Key 锁，还会在这条记录后面的范围 `(30, 40]` 加间隙锁，所以插入 `(21, 40]` 范围内的记录都会被锁定。

### 死锁的产生

既然 InnoDB 中实现的锁是悲观的，那么不同事务之间就可能会互相等待对方释放锁造成死锁，最终导致事务发生错误；想要在 MySQL 中制造死锁的问题其实非常容易：两个会话都持有一个锁，并且尝试获取对方的锁时就会发生死锁，不过 MySQL 也能在发生死锁时及时发现问题，并保证其中的一个事务能够正常工作，这对我们来说也是一个好消息。



## drop、truncate和delete的区别

- delete删除的过程是每次从表中删除一行，并且将该操作记录到日志中，可以回滚。
- truncate指一次性从表中删除所有的数据，不保存在日志中因此是不可恢复的。
- drop将表占用的空间删除掉



## SQL的组成主要有四部分

- 数据定义。

  **DDL(Data Definition Language）数据库定义语言。**

  用于定义数据库的三级结构，包括外模式、概念模式、内模式及其相互之间的映像，定义数据的完整性、安全控制等约束。

  DDL不需要commit。

  `CREATE
  ALTER
  DROP
  TRUNCATE
  COMMENT
  RENAME`

- 数据操纵。

  **DML**（**Data Manipulation Language**）**数据操纵语言**

  用于让用户或程序员使用，实现对数据库中数据的操作。	

  需要commit.。

  `SELECT
  INSERT
  UPDATE
  DELETE
  MERGE
  CALL
  EXPLAIN PLAN
  LOCK TABLE`

- 数据控制

  **DCL**（**Data Control Language**）**数据库控制语言** 

  **TCL**（**Transaction Control Language**）**事务控制语言**

  GRANT 授权
  REVOKE 取消授权

  SAVEPOINT 设置保存点
  ROLLBACK 回滚
  SET TRANSACTION

- 嵌入式中的SQL



## 什么是视图？视图的使用场景有哪些？

定义：视图是一种虚拟的表，其内容由查询语句定义。同真实的表一样，视图包含一系列带有名称的列和行数据。可以对视图进行增，改，查，操作，视图通常是有一个表或者多个表的行或列的子集。视图本身并不包含任何数据，不在数据库中以存储的数据值集形式存在，它只包含映射到基表的一个查询语句，当基表数据发生变化，视图数据也随之变化。一种抽象的概念如下：

<img src="https://s2.loli.net/2022/03/11/IaiJOxPDSmXGQWj.png" alt="视图" style="float: left;" />

**为什么用视图？**关系型数据库中的数据是由一张一张的二维关系表所组成，简单的单表查询只需要遍历一个表，而复杂的多表查询需要将多个表连接起来进行查询任务。对于复杂的查询事件，每次查询都需要编写MySQL代码效率低下。为了解决这个问题，数据库提供了视图（view）功能。

查询的数据来源于不同的表，而查询者希望以统一的方式查询，这样也可以建立一个视图，把多个表查询结果联合起来，查询者只需要直接从视图中获取数据，不必考虑数据来源于不同表所带来的差异

**常用场景：**视图适合于多表连接浏览时使用。不适合增、删、改。



## MYSQL索引和算法原理

[MySQL索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

 MySQL数据库支持多种索引类型，如BTree索引，哈希索引，全文索引等等。主要说一说Btree索引

**对于索引的定义：**数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。最基本的查询算法当然是顺序查找（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如二分查找（binary search）、二叉树查找（binary tree search）等。如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上，例如二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。

目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构

### Btree索引

关于BTree和B+Tree的介绍再数据结构篇中，可以先去看一下，弄清楚B树和B+树的区别。

一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级（内存是纳秒，磁盘是毫秒），所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。

**主存存取**

目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，所以这里就抽象出一个十分简单的存取模型来说明RAM的工作原理。

![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203121404235.png)

从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。上

主存的存取过程如下：

1. 当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。
2. 写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。

所以可以得出结论：这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。

**磁盘存取原理**

索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203121412182.png" style="zoom:80%;" /><img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203121412649.png" style="zoom: 67%;" />

一个个磁盘，磁盘由磁道和扇区组成

当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。所以机械时间加上存储介质的特性，磁盘IO肯定很慢。

解决办法：根据计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。

由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。**预读的长度一般为页（page）的整倍数**。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。

**性能分析**

> 数据存储最小单元
>
> 在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节
>
> 虚拟内存中小单元是页，一个页的大小是4k
>
> InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是默认16K。
>
> ![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203121421667.webp)

- 首先说Btree

  假设Btree一次检索要访问n个节点，数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。

  B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为$O(h)=O(log_dN)$。一般实际应用中，阶d是非常大的数字，通常超过100，因此h非常小（通常不超过3）。综上所述，用B-Tree作为索引结构效率是非常高的。

- 再说B+tree

  为什么B+tree比Btree更适合索引呢？因为d越大索引的性能越好，而阶的上限取决于节点内key和data的大小。因为一页大小有限，又存数据又存索引，导致阶会变小。所以B+数就是想方设法将数据去掉，使得节点里面全是索引(key)就行，因此d越大，$O(log_dN)$就会越小。

- 为什么红黑树不行？

  红黑树本质上是一种自平衡的二叉查找树，数据量大的话树的高度太高了。同时由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。
  
- 一个B+索引树可以存多少行数据？

  答：首先看是几层树。对于 B+树而言，树的高度一般不超过 4 层。

  对于 MySQL 的 InnoDB 存储引擎而言，一个结点默认的存储空间为 16Kb。MySQL 的 InnoDB 存储引擎的索引一般用 bigint 存储，占用 8 个 byte，一个索引又会关联一个指向孩子结点的指针，这个指针占用 6 个 byte，也就是说结点中的一个关键字大概要用 14 byte 的空间，而一个结点的默认大小为 16kb ，那么一个结点可以存储关键的个数最多为$16kb / 14byte = 1170$，即一个节点可以存储1170个指针，所以阶m=1170。

  一行数据是大小是1k，一个页的大小是16k，因此一页可以放16条数据。一个指针指向一个存放记录的页，一个页可以存放16条数据。这样我们根据高度就可以大致算出一颗B+树能存放多少数据了。**B+树索引本身并不能直接找到具体的一条记录，只能知道该记录在哪个页上，数据库会把页载入到内存，再通过二分查找定位到具体的记录。**

  所以一颗高度为2的B+树可以存放的数据是：`1170*16=18720`条数据。一颗高度为3的B+树可以存放的数据是：`1170*1170*16=21902400`条记录（两千万条）

  理论上就是这样，在InnoDB存储引擎中，B+树的高度一般为2-4层，就可以满足千万级数据的存储。查找数据的时候，一次页的查找代表一次IO，那我们通过主键索引查询的时候，其实最多只需要2-4次IO就可以了。



### 哈希索引

哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。

哈希缺点：

1. Hash 索引仅仅能满足等值查询，不能使用范围查询。
2. Hash 索引无法被用来避免数据的排序操作，由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；
3. 当碰撞太高的话，性能不一定很好，比如拉链法，后面跟了一长串。

### 聚簇索引和非聚簇索引

**通俗解释：**

聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据

非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因

**聚簇索引：**聚簇索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的就是整张表的行记录数据，也将聚集索引的叶子节点称为数据页。这个特性决定了索引组织表中数据也是索引的一部分，每张表只能拥有一个聚簇索引。

优点：

1. 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快
2. 聚簇索引对于主键的排序查找和范围查找速度非常快

缺点：

1. 更新主键的代价很高，维护索引很昂贵，因为将会导致被更新的行移动，导致数据被分到不同的页上。因此，对于InnoDB表，我们一般定义主键为不可更新。

使用聚簇索引的场景：

1. 适合用在排序的场合
2. 取出一定范围数据的时候

**非聚簇索引：**辅助索引叶子节点存储的不再是行的物理位置，而是主键值。通过辅助索引首先找到的是主键值，再通过主键值找到数据行的数据页，再通过数据页中的Page Directory找到数据行。

> 辅助索引使用主键作为"指针"而不是使用地址值作为指针的好处是，减少了当出现行移动或者数据页分裂时辅助索引的维护工作，使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个"指针"。也就是说行的位置（实现中通过16K的Page来定位）会随着数据库里数据的修改而发生变化（前面的B+树节点分裂以及Page的分裂），使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响。

二级索引需要两次索引查找，而不是一次才能取到数据，因为存储引擎第一次需要通过二级索引找到索引的叶子节点，从而找到数据的主键，然后在聚簇索引中用主键再次查找索引，再找到数据



## mysql隔离级别

[参考链接](https://zhuanlan.zhihu.com/p/117476959)

本文所说的 MySQL 事务都是指在 InnoDB 引擎下

数据库事务指的是一组数据操作，事务内的操作要么就是全部成功，要么就是全部失败，什么都不做，其实不是没做，是可能做了一部分但是只要有一步失败，就要回滚所有操作，有点一不做二不休的意思。

事务具有原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）四个特性，简称 ACID，缺一不可。今天要说的就是**隔离性**。

- 概念说明，先搞清都是什么意思

  - 脏读：指的是读到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。
  - 可重复读：事务A在读到一条数据之后，此时事务B对该数据进行了修改并提交，那么事务A再读该数据，读到的还是原来的内容。
  - 不可重复读：对比可重复读，不可重复读指的是在同一事务内，不同的时刻读到的同一批数据可能是不一样的，可能会受到其他事务的影响。
  - 幻读：针对数据插入操作来说的。假设事务A对某些行的内容作了更改，但是还未提交，此时事务B插入了与事务A更改前的记录相同的记录行，并且在事务A提交之前先提交了，而这时，在事务A中查询，会发现好像刚刚的更改对于某些数据未起作用，但其实是事务B刚插入进来的，让用户感觉很魔幻，感觉出现了幻觉

- 事务的隔离级别

  > MySQL的事务隔离级别一共有四个，分别是读未提交、读已提交、可重复读以及可串行化。MySQL的隔离级别的作用就是让事务之间互相隔离，互不影响，这样可以保证事务的一致性。在Oracle，SqlServer中都是选择读已提交(Read Commited)作为默认的隔离级别，为什么Mysql不选择读已提交(Read Commited)作为默认隔离级别，而选择可重复读(Repeatable Read)作为默认的隔离级别
  >
  > 隔离级别比较：可串行化>可重复读>读已提交>读未提交
  >
  > 隔离级别对性能的影响比较：可串行化>可重复读>读已提交>读未提交
  >
  > 由此看出，隔离级别越高，所需要消耗的MySQL性能越大（如事务并发严重性），为了平衡二者，一般建议设置的隔离级别为可重复读，MySQL默认的隔离级别也是可重复读。

  ​	<img src="https://s2.loli.net/2022/01/18/PhWqMHs96L3rlTO.png" alt="img"  />

  - 读未提交

    读未提交，其实就是可以读到其他事务未提交的数据，但没有办法保证你读到的数据最终一定是提交后的数据，如果中间发生回滚，那就会出现脏数据问题，读未提交没办法解决脏数据问题。更别提可重复读和幻读了，想都不要想。

    例子：启动两个事务，分别为事务A和事务B，在事务A中使用 update 语句，修改 age 的值为10，初始是1 ，在执行完 update 语句之后，在事务B中查询 user 表，会看到 age 的值已经是 10 了，这时候事务A还没有提交，而此时事务B有可能拿着已经修改过的 age=10 去进行其他操作了。在事务B进行操作的过程中，很有可能事务A由于某些原因，进行了事务回滚操作，那其实事务B得到的就是脏数据了，拿着脏数据去进行其他的计算，那结果肯定也是有问题的。

  - 读提交

    读提交就是一个事务只能读到其他事务已经提交过的数据，也就是其他事务调用 commit 命令之后的数据。

    读提交事务隔离级别是大多数流行数据库的默认事务隔离界别，比如 Oracle

    例子：同样开启事务A和事务B两个事务，在事务A中使用 update 语句将 id=1 的记录行 age 字段改为 10。此时，在事务B中使用 select 语句进行查询，我们发现在事务A提交之前，事务B中查询到的记录 age 一直是1，直到事务A提交，此时在事务B中 select 查询，发现 age 的值已经是 10 了。这就出现了一个问题，在同一事务中(本例中的事务B)，事务的不同时刻同样的查询条件，查询出来的记录内容是不一样的，事务A的提交影响了事务B的查询结果，这就是不可重复读，也就是读提交隔离级别。

  - 可重复读

    上面说不可重复读是指同一事物不同时刻读到的数据值可能不一致。而可重复读是指，事务不会读到其他事务对已有数据的修改，即使其他事务已提交。也就是说，事务开始时读到的已有数据是什么，在事务提交前的任意时刻，这些数据的值都是一样的。但是，对于其他事务新插入的数据是可以读到的，这也就引发了幻读问题。

    例子：事务A开始后，执行 update 操作，将 age = 1 的记录的 name 改为“风筝2号”；事务B开始后，在事务执行完 update 后，执行 insert 操作，插入记录 age =1，name = 古时的风筝，这和事务A修改的那条记录值相同，然后提交。事务B提交后，事务A中执行 select，查询 age=1 的数据，这时，会发现多了一行，并且发现还有一条 name = 古时的风筝，age = 1 的记录，这其实就是事务B刚刚插入的，这就是幻读。

  - 串行化

    串行化是4种事务隔离级别中隔离效果最好的，解决了脏读、可重复读、幻读的问题，但是效果最差，它将事务的执行变为顺序执行，与其他三个隔离级别相比，它就相当于单线程，后一个事务的执行必须等待前一个事务结束。

- 应用场景

  项目中是不用读未提交(Read UnCommitted)和串行化(Serializable)两个隔离级别，原因有二：

  1. 采用读未提交(Read UnCommitted),一个事务读到另一个事务未提交读数据，这个不用多说吧，从逻辑上都说不过去！
  2. 采用串行化(Serializable)，每个次读操作都会加锁，快照读失效，一般是使用mysql自带分布式事务功能时才使用该隔离级别！(笔者从未用过mysql自带的这个功能，因为这是XA事务，是强一致性事务，性能不佳！互联网的分布式方案，多采用最终一致性的事务解决方案！)

  所以我们只用考虑read committed或者read repeatable。一般互联网项目都用读已提交这个。

  [参考](https://blog.csdn.net/qq_26024869/article/details/107034616?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_aa&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_aa&utm_relevant_index=10)



## **Mysql里面为什么用B+树？**

[上面有写](#MYSQL索引和算法原理)



## 一条MySQL语句执行过程

 首先了解一下mysql的架构

首先大方向上要分为两层，server层和存储引擎层。

- server层

  Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

- 存储引擎层

  存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎，现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

**下面来说一下过程：**

**①第一步连接器**

连接到mysql服务器会首先碰到连接器，连接器负责跟客户端建立连接、获取权限、维持和管理连接。完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。

**②查询缓存**

MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。

如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。

查询缓存也有不好的地方。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。

**③分析器**

分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法规则，只有遵循它的规则，才能获取到在它规则管理内的数据

**④优化器**

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。

**⑤执行器**

开始执行语句。开始执行的时候，要先判断一下你对这个表 有没有执行对应操作的权限，如果没有，就会返回没有权限的错误；如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

如果表没有索引，会从第一行一行一行地读取，根据where后面的条件是否满足，如果有索引则会根据索引的规则去寻找，然后执行生成结果集。



## 分库分表有哪些方案？有什么区别？

## mysql调优

### 简单的优化方式

**MySQL 分析表**

分析表用于分析和存储表的关键字分布，分析的结果可以使得系统得到准确的统计信息，使得 SQL 生成正确的执行计划。如果用于感觉实际执行计划与预期不符，可以执行分析表来解决问题，分析表语法如下：

```
analyze table cxuan005;
```

分析结果涉及到的字段属性如下

Table：表示表的名称；

Op：表示执行的操作，analyze 表示进行分析操作，check 表示进行检查查找，optimize 表示进行优化操作；

Msg_type：表示信息类型，其显示的值通常是状态、警告、错误和信息这四者之一；

Msg_text：显示信息。

对表的定期分析可以改善性能，应该成为日常工作的一部分。因为通过更新表的索引信息对表进行分析，可改善数据库性能。

**MySQL 检查表**

数据库经常可能遇到错误，比如数据写入磁盘时发生错误，或是索引没有同步更新，或是数据库未关闭 MySQL 就停止了。遇到这些情况，数据就可能发生错误： **Incorrect key file for table: ' '. Try to repair it**. 此时，我们可以使用 Check Table 语句来检查表及其对应的索引。

```
check table cxuan005;
```

检查表的主要目的就是检查一个或者多个表是否有错误。Check Table 对 MyISAM 和 InnoDB 表有作用。Check Table 也可以检查视图的错误。

**MySQL 优化表**

MySQL 优化表适用于删除了大量的表数据，或者对包含 VARCHAR、BLOB 或则 TEXT 命令进行大量修改的情况。MySQL 优化表可以将大量的空间碎片进行合并，消除由于删除或者更新造成的空间浪费情况。它的命令如下

```
optimize table cxuan005;
```

### 查询时的优化

**小表驱动大表**

![img](https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/171401a253f1cac9~tplv-t2oaga2asx-zoom-in-crop-mark:3024:0:0:0.awebp)

**避免全表扫描**

mysql在使用不等于(!=或者<>)的时候无法使用导致全表扫描。在查询的时候，如果对索引使用不等于的操作将会导致索引失效，进行全表扫描

**避免mysql放弃索引查询**

如果mysql估计使用全表扫描要比使用索引快，则不使用索引。（最典型的场景就是数据量少的时候）

**使用覆盖索引，少使用select***

需要用到什么数据就查询什么数据，这样可以减少网络的传输和mysql的全表扫描。

尽量使用覆盖索引，比如索引为name，age，address的组合索引，那么尽量覆盖这三个字段之中的值，mysql将会直接在索引上取值（using index），并且返回值不包含不是索引的字段。

## MySQL 对于千万级的大表要怎么优化？

https://www.zhihu.com/question/19719997



+++



# Redis

## 关系型数据库和非关系型数据库

### **关系型数据库**

**含义：**采用关系模型来组织数据的数据库。简单说关系模型就是二维表格模型，而关系型数据库就是由二维表及其之间的联系组成的数据结构

**优点：**

1. 容易理解：二维表结构是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型来说更容易理解
2. 使用方便：通用的SQL语言使得操作关系型数据库非常方便
3. 易于维护：丰富的完整性(实体完整性、参照完整性和用户定义的完整性)大大减低了数据冗余和数据不一致的概率

**缺点：**

1. 高并发读写需求。 网站的用户并发性非常高，往往达到每秒上万次读写请求，对于传统关系型数据库来说，硬盘I/O是一个很大的瓶颈
2. 海量数据的高效率读写。 网站每天产生的数据量是巨大的，对于关系型数据库来说，在一张包含海量数据的表中查询和修改，效率是非常低的
3. 高扩展性和可用性。在基于web的结构当中，数据库是最难进行横向扩展的，当一个应用系统的用户量和访问量与日俱增的时候，数据库却没有办法像web server和app server那样简单的通过添加更多的硬件和服务节点来扩展性能和负载能力。对于很多需要提供24小时不间断服务的网站来说，对数据库系统进行升级和扩展是非常痛苦的事情，往往需要停机维护和数据迁移。

**一些不需要关系型数据库的情况：**

1. 关系型数据库在对事物一致性的维护中有很大的开销，而现在很多web2.0系统对事物的读写一致性都不高

2. 对关系数据库来说，插入一条数据之后立刻查询，是肯定可以读出这条数据的，但是对于很多web应用来说，并不要求这么高的实时性，比如发一条消息之后，过几秒乃至十几秒之后才看到这条动态是完全可以接受的

3. 任何大数据量的web系统，都非常忌讳多个大表的关联查询，以及复杂的数据分析类型的复杂SQL报表查询，特别是SNS类型的网站**（SNS，专指社交网络服务，包括了社交软件和社交网站。）**

   

### **非关系型数据库**

**含义：**NoSQL一词首先是Carlo Strozzi在1998年提出来的，指的是他开发的一个没有SQL功能，轻量级的，开源的关系型数据库。但是NoSQL的发展慢慢偏离了初衷，我们要的不是“no sql”，而是“no relational(not noly)”，也就是我们现在常说的非关系型数据库了。

**优点：**

1. 格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。
2. 速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘；
3. 高扩展性。
4. 成本低：nosql数据库部署简单，基本都是开源软件。

**缺点：**

1. 不提供sql支持，学习和使用成本较高；
2. 无事务处理；
3. 数据结构相对复杂，复杂查询方面稍欠。

### 总结

关系型数据库的最大特点就是事务的一致性：传统的关系型数据库读写操作都是事务的，具有ACID的特点，这个特性使得关系型数据库可以用于几乎所有对一致性有要求的系统中，如典型的银行系统。
    

但是，在网页应用中，尤其是SNS应用中，一致性却不是显得那么重要，用户A看到的内容和用户B看到同一用户C内容更新不一致是可以容忍的，或者说，两个人看到同一好友的数据更新的时间差那么几秒是可以容忍的，因此，关系型数据库的最大特点在这里已经无用武之地，起码不是那么重要了。

 相反地，关系型数据库为了维护一致性所付出的巨大代价就是其读写性能比较差，而像微博、facebook这类SNS的应用，对并发读写能力要求极高，关系型数据库已经无法应付因此，必须用新的一种数据结构存储来代替关系数据库。
    

关系数据库的另一个特点就是其具有固定的表结构，因此，其扩展性极差，而在SNS中，系统的升级，功能的增加，往往意味着数据结构巨大变动，这一点关系型数据库也难以应付，需要新的结构化数据存储。
    

于是，非关系型数据库应运而生，由于不可能用一种数据结构化存储应付所有的新的需求，因此，非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合。
    

必须强调的是，数据的持久存储，尤其是海量数据的持久存储，还是需要一种关系数据库这员老将。



## 什么时候用redis什么时候用mysql？

Redis和MySQL不是相互替代的关系，而是相辅相成的，越来越多的项目组已经采用了redis+MySQL的架构来开发平台工具。

首先mysql是持久化数据库，是关系型数据库，是直接保存在硬盘上的。redis是非关系型数据库，是内存运行的数据存储获取工具。

但是数据量多少并不是redis和mysql选择的标准，因为都可以集群括展。

他们的使用场景是不同的：

1. 关系型数据库最重要的有两个点，第一是持久化存储的功能，即数据都存储在硬盘中。第二就是关系型数据库可以提供复杂的查询和统计功能。
2. 关系型数据库偏向于快速存取数据，用于实时响应要求高的场景，响应时间在毫秒级，通常作为热点数据的缓存使用。

数据多而且调用频繁的话，用mysql存储的话数据库连接被一直占用，其它的数据请求就进来了，导致连接超时，数据量大的话，数据库直接死机了。只能重启才能解决问题。这个时候如果把数据请求量大的数据放在redis中的话就可以分担一下mysql的压力，从而提高系统的性能，解决请求并发问题。



## Redis持久化

RDB模式和AOF模式

在默认情况下，Redis将数据库快照保存在名为dump.rdb的二进制文件中

两个模式的选择：

1. **如果主要充当缓存功能,或者可以承受数分钟数据的丢失, 通常生产环境一般只需启用RDB可,此也是默认值**

2. **如果数据需要持久保存,一点不能丢失,可以选择同时开启RDB和AOF,一般不建议只开启AOF**

### RDB模式

具体原理有两种SAVE，BGSAVE

**SAVE**

SAVE是阻塞服务，在创建新文件dump.rdb替代旧文件时候无法响应客户端请求，生产环境中很少这样，一般都是停机维护时候才考虑

<img src="https://upload-images.jianshu.io/upload_images/18517139-3474d032b5ddff7c.png?imageMogr2/auto-orient/strip|imageView2/2/w/583/format/webp" alt="img" style="zoom: 67%; float: left;" />

**BGSAVE**

与之对应的，BGSAVE就是非阻塞的。当创建RDB文件时候，会fork一个子进程来做这件事，同时父进程会正常接收处理来自客户端的请求。子进程执行RDB操作，处理完后会向父进程发送一个信号，通知父进程处理完毕，父进程用新的dump.rdb文件替代旧文件。可以说BGSAVE是一个异步命令。fork是指redis通过创建子进程来进行RDB操作，cow指的是**copy on write**，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。

**RDB优点：**

1. RDB保存了某个时间点的数据，可以保留多个备份。当出现问题的时候方便恢复到不同时间节点(多版本恢复)，同事文件格式支持不少第三方工具分析
2. RDB可以最大化Redis性能，父进程在保存RDB文件时候，唯一要做的就是fork一个子进程，接着子进程会接替保存工作，父进程无需执行任何磁盘io操作
3. RDB在大量数据的时候，恢复比AOF快
4. 文件单一紧凑，方便网络传输，适合灾难恢复

**RDB缺点：**

1. RDB不能实时保存数据，即这次保存数据和上次保存数据之间这段时间如果有新数据，可能会丢失这部分新数据。虽然Redis允许设置不同的保存点来控制保存RDB文件的频率，但是由于数据集的属性，这不是一个轻松地操作，因此会丢失好几分钟内的数据
2. 当数据量非常大的时候，从父进程fork子进程来保存RDB文件时候需要一点时间。当数据集很庞大的时候，fork会非常耗时，造成服务器在一定时间内停止处理客户端，会有毫秒或秒级响应。

### AOF模式

AOF即Append Only File，需要手动开启，采用追加的方式保存，默认文件是appendonly.aof，记录所有写的命令。

AOF 方式不能保证绝对不丢失数据，目前常见的操作系统中，执行系统调用 write 函数，将一些内容写入到某个文件里面时，为了提高效率，系统通常不会直接将内容写入硬盘里 面，而是先将内容放入一个内存缓冲区（buffer）里面，等到缓冲区被填满，或者用户执行 fsync 调用和 fdatasync 调用时才将储存在缓冲区里的内容真正的写入到硬盘里，未写入磁盘之前，数据可能会丢失 。过程：

1. 命令追加：写到aof_buf中；
2. 写入文件：执行write操作；
3. 同步文件：同步到磁盘中。

**优点：**

1. 数据安全性相对较高，根据所使用的fsync策略(fsync是同步内存中redis所有已经修改的文件到存储设备)，默认是appendfsync everysec，即每秒执行一次 fsync,在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据( fsync会在后台线程执行，所以主线程可以继续努力地处理命令请求)
2. 由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中不需要seek, 即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，可以通过 redis-check-aof 工具来解决数据一致性的问题
3. Redis可以在 AOF文件体积变得过大时，自动地在后台对AOF进行重写,重写后的新AOF文件包含了恢复当前数据集所需的最小命令集合。整个重写操作是绝对安全的，因为Redis在创建新 AOF文件的过程中，append模式不断的将修改数据追加到现有的 AOF文件里面，即使重写过程中发停机，现有的 AOF文件也不会丢失。而一旦新AOF文件创建完毕，Redis就会从旧AOF文件切换到新AOF文件，并开始对新AOF文件进行追加操作。
4. AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，也可以通过该文件完成数据的重建AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以Redis协议的格式保存，因此 AOF文件的内容非常容易被人读懂，对文件进行分析(parse)也很轻松。导出（export)AOF文件也非常简单:
5. 举个例子，如果你不小心执行了FLUSHALL.命令，但只要AOF文件未被重写，那么只要停止服务器，移除 AOF文件末尾的FLUSHAL命令，并重启Redis ,就可以将数据集恢复到
   FLUSHALL执行之前的状态。

**缺点：**

1. 即使有些操作是重复的也会全部记录，AOF 的文件大小要大于 RDB 格式的文件

2. AOF 在恢复大数据集时的速度比 RDB 的恢复速度要慢

3. 根据fsync策略不同,AOF速度可能会慢于RDB

4. bug 出现的可能性更多

   

## Redis的数据结构讲一讲 + 使用场景

[详细参考链接](https://www.cnblogs.com/xiaolincoding/p/15628854.html)

五种基本的数据类型：**String**、**Hash**、**List**、**Set**、**SortedSet**

更高级的有：**HyperLogLog、Geo、BloomFilter**

### 键值对数据库是怎么实现的？

> Redis 的键值对中的 key 就是字符串对象，而 **value 可以是字符串对象，也可以是集合数据类型的对象**，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。

Redis 是使用了一个「哈希表」保存所有键值对，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对。哈希表其实就是一个数组，数组中的元素叫做哈希桶。哈希桶存放的是指向键值对数据的指针,这样通过指针就能找到键值对数据，然后因为键值对的值可以保存字符串对象和集合数据类型的对象，所以键值对的数据结构中并不是直接保存值本身，而是保存了 void * key 和 void * value 指针，分别指向了实际的键对象和值对象，这样一来，即使值是集合数据，也可以通过 void * value 指针找到。如图：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203132208185.png" alt="image-20220313220842101" style="zoom:80%;float:left" /><img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203132209926.png" alt="image-20220313220916793" style="zoom:50%;" />

特别说明：void * key 和 void * value 指针指向的是 **Redis 对象**，Redis 中的每个对象都由 redisObject 结构表示

### string

**String** 是 Redis 最简单最常用的数据结构

Redis中的字符串，不是 C 语言中的字符串（即以空字符’\0’结尾的字符数组），是自己构建了一种名为 **简单动态字符串（simple dynamic string,SDS**）的抽象类型，并将 SDS 作为 Redis的默认字符串表示。其数据结构如下所示：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203131740250.png" alt="image-20220313174005132" style="zoom: 67%; float: left;" />

> 上图中，uint8_t表示8位无符号整数

**为什么使用SDS?**

1. 由于 len 属性的存在，我们获取 SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)。而对于 C 语言，获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。
2. C 语言中使用 `strcat`  函数来进行两个字符串的拼接，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。而对于 SDS 数据类型，在进行字符修改的时候，会首先根据记录的 len 属性检查内存空间是否满足需求，如果不满足，会进行相应的空间扩展，然后在进行修改操作，所以不会出现缓冲区溢出。
3. C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。而对于SDS，由于`len`属性和`alloc`属性的存在，对于修改字符串SDS实现了**空间预分配**和**惰性空间释放**两种策略
4. 因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而所有 SDS 的API 都是以处理二进制的方式来处理 `buf` 里面的元素，并且 SDS 不是以空字符串来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束。

### ZipList（压缩列表）

压缩列表的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。

压缩列表的构成如下：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203132212852.png" alt="img" style="zoom:80%;float:left" />

1. zlbytes，记录整个压缩列表占用对内存字节数；
2. zltail，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；
3. zllen，记录压缩列表包含的节点数量；
4. zlend，标记压缩列表的结束点，固定值 0xFF（十进制255）。
5. prevlen，记录了「前一个节点」的长度；
6. encoding，记录了当前节点实际数据的类型以及长度；
7. data，记录了当前节点的实际数据；

当往压缩列表中插入数据时，压缩列表就会根据数据是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息，这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的。

**缺点：**空间扩展操作也就是重新分配内存，因此连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能。所以说，虽然压缩列表紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，会导致内存重新分配，最糟糕的是会有「连锁更新」的问题。

### hash表

Redis 散列可以存储多个键值对之间的映射。和字符串一样，散列存储的值既可以是字符串又可以是数值，并且用户同样可以对散列存储的数字值执行自增或自减操作。

### 整数集合

整数集合是 Set 对象的底层实现之一。当一个 Set 对象只包含整数值元素，并且元素数量不时，就会使用整数集这个数据结构作为底层实现。整数集合本质上是一块连续内存空间，它的结构定义如下：

```c
typedef struct intset {
    //编码方式
    uint32_t encoding;
    //集合包含的元素数量
    uint32_t length;
    //保存元素的数组
    int8_t contents[];
} intset;
```

保存元素的容器是一个 contents 数组，虽然 contents 被声明为 int8_t 类型的数组，但是实际上 contents 数组并不保存任何 int8_t 类型的元素，contents 数组的真正类型取决于 intset 结构体里的 encoding 属性的值。

**整数集合的升级操作**

整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，当然升级的过程中，也要维持整数集合的有序性。

整数集合升级的过程不会重新分配一个新类型的数组，而是在原本的数组上扩展空间，然后在将每个元素按间隔类型大小分割。整数集合升级的好处是**节省内存资源**。

### 跳表

Redis 只有在 Zset 对象的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。Zset 对象是唯一一个同时使用了两个数据结构来实现的 Redis 对象，这两个数据结构一个是跳表，一个是哈希表。这样的好处是既能进行高效的范围查询，也能进行高效单点查询。

链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。**跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表**，这样的好处是能快读定位数据。如图：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203132220846.png" alt="img" style="zoom: 67%;" />

如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，而使用了跳表后，只需要查找 2 次就能定位到节点 4，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4。

### quicklist（快表）

在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。

其实 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。

在前面讲压缩列表的时候，我也提到了压缩列表的不足，虽然压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降。

quicklist 解决办法，**通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。**

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203132224976.png" alt="img" style="zoom:67%;" />

### 使用场景

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202204051333652.png" style="zoom: 50%; float: left;" />



## 避免缓存穿透的利器之BloomFilter

本质就是用单向散列函数把数据映射到二进制向量中

布隆过滤器优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。即假阳性，就是说如果每一位为0表示一定没有，为1表示可能会出现没有的情况。

Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。

因为布隆过滤器可以明确知道某个查询数据库不存在，所以可以过滤掉无效的查询到数据库，减少数据库的压力。



## 如果有大量的key需要设置同一时间过期，一般需要注意什么？

如果大量的key过期时间设置的过于集中，到过期的那个时间点，**Redis**可能会出现短暂的卡顿现象。严重的话会出现缓存雪崩，我们一般需要在时间上加一个随机值，使得过期时间分散一些。



## 缓存穿透，缓存击穿，缓存血崩

[参考](https://segmentfault.com/a/1190000039688578)

- **缓存穿透**

  定义：缓存穿透是指缓存和数据库都没有的数据，被大量请求，比如订单号不可能为`-1`，但是用户请求了大量订单号为`-1`的数据，由于数据不存在，缓存就也不会存在该数据，所有的请求都会直接穿透到数据库。
  如果被恶意用户利用，疯狂请求不存在的数据，就会导致数据库压力过大，甚至垮掉。

  解决：

- **缓存击穿**

  定义：缓存击穿是指数据库原本有得数据，但是缓存中没有，一般是缓存突然失效了，这时候如果有大量用户请求该数据，缓存没有则会去数据库请求，会引发数据库压力增大，可能会瞬间打垮。

  解决：

- **缓存血崩**

  定义：缓存雪崩是指缓存中有大量的数据，在同一个时间点，或者较短的时间段内，全部过期了，这个时候请求过来，缓存没有数据，都会请求数据库，则数据库的压力就会突增，扛不住就会宕机。

  解决：



## redis高并发和快的原因

1. redis是基于内存的，内存的读写速度非常快；没有磁盘IO的开销

2. redis是单线程的，省去了很多上下文切换线程的时间；

3. redis使用多路复用技术，可以处理并发的连接。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。



## Redis的单线程

Redis由很多个模块组成，如网络请求模块、索引模块、存储模块、高可用集群支撑模块、数据操作模块等。

很多人说Redis是单线程的，就认为Redis中所有模块的操作都是单线程的，其实这是不对的。我们所说的Redis单线程，指的是"其网络IO和键值对读写是由一个线程完成的"，也就是说，**Redis中只有网络请求模块和数据操作模块是单线程的。而其他的如持久化存储模块、集群支撑模块等是多线程的。**

**原因：**

1. 锁带来的性能消耗。多线程可能会产生竞态条件，如果要对数据进行细粒度操作需要加锁，会加大开销增大延时。
2. CPU上下文切换带来的性能消耗。在多核CPU架构下，Redis如果在不同的核上运行，就需要频繁地进行上下文切换，这个过程会增加Redis的执行时间，客户端也会观察到较高的尾延迟了
3. redis是IO密集型程序，对于CPU是利用率没那么高，CPU并不是性能瓶颈
4. 在单线程中使用多路复用 I/O技术也能提升Redis的I/O利用率

**总结：**上面的原因说的也是多线程实现redis的劣势。我们可以从整体来看，一个计算机程序在执行的过程中，主要需要进行两种操作分别是读写操作和计算操作。其中读写操作主要是涉及到的就是I/O操作，其中包括网络I/O和磁盘I/O，计算操作主要涉及到CPU。**而多线程的目的，就是通过并发的方式来提升I/O的利用率和CPU的利用率。**那么，Redis需不需要通过多线程的方式来提升提升I/O的利用率和CPU的利用率呢？首先redis数据的存取对CPU的要求很小，所以说CPU不是redis性能的瓶颈。那么再看IO，提高IO效率多线程是一种方案，但不是唯一的一种，还有IO多路复用这个技术。所以在redis采用的是IO复用的技术来提高IO并发。



## Redis的IO多路复用

redis是非阻塞IO+IO多路复用的技术来实现的

Linux的IO多路复用机制是指一个线程处理多个IO流，也就是select/epoll机制。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203131703393.jpeg" alt="img" style="float: left;" />



## Redis怎么统计在线用户

[参考链接](https://blog.huangz.me/diary/2016/redis-count-online-users.html#)

| 方案        | 特点                                                         |
| :---------- | :----------------------------------------------------------- |
| 有序集合    | 能够同时储存在线用户的名单以及用户的上线时间，能够执行非常多的聚合计算操作，但是耗费的内存也非常多。 |
| 集合        | 能够储存在线用户的名单，也能够执行聚合计算，消耗的内存比有序集合少，但是跟有序集合一样，这个方案消耗的内存也会随着用户数量的增多而增多。 |
| HyperLogLog | 无论需要统计的用户有多少，只需要耗费 12 KB 内存，但由于概率算法的特性，只能给出在线人数的估算值，并且也无法获取准确的在线用户名单。 |
| 位图        | 在尽可能节约内存的情况下，记录在线用户的名单，并且能够对这些名单执行聚合操作。 |



## redis，讲讲缓存一致性问题

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203132237449.jpeg" alt="img" style="zoom: 50%; float: left;" /><img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203132237909.jpeg" alt="img" style="zoom: 50%;" />

果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可。但随着业务量的增长，你的项目请求量越来越大，这时如果每次都从数据库中读数据，那肯定会有性能问题。这个阶段通常的做法是，引入「缓存」来提高读性能，架构模型如上图。当下优秀的缓存中间件，当属 Redis 莫属，它不仅性能非常高，还提供了很多友好的数据类型，可以很好地满足我们的业务需求。但引入缓存之后，你就会面临一个问题：之前数据只存在数据库中，现在要放到缓存中读取，具体要怎么存呢?

**最简单的方案：**

1. 数据库的数据，全量刷入缓存(不设置失效时间)
2. 写请求只更新数据库，不更新缓存
3. 启动一个定时任务，定时把数据库的数据，更新到缓存中

**缺点：**

1. 缓存利用率低：不经常访问的数据，还一直留在缓存中
2. 数据不一致：因为是「定时」刷新缓存，缓存和数据库存在不一致(取决于定时任务的执行频率)

所以，这种方案一般更适合业务「体量小」，且对数据一致性要求不高的业务场景。

那么现在就有两个问题，缓存利用率和一致性问题

**缓存利用率**

想要缓存利用率「最大化」，只需要缓存中只保留最近访问的「热数据，可以这样做：

1. 写请求依旧只写数据库
2. 读请求先读缓存，如果缓存不存在，则从数据库读取，并重建缓存
3. 同时，写入缓存中的数据，都设置失效时间

这样一来，缓存中不经常访问的数据，随着时间的推移，都会逐渐「过期」淘汰掉，最终缓存中保留的，都是经常被访问的「热数据」，缓存利用率得以最大化。

**一致性问题**

大部分观点认为，做缓存不应该是去更新缓存，而是应该删除缓存，然后由下个请求去去缓存，发现不存在后再读取数据库，写入缓存。原因有如下两个：

1. 线程安全问题。有请求A和请求B进行更新操作，假如有以下情况：（1）线程A更新了数据库（2）线程B更新了数据库（3）线程B更新了缓存（4）线程A更新了缓存，于是这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据
2. 业务场景角度。如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用更新操作而不是删除，就会导致数据压根还没读到，缓存就被频繁的更新，浪费性能。其次，如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。

当数据发生更新时，我们不仅要操作数据库，还要一并操作缓存。具体操作就是，修改一条数据时，不仅要更新数据库，也要连带缓存一起更新。但数据库和缓存都更新，又存在先后问题，那对应的方案就有 2 个：

- 先更新缓存，后更新数据库

  如果缓存更新成功了，但数据库更新失败，那么此时缓存中是最新值，但数据库中是「旧值」。虽然此时读请求可以命中缓存，拿到正确的值，但是，一旦缓存「失效」，就会从数据库中读取到「旧值」，重建缓存也是这个旧值。这时用户会发现自己之前修改的数据又「变回去」了，对业务造成影响。

- 先更新数据库，后更新缓存

  如果数据库更新成功了，但缓存更新失败，那么此时数据库中是最新值，缓存中是「旧值」。之后的读请求读到的都是旧数据，只有当缓存「失效」后，才能从数据库中得到正确的值。这时用户会发现，自己刚刚修改了数据，但却看不到变更，一段时间过后，数据才变更过来，对业务也会有影响。

上述这两个方案都不行，以下给出解决方案：

- 如果先更新缓存，后更新数据库的话，使用延时双删策略

  延时双删的方案的思路是，为了避免更新数据库的时候，其他线程从缓存中读取不到数据，就在更新完数据库之后，再sleep一段时间，然后再次删除缓存。sleep的时间要对业务读写缓存的时间做出评估，sleep时间大于读写缓存的时间即可。

- 如果先更新数据库，后更新缓存的话，设置缓存过期时间，消息队列

  设置过期时间：每次放入缓存的时候，设置一个过期时间，比如5分钟，以后的操作只修改数据库，不操作缓存，等待缓存超时后从数据库重新读取。如果对于一致性要求不是很高的情况，可以采用这种方案。

  消息队列：先更新数据库，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。

基于以上原因，redis官方选择了更简单、更快的方法，不支持错误回滚。这样的话，如果在我们的业务场景中需要保证原子性，那么就要求了开发者通过其他手段保证命令全部执行成功或失败，例如在执行命令前进行参数类型的校验，或在事务执行出现错误时及时做事务补偿。



## Redis的事务满足原子性吗？

redis中的事务是不满足原子性的，在运行错误的情况下，并没有提供类似数据库中的回滚功能。那么为什么redis不支持回滚呢，官方文档给出了说明，大意如下：

1. redis命令失败只会发生在语法错误或数据类型错误的情况，这一结果都是由编程过程中的错误导致，这种情况应该在开发环境中检测出来，而不是生产环境
2. 不使用回滚，能使redis内部设计更简单，速度更快
3. 回滚不能避免编程逻辑中的错误，如果想要将一个键的值增加2却只增加了1，这种情况即使提供回滚也无法提供帮助



## redis有那些命令是原子指令





## 为何Redis使用跳表而非红黑树实现SortedSet？

[参考链接](https://juejin.cn/post/6844903446475177998)

首先要知道红黑树和跳表的插入删除，删除，查找时间复杂度是一样的。

redis作者说了三个原因：

1. 范围查找。跳表在区间查询的时候效率是高于红黑树的，跳表进行查找O(logn)的时间复杂度定位到区间的起点，然后在原始链表往后遍历就可以了 ，其他插入和单个条件查询，更新两者的复杂度都是相同的O(logn)。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。
2. 易于实现
3. 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。

## redis如何实现消息队列

消息队列是指利用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。

回顾下我们使用的消息队列有如下特点：

1. 三个角色：生产者、消费者、消息处理中心
2. 异步处理模式：生产者将消息发送到一条虚拟的通道(消息队列)上，而无须等待响应。消费者则订阅或是监听该通道，取出消息。两者互不干扰，甚至都不需要同时在线，也就是我们说的松耦合
3. 可靠性：消息要可以保证不丢失、不重复消费、有时可能还需要顺序性的保证



## 大key如何处理

# **ISO（国际标准化组织）制定的网络七层模型**

**物理层**、**数据链路层**、**网络层**、**传输层**、**会话层**、**表示层**、**应用层**



# **TCP/IP网络五层模型**

**物理层**、**数据链路层**、**网络层**、**传输层**、**应用层**

+++



# 应用层

## TCP（HTTP）长链接和短连接的区别

> HTTP 的长连接和短连接本质上是 TCP 长连接和短连接。HTTP 属于应用层协议，在传输层使用 TCP 协议，在网络层使用 IP 协议。IP 协议主要解决网络路由和寻址问题，TCP 协议主要解决如何在 IP 层之上可靠的传递数据包，使在网络上的另一端收到发端发出的所有包，并且顺序与发出顺序一致。TCP 有可靠，面向连接的特点。

- tcp短连接

  client向server发起连接请求，server接到请求，然后双方建立连接。client向server发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起close操作。为什么呢，一般的server不会回复完client后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接一般只会在client/server间传递一次读写操作

  客户端和服务器之间的TCP链接只能为一个HTTP请求服务，当服务器处理完客户的一次HTTP请求之后就会主动将TCP连接关闭。此后如果客户与同一个服务器进行多次HTTP请求的话还需要重新建立TCP连接。也就是说客户的多次HTTP请求不能共用一个TCP连接。

- tcp长链接

  client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。多次HTTP请求共用同一个TCP连接。

  在长连接的应用场景下，client端一般不会主动关闭它们之间的连接，Client与server之间的连接如果一直不关闭的话，会存在一个问题，随着客户端连接越来越多，server早晚有扛不住的时候，这时候server端需要采取一些策略，如关闭一些长时间没有读写事件发生的连接，这样可以避免一些恶意连接导致server端服务受损；如果条件再允许就可以以客户端机器为颗粒度，限制每个客户端的最大长连接数，这样可以完全避免某个蛋疼的客户端连累后端服务。

  但是我不能一直连接啊，如果客户端消失了难倒我服务器端还傻傻的等待吗？这里面有一个机制叫做保活机制。在一段时间内连接处于非活动状态（一般是两个小时），那么服务器端将向客户端发送一个报文，如果服务端没有收到回应，则在一定时间间隔内还会继续发送。当发送次数达到阈值（保活次数）后，确认对方主机不可达，断开连接。发送探测消息，客户端有四种状态：

  1. 对方主机正常，但对方不想赢，超过次数后关闭
  2. 对方正常，但因为网络原因没收到确认报文
  3. 对方主机崩溃了，不会响应报文
  4. 对方主机崩溃然后重启，服务器会受到响应报文，然后关掉链接





## TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？

这是两个完全不一样的东西，毕竟长得都不一样

> HTTP 的 Keep-Alive，是由**应用层（用户态）** 实现的，称为 HTTP 长连接；
>
> TCP 的 Keepalive，是由 **TCP 层（内核态）** 实现的，称为 TCP 保活机制；

- **HTTP 的 Keep-Alive**

  http协议采用的是请求—应答模式，即客户端发起请求，服务端会返回响应。

  但是有一个网页有很多组成部分，除了文本还有图片，视频等静态资源。如果每一个资源都创建一个连接然后关闭，代价太大了。而且每次请求都是建立 TCP -> 请求资源 -> 响应资源 -> 释放连接 这样的**短连接**方式太累了，一次只能请求一个资源。所以想能不能在第一个 HTTP 请求完后，先不断开 TCP 连接，让后续的 HTTP 请求继续使用此连接？

  所以HTTP 的 Keep-Alive 就是实现了这个功能，可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 **HTTP 长连接**。

  HTTP1.0中是默认关闭的。通过headers设置"Connection: Keep-Alive"开启。HTTP的Keep-Alive是HTTP1.1中默认开启的功能。通过headers设置"Connection: close "关闭。

- **TCP 的 Keepalive**

  TCP 的 Keepalive 这东西其实就是 **TCP 的保活机制**

  如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。

  - 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
  - 如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。

  所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活，这个工作是在内核完成的。



## HTTP协议详解

[参考](https://www.cnblogs.com/phpstudy2015-6/p/6810130.html)

### 请求报文

HTTP协议是以ASCⅡ码传输，建立在TCP/IP协议之上的应用层规范。
HTTP请求报文由请求行（request line）、请求头部（header）、空行和请求数据四个部分组成，下图是请求报文的一般格式。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202204081412753.jpeg" alt="enter" style="float: left;" />

- 请求换行

  请求行是由请求方法、url字段以及HTTP协议版本字段三个部分组成，它们用空格分开。HTTP协议的请求方法有GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT。
  而常见的有如下几种：

  > **GET**
  >
  > 当客户端要从服务器读取数据时，点击网页上的链接，或者通过在浏览器的地址栏输入网址来浏览网页的，使用的都是GET方式。GET的方法要求服务器将URL定位的资源放在响应报文的数据部分，回送给客户端。回送给客户端。使用GET的方法，请求参数和对应的值附加在URL后面，利用问号 （？），代表URL的结尾和请求参数的开始，传递的参数长度受到限制。例如，/index.html?id=1&password=123,这样通过GET的方式传递的数据直接显示在地址上，所以我们可以将请求以链接的方式发送给接收方。缺点：但是这种方式显然不能传递私密的数据。另外不同浏览器对地址的字符长度限制有不同的数据，一般最多不超过1024个字符，所以大量的数据传输，不适合使用GET方式。
  >
  > **POST**
  >
  > POST将请求参数封装在HTTP的请求数据中，可以大量的传递数据，理论上对数据得大小的没有限制，但实际各个WEB服务器会规定对post提交数据大小进行限制。而且可以不显示在URL中。一个post的http请求如下：
  >
  > <img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/1207920-20190708160109318-1680528296.png" alt="wireshark" style="zoom: 67%;float:left" />

  **POST方法向服务器提交数据，比如表单的数据的提交。GET的方法一般用于获取/查询资源信息。**

- 请求头

  请求头部由键值对组成，关键字和值之间用 **:** 分开，所以一般用unordered_map来存储请求头。请求头封装了有关客户端请求的信息，典型的请求头有：

  | 请求头          | 含义                                                         |
  | :-------------- | :----------------------------------------------------------- |
  | User-Agent      | 产生请求的浏览器类型，User-Agent请求报头域允许客户端将它的操作系统、浏览器和其它属性告诉服务器 |
  | Accept          | 客户端可识别的响应内容类型列表。eg：Accept：image/gif，表明客户端希望接受GIF图象格式的资源；Accept：text/html，表明客户端希望接受html文本。 |
  | Accept-Language | 客户端可接受的自然语言                                       |
  | Accept-chartset | 客户端可接受应答的字符集。eg：Accept-Charset:iso-8859-1,gb2312.如果在请求消息中没有设置这个域，缺省是任何字符集都可以接受。 |
  | Accept-Encoding | 客户端可接受的编码压缩格式                                   |
  | HOST            | 请求的主机名称，允许多个域名同处一个IP之地，即虚拟主机       |
  | Connection      | 连接方式（close或keep-alive）                                |
  | Cookie          | 存储于客户端扩展字段，向同一域名的服务端发送该域的cookie     |
  | Authorization   | Authorization请求报头域主要用于证明客户端有权查看某个资源。当浏览器访问一个页面时，如果收到服务器的响应代码为401（未授权），可以发送一个包含Authorization请求报头域的请求，要求服务器对其进行验证。 |

- 空行

  最后一个请求头之后是一个空行，发送回车符和换行符(\r\n)，通知服务器以下不会再有请求头。

- 请求体

  请求数据不再GET方法中使用，而是在POST方法中使用。POST方法适用于客户端提交表单。与请求数据相关的最常使用的请求头是包体类型 Content-Type 和包体长度 Content-Length

### 响应报文

HTTP响应报文是由状态行、响应头部、空行和响应包体四个部分组成，如下图所示：

<img src="https://img2018.cnblogs.com/blog/1207920/201907/1207920-20190708160115618-73171525.png" alt="description here" style="float: left;" />

状态行（status line）代替了请求行。状态行通过提供一个状态码来说明请求情况。

- 状态行

  状态行由HTTP协议版本（HTTP-Version），状态码（Statue-Code） 和 状态码描述文本（Reason-Phrase） 三个部分组成，它们之间用空格隔开；

  > 状态码有三位数字组成，第一位定义了响应的类别，可能有五种取值：
  >
  > - **1xx**：表示服务端已经接收到客户端请求，客户端可以继续发送请求；
  > - **2xx**：表示服务端已经成功接收请求并处理；
  > - **3xx**：表示服务器要求客户端重定向；
  > - **4xx**：客户端请求有问题；
  > - **5xx**：服务端未能正常处理客户端的请求出现错误；
  >
  > 常见状态码描述文本有如下：
  >
  > - **200 OK**：请求成功；
  > - **400 Bad Request**：客户端请求语法有问题，不能被服务端理解；
  > - **401 Unauthorized**：请求未经授权，必须与Authorization请求报头域一起使用（eg：BASE64用户身份验证）；
  > - **403 Forbidden**：服务器收到请求但是拒绝提供服务，通常会在响应正文中给出不提供服务的原因；
  > - **404 Not Found**：请求的资源不存在，eg，输错了URL；
  > - **500 Internal Server Error**：服务器发生错误，无法完成客户端请求；
  > - **503 Service Unavailable**：表示服务器当前不能处理客户端请求，一段时间之后可能恢复正常；

- 响应头

  响应头可能包括以下信息：

  | 响应头           | 描述                                                         |
  | :--------------- | :----------------------------------------------------------- |
  | Server           | Server 响应报头域包含了服务器用来处理请求的软件信息及其版本。它和 User-Agent 请求报头域是相对应的，前者发送服务器端软件的信息，后者发送客户端软件(浏览器)和操作系统的信息。 |
  | Vary             | 指示不可缓存的请求头列表                                     |
  | Connection       | 连接方式                                                     |
  | www-Authenticate | WWW-Authenticate响应报头域必须被包含在401 (未授权的)响应消息中，这个报头域和前面讲到的Authorization 请求报头域是相关的，当客户端收到 401 响应消息，就要决定是否请求服务器对其进行验证。如果要求服务器对其进行验证，就可以发送一个包含了Authorization 报头域的请求 |

- 响应体

  服务器返回给客户端的文本信息，如下图：

  <img src="https://s2.loli.net/2022/04/08/CpVYWPQyARMmTln.png" alt="http" style="float: left;" />

### http的无状态性

  HTTP协议是无状态的（stateless）。也就是说，同一个客户端第二次访问同一个服务器上面的页面时，服务器无法得知这个客户端曾经访问过，服务器无法辨别不同的客户端。HTTP的无状态性简化了服务器的设计，是服务器更容易支持大量并发的HTTP请求。HTTP协议是采用请求-响应的模型。客户端向服务端发送一个请求报文，服务端以一个状态作为回应。当使用普通模式，即非keep-alive模式时，每个请求-应答都要重新建立一个连接，连接完成后立即断开；

  HTTP1.1 使用持久连接keep-alive，所谓持久连接，就是服务器在发送响应后仍然在一段时间内保持这条连接，允许在同一个连接中存在多次数据请求和响应，即在持久连接情况下，服务器在发送完响应后并不关闭TCP 连接，而客户端可以通过这个连接继续请求其他对象。

  HTTP 长连接不可能一直保持，例如 Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100，表示这个长连接最多接收100次请求就断开。HTTP 是一个无状态协议，这意味着每个请求都是独立的，Keep-Alive 没能改变这个结果。另外，Keep-Alive也不能保证客户端和服务器之间的连接一定是活跃的，在 HTTP1.1 版本中也如此。唯一能保证的就是当连接被关闭时你能得到一个通知，所以不应该让程序依赖于 Keep-Alive 的保持连接特性，否则会有意想不到的后果。

### 浏览器控制台中的http报文

  ![浏览器控制台http请求报文](https://s2.loli.net/2022/04/08/hnVyHgKIqD35RSz.png)



## https和http区别

> https=http+ssl但是现在ssl都被tsl所取代

- 首先说明为什么http协议不安全？**首先要知道一个安全的机制应该满足三个特性：机密性，完整性，不可否认性。**http协议通信使用明文进行通信，且没有任何其他保护措施，我们依次来看一下不安全特性。首先是机密性，由于使用明文进行通信，导致信息会被窃听泄露；然后是完整性，一段裸奔的明文在网络上传递，会被轻而易举的篡改；最后是不可否认性，由于http的请求和响应不会对通信方的身份进行确认，导致很容会被欺骗，而且用户无法察觉

  但是https使得上述三个特性都满足。

  HTTPS并非是应用层的一种新协议。只是HTTP通信接口部分用SSL（Secure Socket Layer）和TLS（Transport Layer Security）协议代替而已。

  通常，HTTP直接和TCP通信。当使用SSL时，则演变成先和SSL通信，再由SSL和TCP通信了。简言之，**所谓HTTPS，其实就是身披SSL协议这层外壳的HTTP（SSL协议位于TCP和HTTP协议之间）**。SSL主要包括几大块：

  1. 解决机密性。对请求和应答消息进行加密。公钥加密效率比较低，对称加密效率较高。因此对于密钥协商这块，使用公钥两方协商密钥，然后用密钥执行对称加密对消息加密
  2. 完整性。依靠单向散列函数实现，比如MD5或者SHA1
  3. 不可否认性。依靠数字签名来实现。



## https加密算法

https的ssl连接过程如下图：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203071410891.png" alt="img" style="zoom:80%;float:left" />

![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203071411049.png)

## SSL/TLS密钥交换算法

### HTTPS加密：完整握手流程与密钥交换原理

HTTPS通过**TLS/SSL协议**在HTTP层与TCP层之间建立加密通道，确保数据传输的**机密性**、**完整性**和**身份认证**。其核心在于**TLS握手流程**和**密钥交换机制**，以下分步详解：

---

#### **一、TLS完整握手流程（以TLS 1.2为例）**

##### **1. 建立TCP连接**
• 客户端发起TCP三次握手，建立与服务器的连接（如`443`端口）。

---

##### **2. TLS握手阶段**
1. **ClientHello**  
   • 客户端发送支持的TLS版本、**加密套件列表**（如`TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256`）、**客户端随机数**（Client Random）。

2. **ServerHello**  
   • 服务器选择TLS版本和加密套件，返回**服务器随机数**（Server Random）和**数字证书**（包含公钥和域名信息）。

3. **证书验证**  
   • 客户端验证证书合法性（CA签名、有效期、域名匹配），并检查证书吊销状态（CRL或OCSP）。

4. **密钥交换**  
   • **客户端生成预主密钥（Pre-Master Secret）**：  
     ◦ **RSA密钥交换**：客户端生成预主密钥，用服务器公钥加密后发送（`ClientKeyExchange`）。  
     ◦ **Diffie-Hellman（DH）密钥交换**：客户端发送DH参数（如`Client Params`），与服务器的DH参数结合生成预主密钥。

5. **生成主密钥（Master Secret）**  
   • 双方通过**伪随机函数（PRF）**，结合**客户端随机数**、**服务器随机数**和**预主密钥**，生成**主密钥**。

6. **生成会话密钥**  
   • 主密钥派生为**4个会话密钥**：  
     ◦ 客户端加密密钥（Client Write Key）  
     ◦ 服务器加密密钥（Server Write Key）  
     ◦ 客户端MAC密钥（Client HMAC Key）  
     ◦ 服务器MAC密钥（Server HMAC Key）

7. **完成握手（Finished）**  
   • 双方发送加密的`Finished`消息，验证握手数据完整性。随后进入加密通信阶段。

---

#### **二、密钥交换原理**

##### **1. 密钥交换的目标**
• **安全协商对称密钥**：在不安全的网络中，双方协商出仅彼此知道的对称密钥（会话密钥），用于后续通信加密。

---

##### **2. 常见密钥交换算法**

###### **(1) RSA密钥交换**
• **流程**：  
  1. 服务器公钥加密预主密钥，仅服务器私钥可解密。  
  2. 双方基于预主密钥生成会话密钥。  
• **缺点**：  
  • 缺乏前向保密（Forward Secrecy），若服务器私钥泄露，历史通信可被解密。

###### **(2) Diffie-Hellman（DH）密钥交换**
• **流程**：  
  1. 客户端和服务器交换DH参数（如`g^a mod p`和`g^b mod p`）。  
  2. 双方计算共享密钥：`g^(ab) mod p`（即预主密钥）。  
• **优点**：  
  • 支持前向保密，每次会话生成独立密钥，即使私钥泄露，历史会话仍安全。  
• **变种**：  
  • **ECDHE**（基于椭圆曲线的临时DH）：计算更快，安全性更高。

---

##### **3. 前向保密（Forward Secrecy）**
• **原理**：每次会话使用临时密钥（Ephemeral Key），会话结束后销毁。  
• **实现方式**：通过**ECDHE_RSA**或**ECDHE_ECDSA**等加密套件。  
• **重要性**：防止长期私钥泄露导致历史数据被解密。

---

#### **三、TLS 1.3的优化**
• **简化握手**：合并ClientHello和ServerHello步骤，移除RSA密钥交换（仅支持前向保密算法）。  
• **1-RTT握手**：首次连接仅需1个往返（Round Trip Time），性能大幅提升。  
• **0-RTT模式**：对重复连接支持0-RTT，但存在重放攻击风险。

---

#### **四、加密套件解析（示例）**
`TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256`  
• **密钥交换**：ECDHE（临时椭圆曲线DH）。  
• **身份验证**：RSA签名。  
• **对称加密**：AES-128-GCM（加密算法和模式）。  
• **完整性校验**：SHA256（HMAC哈希算法）。

---

#### **五、完整流程示例**
```plaintext
客户端                            服务器
  |-------- TCP三次握手 ----------->|
  |-------- ClientHello ----------->|
  |<-------- ServerHello -----------|
  |<-------- Certificate -----------|
  |<-------- ServerKeyExchange -----| (DH参数)
  |<-------- ServerHelloDone ------|
  |-------- ClientKeyExchange ----->| (DH参数)
  |-------- ChangeCipherSpec ------>|
  |-------- Finished -------------->|
  |<------- ChangeCipherSpec ------|
  |<------- Finished --------------|
  |====== 加密通信开始 =============|
```

---

#### **六、关键安全机制**
1. **数字证书**：验证服务器身份，防止中间人攻击。  
2. **随机数**：防止重放攻击，确保每次会话唯一性。  
3. **加密套件协商**：选择双方支持的最强加密算法。  
4. **完整性校验**：HMAC或AEAD模式（如GCM）保护数据不被篡改。

---

#### **七、常见问题**
1. **为什么需要预主密钥和主密钥？**  
   • 预主密钥通过密钥交换算法生成，主密钥结合随机数增强安全性，最终派生会话密钥。

2. **RSA与DH密钥交换如何选择？**  
   • 优先使用DH（如ECDHE），支持前向保密；RSA适用于旧系统兼容。

3. **证书吊销如何影响握手？**  
   • 若证书被吊销（通过OCSP Stapling），客户端会终止连接。

---

### **总结**
HTTPS通过TLS握手建立加密通道，核心在于**密钥交换**和**身份验证**。RSA密钥交换简单但缺乏前向保密，而DH（尤其是ECDHE）在安全性和性能上更优。TLS 1.3进一步优化流程，强制使用前向保密，提升安全与效率。理解这些原理有助于配置安全的HTTPS服务，防范中间人攻击和数据泄露风险。

## 两台机器如何用HTTP找到对方？

## 计算机网络输入URL到看到网页

## 访问一个网页的过程

**这三个问题本质上都是一个问题**

[参考链接，写的不错](https://mp.weixin.qq.com/s/iSZp41SRmh5b2bXIvzemIw)

- **1、浏览器首先会解析URL**

  比如有一个网址：`https://www.webserver.com/dir/file`，其解析过程如下图所示：                                                                                                                                                                                                             

  ![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203211344104.png)

- **2、浏览器确定了服务器和文件名后，会产生HTTP请求消息**

  可以根据具体请求来封装成get请求或者是post请求

- 3、DNS协议

  在发送给服务器地址之前，要先查询服务器域名对应的IP地址

  常考知识点：DNS解析过程

- **4、走本机网络的协议栈**

  通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的协议栈。

  HTTP本质是基于TCP/IP协议栈的，所以在发送HTTP报文之前需要先和对方主机建立TCP连接，连接建立后经过TCP协议和IP协议的封装后，形成一个网络报文，即**IP头部+TCP头部+HTTP报文**。

  但是当到达对方网络后还需要经过数据链路层传送给对方，因此还需要在ip头部前加入MAC头部，所以最终从我们客户端主机出去的报文就是**MAC头部+IP头部+TCP头部+HTTP报文**这么一个东西

- **5、经过本机网卡**

  这些数据本身是一串二进制信息，需要用网卡转成电信号，才能在网线上传输。

  网卡收到来自内核协议栈的数据后，会在开头加上报头和起始帧分界符，在末尾加上帧校验序列，如下图

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203211409575.png" alt="图片" style="zoom: 50%; float: left;" />

- **6、到达交换机**

  交换机主要工作在二层中，内部维护了一个MAC地址表，通过这个表查找对应MAC地址所在的端口上，从这个端口转发出去。

  当地址表中找不到指定的 MAC 地址时，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。只有相应的接收者才接收包，而其他设备则会忽略这个包。

- **7、路由器**

  路由器是工作在三层的网络设备，这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。

  路由器有MAC地址的，所以他可以成为接收方和发送方。

  收到包后会解开MAC地址查看其目的IP地址，根据路由表中的转发规则选择转发，如果没有匹配规则就使用默认路由，路由表中子网掩码为 `0.0.0.0` 的记录表示默认路由。

  知道对方的 IP 地址之后，接下来需要通过 `ARP` 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。



## traceroute原理

traceroute的作用：当源主机A向目标主机B发送消息，发现消息无法送达。此时，可能是某个中间节点发生了问题，比如路由器02因负载过高产生了丢包。此时，可以通过traceroute进行初步的检测，定位网络包在是在哪个节点丢失的，之后才可以进行针对性的处理。命令如下：

```shell
traceroute www.iqiyi.com
traceroute: Warning: www.iqiyi.com has multiple addresses; using 121.9.221.96
traceroute to static.dns.iqiyi.com (121.9.221.96), 64 hops max, 52 byte packets
 1  xiaoqiang (192.168.31.1)  1.733 ms  1.156 ms  1.083 ms
 2  192.168.1.1 (192.168.1.1)  2.456 ms  1.681 ms  1.429 ms
 # ... 忽略部分输出结果
 9  121.9.221.96 (121.9.221.96)  6.607 ms  9.049 ms  6.706 ms
```

> 注意，每次检测都同时发送3个数据包，因此打印出来三个时间。此外，如果某一个数据报超时没有返回，则时间显示为 *，此时需要特别注意，因为有可能出问题了

**原理如下：**

主机之间通信，网络层IP数据报的首部中，有个TTL字段(Time To Live)。TTL的作用是，设置IP数据报被丢弃前，最多能够经过的节点数。此外，每经过一个中间节点，再向下一个节点转发数据前，都会将TTL减1。如果TTL不为0，则将数据报转发到下一个节点；否则，丢弃数据报，并返回错误。

从源主机向目标主机发送IP数据报，并按顺序将TTL设置为从1开始递增的数字（假设为N），导致第N个节点（中间节点 or 目标主机）丢弃数据报并返回出错信息。源主机根据接收到的错误信息，确定到达目标主机路径上的所有节点的IP，以及对应的耗时。原理图如下：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203211441013.jpeg" alt="img" style="zoom:80%;float:left" />

- 问题1：用的UDP还是TCP协议

  答：UDP

- 问题二：当TTL为0时，接收节点会丢弃接数据报，并向源主机报错。这里的报错信息是什么？

  答：报错信息是ICMP（Internet Control Message Protocol）报文，它用于在主机、路由之间传递控制信息。

- 问题三：假设到达目标主机一共有N跳，且TTL刚好设置为N，那么，目标主机成功收到数据报，此时并没有错误回报，traceroute如何确定已经到达目标主机？

  答：traceroute发送UDP报文时，将目标端口设置为较大的值（ 33434 - 33464），避免目标主机B上该端口有在实际使用。当报文到达目标主机B，目标主机B发现目标端口不存在，则向源主机A发送ICMP报文（Type=3，Code=3），表示目标端口不可达。所以知道已经到达了目标主机



## dns的解析过程

DNS是应用层协议，事实上他是为其他应用层协议工作的，包括不限于HTTP和SMTP以及FTP，用于将用户提供的主机名解析为ip地址。

DNS服务器一般分三种，根DNS服务器，顶级DNS服务器，二级DNS服务器。

如果某个用户正在用浏览器`mail.baidu.com`的网址，当你敲下回车键的一瞬间：

1. 检查**浏览器缓存**中是否存在该域名与IP地址的映射关系，如果有则解析结束，没有则继续

2. 到**系统本地**查找映射关系，一般在`hosts`文件中，如果有则解析结束，否则继续
3. 到**本地域名服务器**去查询，有则结束，否则继续
4. **本地域名服务器**查询**根域名服务器**，该过程并不会返回映射关系，只会告诉你去下级服务器(顶级域名服务器)查询
5. **本地域名服务器**查询**顶级域名服务器**(即`com`服务器)，同样不会返回映射关系，只会引导你去二级域名服务器查询
6. **本地域名服务器**查询**二级域名服务器**(即`baidu.com`服务器)，引导去三级域名服务器查询
7. **本地域名服务器**查询**三级域名服务器**(即`mail.baidu.com`服务器)，此时已经是最后一级了，如果有则返回映射关系，则**本地域名服务器**加入自身的映射表中，方便下次查询或其他用户查找，同时返回给该用户的计算机，没有找到则网页报错
8. 如果还有下级服务器，则依此方法进行查询，直至返回映射关系或报错

像该过程中的第1、2、3点，仅限于在`本地域名服务器`中查找，如果有则直接返回映射关系，否则就去其他`DNS`服务器中查询，这种查询方式我们叫做**递归查询**。

第3、4、5、6、7、8过程，他们只会给出下级`DNS`服务器的地址，并不会直接返回映射关系，这种查询方式叫做**迭代查询**



**所有DNS请求和回答报文使用的UDP数据报经过端口53发送**

为什么用UDP？因为一次UDP名字服务器交换可以短到两个包：一个查询包、一个响应包。一次TCP交换则至少包含9个包：三次握手初始化TCP会话、一个查询包、一个响应包以及四次分手的包交换。考虑到效率原因，TCP连接的开销大得，故采用UDP作为DNS的运输层协议，这也将导致只有13个根域名服务器的结果。

但不一定全部都是UDP，比如DNS的规范规定了2种类型的DNS服务器，一个叫主DNS服务器，一个叫辅助DNS服务器。在一个区中主DNS服务器从自己本机的数据文件中读取该区的DNS数据信息，而辅助DNS服务器则从区的主DNS服务器中读取该区的DNS数据信息。当一个辅助DNS服务器启动时，它需要与主DNS服务器通信，并加载数据信息，这就叫做区传送(zone transfer)。区域传送时使用TCP，主要有一下两点考虑：②辅助域名服务器会定时(一般是3小时)向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。②区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多。



## cookie和session

[参考](https://www.nowcoder.com/questionTerminal/5a2d287965824d3ca93921bf89f8654c)



## UDP实现TCP功能

> 首先要明白为什么tcp没有基于udp实现？
>
> ①历史原因，tcp其实早于udp出现，改用udp重新实现的话，会导致一大波人要修改自己的代码。不管多烂，只要做的人多了你都没办法大改
>
> ②首先UDP就八个字节，加了个校验码啥都没有了。所以没什么能被tcp利用的，那我不如在ip层自己封装

[参考](https://www.cnblogs.com/pluto-charon/p/13777837.html)

如果用UDP实现TCP功能，需要实现以下事情：

1. 增加ack机制，确保能发送到对端
2. 增加seq机制，实现顺序化传输
3. 需要用队列实现缓冲区，主要是为了重传
4. 校验机制

**问：多说一嘴，为啥现在很多都自己实现TCP协议？**

答：因为慢启动和拥塞避免的缺点。

**问：在哪一层进行封装？**

答：在应用层。下一层的功能要用上一层来进行封装。



## TCP网络编程的本质（三个半事件）

TCP网络编程最本质的是处理三个半事件：

1. 连接建立：包括服务器端被动接受连接（accept）和客户端主动发起连接（connect）。TCP连接一旦建立，客户端和服务端就是平等的，可以各自收发数据。
2. 连接断开：包括主动断开（close、shutdown）和被动断开（read()返回0）。
3. 消息到达：文件描述符可读。这是最为重要的一个事件，对它的处理方式决定了网络编程的风格（阻塞还是非阻塞，如何处理分包，应用层的缓冲如何设计等等）。
4. 消息发送完毕：这算半个。对于低流量的服务，可不必关心这个事件；另外，**这里的“发送完毕”是指数据写入操作系统缓冲区（内核缓冲区）**，将由TCP协议栈负责数据的发送与重传，不代表对方已经接收到数据。



## 正向代理和反向代理

[参考链接](https://www.cnblogs.com/anker/p/6056540.html)

一张图就能说明问题

<img src="https://s2.loli.net/2022/07/15/DMzIaVSKu3O4nBm.png" alt="img" style="float: left;" />



## HTTP1.0和HTTP1.1的一些区别

HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。主要区别主要体现在：

1. **缓存处理**，在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
2. **带宽优化及网络连接的使用**，HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
3. **错误通知的管理**，在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
4. **Host头处理**，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。
5. **长连接**，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。



## HTTP1.0和HTTP2.0有什么区别

### 背景

1989年作为万维网交流标准，属于应用层协议，在客户端和服务器端进行信息交换。这个过程中，客户端发送一个基于文本的请求到服务器通过调用GET 或者POST方法。 相应的，服务器返回资源给客户端。

http2.0起初是通过SPDY协议而来的，SPDY是一个由 Google 主导的研究项目发明的HTTP替代协议。Google为了减少加载延迟而开发的，通过使用例如压缩，多路复用，优化等。 SPDY位于HTTP之下、TCP/SSL之上，这样可以轻松兼容老版本的HTTP协议，同时可以使用已有的SSL功能。SPDY优化了HTTP1.X的请求延迟，解决了HTTP1.X的安全性

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/2020-10-25T152800.png" alt="2020-10-25T152800.png" style="zoom:80%;float:left" />

### 新特性1：二进制分帧

TCP连接相当于两根管道（一个用于服务器到客户端，一个用于客户端到服务器），管道里面数据传输是通过字节码传输，传输是有序的，每个字节都是一个一个来传输。例如客户端要向服务器发送Hello、World两个单词，只能是先发送Hello再发送World，没办法同时发送这两个单词。不然服务器收到的可能就是HWeolrllod（注意是穿插着发过去了，但是顺序还是不会乱）。但是能否同时发送Hello和World两个单词能，当然也是可以的，可以将数据拆成包，给每个包打上标签。发的时候是这样的①H ②W ①e ②o ①l ②r ①l ②l ①o ②d。这样到了服务器，服务器根据标签把两个单词区分开来。

二进制分帧层 在 应用层(HTTP/2)和传输层(TCP or UDP)之间。HTTP/2并没有去修改TCP协议而是尽可能的利用TCP的特性。在二进制分帧层中， HTTP/2 会将所有传输的信息分割为帧（frame）,并对它们采用二进制格式的编码。

>二进制为何能提高数据传输效率：
>
>1. 根据协议约定，省去参数名所占用的字节，缩减了数据。
>2. 将数值类型的数据打包至相应范围内的二进制，节省了空间，4bytes能表示 32 位的文本数值，但文本数据值要 32bytes。
>3. 在一定程度上可以起到加密数据的作用，如果第三方不知道数据协议，就没有办法截取相应的字节为获取数据

### 新特性2：多路复用技术

HTTP 性能优化的关键并不在于高带宽，而是低延迟。TCP 有个慢启动的特性，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。由于这种原因，让原本就具有突发性和短时性的 HTTP 连接变的十分低效。HTTP/2 通过让所有数据流共用同一个连接，可以更有效地使用 TCP 连接，让高带宽也能真正的服务于 HTTP 的性能提升。

<img src="https://cdn.jsdelivr.net/gh/guaguaupup/cloudimg/data/2020-10-25T154800.png" alt="2020-10-25T154800.png" style="zoom:80%;float:left" />



### 新特性3：头压缩

在 HTTP/1 中，HTTP 请求和响应都是由「状态行、请求 / 响应头部、消息主体」三部分组成。一般而言，消息主体都会经过 gzip 压缩，或者本身传输的就是压缩过后的二进制文件（例如图片、音频），但状态行和头部却没有经过任何压缩，直接以纯文本传输。着 Web 功能越来越复杂，每个页面产生的请求数也越来越多，导致消耗在头部的流量越来越多，尤其是每次都要传输 UserAgent、Cookie 这类不会频繁变动的内容，完全是一种浪费。

> 压缩的原理:
>
> - 维护一份相同的静态表（Static Table），包含常见的头部名称，以及特别常见的头部名称与值的组合；
> - 维护一份相同的动态表（Dynamic Table），可以动态的添加内容；
> - 支持基于静态哈夫曼码表的哈夫曼编码（Huffman Coding）；







+++







# 传输层

## TCP 与 UDP 的区别

> 参考书籍笔记中linux高性能服务中第一个笔记

1. **连接：**

   TCP是面向连接的，传输数据前要先建立连接。

   UDP是无连接的

2. **可靠性：**

   通过TCP传输的数据无差错，不丢失，不重复，而且按序到达。

   UDP是尽最大努力交付，不保证数据到达后的可靠性。

3. **服务对象：**

   TCP链接是点到点服务，一条连接只能有两个端点。

   UDP可以一对一、一对多、多对多、多对一交互

4. **传输方式：**

   TCP是面向字节流的，但保证顺序和可靠。

   UDP面向报文，不会出现该问题、

5. **拥塞，流量控制：**

   UDP没有拥塞控制，导致网络出现拥塞时不会使得源主机发送数据速率降低

   TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。

6. **首部开销：**

   TCP首部开销20字节，如果使用了「选项」字段则会变长的。

   UDP首部8字节并且是固定不变的，开销较小。

7. **分片不同**

   TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。

   UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了一个分片，则就需要重传所有的数据包，这样传输效率非常差，所以通常 UDP 的报文应该小于 MTU。
   
   > **MSS和MTU**
   >
   > <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202202250931939.png" alt="MSS与MTU的关系_令牌环网" style="float: left;" />
   >
   > **MTU**：maximum transmission unit，最大传输单元，由硬件规定，如以太网的MTU为1500字节。主要在数据链路层
   >
   > **MSS**：maximum segment size，最大分节大小，为TCP数据包每次传输的最大数据分段大小，一般由发送端向对端TCP通知对端在每个分节中能发送的最大TCP数据。MSS值为MTU值减去IPv4 Header（20 Byte）和TCP header（20 Byte）得到。

## **UDP 、TCP 首部格式**

- UDP首部格式

  ​	<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210822162147.webp" alt="img" style="zoom:67%;" />

  1. 源端口号。需要对方回信时候可以用，不需要回复可以设置为0

  2. 目的端口。必须有，交付报文要用到。

  3. 长度。表示UDP首部和UDP数据的长度和，最小为8个字节。因为首部就8个字节

  4. 校验和。发送端计算，接收端验证，为了发现在数据收发间有无改动

     

- TCP首部格式

  ![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210822162156.jpeg)

  1. 源端口（16位）和目的端口（16位）
  
  2. 32位序列号。表示当前tcp数据第一个字节在整个字节流中的相对位置。一次TCP通信中某一个方向上的字节流的编号，第一个报文的序号值被系统初始化为某个随机值ISN，后序的TCP报文的序号值被设置成ISN+报文所携带数据的第一个字节序号。比如某个报文要传输的数据时字节流中的1025-2048字节，序号就是ISN+1025。
  
  3. 32位确认号。用来响应收到的TCP报文段。ack就是收到的32位序列号+1.

  4. 4位头部长度。表示TCP头部由多少个4字节组成。因为最多能表示15，所以15*4=60。
  
  5. 标志位(6位)
  
     - URG--表示本报文段的紧急指针是否有效。
     
     - ACK--确认标志，表示确认号是否有效。携带ack标志的报文段是确认报文段。
     - PSH--表示接收端应用程序是否应该立即从TCP缓存中读出该数据。如果应用程序不读走，就会一直在停留在TCP的接收缓冲区中。
     - SYN--同步标志，用于数据同步，有syn的报文段成为同步报文段。
     - FIN--表示数据是否发送完毕。FIN=1表示数据发送完毕，可以释放连接。有fin标志的成为结束报文段。
     - RST--该位置为1时表示tcp连接中出现异常必须强制断开
  
  6. 16位窗口大小。指的是通告窗口(Receiver Window, RWND)。这个用来告诉对方自己的接收缓冲区还能容纳多少数据，这样可以控制对方的发送速度。
  7. 16位校验和。检验数据的正确性，保证可靠性。不仅校验头部，也校验数据部分
  8. 16位紧急指针（2字节）。标记紧急字段在数据中的位置
  9. 以上一共20字节，还有40字节可选用字段。
  10. 数据部分



## TCP的特点

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202202250915293.png" alt="image-20220225091459903" style="zoom:67%; float:left" />

**面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；

**可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；

**字节流**：(无边界+有序的概念)消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃。





<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202202250919337.png" alt="image-20220225091921269" style="zoom:67%; float:left" />

TCP四元组可以唯一的确定一个连接。所以有一个问题比如：有一个 IP 的服务器监听了一个端口，它的 TCP 的最大连接数是多少？

首先服务器端地址确定了，源端口确定了，那么只有客户端的IP数和目标端口不确定，那不就是$2 ^ {32} \times 2^{16} = 2^{48}$。当然实际上并发的TCP连接数肯定达不到这么多：①**文件描述符限制**，Socket 都是文件，所以首先要通过 `ulimit` 配置文件描述符的数目；②**内存限制**，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的。

 

## ☆TCP三次握手

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210822164519.png" alt="UDP 报文" style="zoom: 67%;" />

注意该图客户端课服务器端分别所处于的阶段，客户端由两个阶段，服务器方有三个。

- 开始建立连接。服务器主动监听某个端口，处于`LISTEN`状态。

- 第一次握手

  客户端会随机初始化一个序号（ client_isn ），将此序号置于 TCP ⾸部的「序列号」字段中，同时把 SYN 标志位置为 1 ，表示这是一个 SYN 报⽂。接着把第⼀个 SYN 报⽂发送给服务端，表示向服务端发起连接，该报⽂不包含应⽤层数据，之后客户端处于 SYN-SENT 状态。

- 第二次握手

  服务端收到客户端的 SYN 报⽂后，⾸先服务端也随机初始化⾃⼰的序列号（ server_isn ），将此序号填⼊TCP ⾸部的「序列号」字段中，其次把 TCP ⾸部的「确认应答号」字段填⼊ client_isn + 1 , 接着把 SYN和 ACK 标志位置为 1 。最后把该报⽂发给客户端，该报⽂也不包含应⽤层数据，之后服务端处于SYNRCVD 状态。

  > 其实第二次握手细分的话包含两次，可以想一下。首先是服务器端收到了客户端的同步报文，然后发送一个ACK确认报文，ack=clien_isn+1，ACK标志位置为1。然后在发送一个同步报文段，FIN标志位置为1，随机初始化一个属于自己的序列号server_isn。这两部可以合并为1步发送而已

- 第三次握手

  客户端收到服务端报⽂后，还要向服务端回应最后⼀个应答报⽂，⾸先该应答报⽂ TCP ⾸部 ACK 标志位置为 1 ，其次「确认应答号」字段填⼊ server_isn + 1 ，最后把报⽂发送给服务端，**这次报⽂可以携带客户到服务器的数据**，之后客户端处于 ESTABLISHED 状态。等到服务器收到客户端的应答报⽂后，也进⼊ ESTABLISHED 状态。

**所以从上面可以看到，三次握手的前两次是不能携带数据的，只有第三次可以携带数据。因为经过两次握手，客户端收到ack确认报文段之后就已经建立了连接，表明服务端的接受和发送能力是正常的，当然可以传输局。**等到服务器收到来自客户端你的确认报文后，也表明客户端的接受和发送能力是正常的，就可以进行正常的全双工通信了。





## 为什么是三次握手

TCP最重要的就是序列号这个东西

之所以是三次握手的原因有三个，我想从大局上说一下为什么是三次，不是细致的解释。从客户端发起FIN同步报文段开始，其实是四段。TCP是一个全双工的通信方式，因此可以理解为两条单向通道。那么客户端发送FIN报文段给服务器端，服务器端发送ACK报文段这一个过程是一个单向通道的建立过程，表明服务器是完好的，可以收发数据。然后服务器到客户端这条通道同理也需要相同的过程，服务器发送FIN同步报文段给客户端，客户端返回一个ACK确认帧给服务器，这样一个全双工的通道就建立好了。而服务器发送的ACK确认帧和服务器发送的FIN同步报文段完全可以放在一起，不用分两次发送，所以就造成了三次握手。

然后在分析一下三次握手的原因或者说好处：

1. 阻止重复的历史连接
2. 同步双方的初始序列号
3. 避免资源浪费

- **避免历史连接**

  这个是RFC 793文档中说明的三次握手的主要原因。就是为了防止旧的重复连接初始化造成混乱。

  当网络拥堵的情况下，三次握手时一个客户端连续多次发送SYN建立连接的报文，造成一个旧的SNY报文比新的SYN早到服务器端。服务器端会回复一个SYN+ACK报文给客户端，客户端收到后会根据自身的上下文判断这是否是一个历史连接，如果是历史连接则发送一个RST报文给服务器端表示终止。

  比如SYN1的ISN=90，SYN2的ISN=100，那么如果服务器端先收到SYN1的话，发送过来的ACK=90+1，但是客户端期望收到ACK=100+1，所以客户端知道这个给我回复的ACK报文段是历史连接的，我必须发送一个RST报文告诉服务器端终止由这个SYN90报文引起的连接。等SYN100到了我就发送ACK确认报文给服务器端，从而建立连接。

- **同步双方序列号**

  要记住“序列号”这个东西是TCP保持可靠顺序传输的关键。通过序列号这个东西接收方可以做三件事：

  1. 去除重复连接
  2. 根据数据报的序列号按序接收
  3. 可以标识发出去的数据包有哪些被接受了

  这就是我上面说的双方同步序列号其实是四次握手，但是二三次握手可以优化成一步，也就是三次握手了。而两次握手只能保证一方的序列号成功被对方接受，而不能保证双方序列号都被互相接受。

- **避免资源浪费**

  在多次行不行，当然行，但是四次已经优化成三次了，再多的话就浪费没必要了。





## 初始序列号（ISN）

`ISN` 全称是 `Initial Sequence Number`，是 TCP 发送方的字节数据编号的原点，告诉对方我要开始发送数据的初始化序列号。

ISN不是固定的， 如果是固定的，攻击者很容易猜出后续的确认序号，为了安全起见，避免被第三方猜到从而发送伪造的 `RST` 报文，因此 ISN 是动态生成的

> - 为什么ISN是动态生成的？
>
>   1. 通过SYN来判断这个连接是失效的还是有效的，不然你无法判断会出现错乱。所以每次连接前重新初始化一个序列号就是为了能够使得通信双反根据序号将不属于本次连接的报文段丢弃掉
>
>   1. 安全性，防止黑客伪造相同序号的TCP报文被对方接受
>
> - 为什么客户端和服务端的初始序列号 ISN 是不相同的？
>
>   因为相同的话就可动态生成违背了啊，前面说了ISN只能动态生成，你还让客户端和服务端相同，那不得提前协商？还没建立连接了在提前协商？
>
> - 初始序列号 ISN 是如何随机产⽣的？
>
>   $ISN = M + F (localhost, localport, remotehost, remoteport)$
>
>   M 是⼀个计时器，这个计时器每隔 4 毫秒加 1。 
>
>   是⼀个 Hash 算法，根据源 IP、⽬的 IP、源端⼝、⽬的端⼝⽣成⼀个随机数值。 MD5 ,SHA1都可以



## 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

关于什么是MSS，什么是MTU在[TCP 与 UDP 的区别](#TCP 与 UDP 的区别)中有详细说明

当 IP 层有⼀个超过 MTU大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，保证每⼀个分片都小于 MTU。把⼀份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后再交给上⼀层 TCP 传输层。**那么当如果⼀个** **IP** **分片丢失，整个** **IP** **报文的所有分片都得重传**。这是因为IP层本身没有重传机制，他只是高效的发送数据而已，没有协议来保证完整性。当接收方TCP报文不完整后不会响应ACK的，那么TCP发送方就会触发超时重传，重发整个TCP报文段。这样做就非常没有效率可言。

所以为了提高效率，在建立连接的时候会剔除IPHeader和TCPHeader，剩下的就是协商的MSS值，当TCP发现超过MSS后就会分片，这样形成的IP包长度也就不会大于MTU了，也就不用IP分片了。



## 半连接队列(SYN队列)和全连接队列(accept队列)

当服务器第一次收到客户端的 `SYN` 之后，就会处于 `SYN_RCVD` 状态，此时双方还没有完全建立连接。服务器会把这种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列也叫做SYN队列

在第三次握手后，服务端收到ACK确认报文后，从SYN队列中移除放到accept队列中，通过调用accept() socketAPI 从accept队列中取出连接

队列满了就有可能会出现丢包现象。

- 如何增大半连接队列？

  首先`max_qlen_log`表示半连接队列的值

  如果`max_sys_backlog > min(somaxconn, backing)`，则`max_qlen_log = min(somaxconn, backing)*2`

  如果`max_sys_backlog <= min(somaxconn, backing)`，则`max_qlen_log = max_sys_backlog*2`

- 如何增大全连接队列

  TCP 全连接队列的最大值取决于 somaxconn 和backlog之间的最小值，也就是min(somaxconn, backlog)。

  `somaxconn`是 Linux 内核的参数，默认值是 128，可以通过 `/proc/sys/net/core/somaxconn `来设置其值；

  `backlog`是listen(int sockfd, int backlog) 函数中的 backlog大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；



## 什么是 SYN 攻击？如何避免 SYN 攻击？

**定义：**假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到⼀个 SYN 报文，就进入SYN_RCVD 状态，但是服务器发送的ACK+SYN无法得到应答， 久而久之服务器端的SYN接收，即半连接队列就会被占满，正常用户发送的STN报文无法被存储，服务器无法提供其他服务。

**如何避免：**

1. 通过修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理。扩大队列大小，队列满时对新的SYN报文直接回复RST，然后丢弃掉。这样治标不治本吧
2. 当SYN队列满了之后，服务器如果再次收到SYN同步报文，不将该连接放入同步队列。服务器会计算出一个cookie值，以SYN+ACK中的序列号返回给客户端。当服务端再次收到客户端的ACK时会检查其合法性，如果合法再放到ACCEPT队列中





## 三次握手中可以携带数据吗

第一次、第二次握手不可以携带数据，而第三次握手是可以携带数据的。

假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据，疯狂着重复发 SYN 报文，这会让服务器花费大量的内存空间来缓存这些报文，这样服务器就更容易被攻击了。

对于第三次握手，此时客户端已经处于连接状态，他已经知道服务器的接收、发送能力是正常的了，所以可以携带数据是情理之中。



## ☆TCP四次挥手<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20210822184132.png" alt="UDP 报文" style="zoom:67%;" />

TCP是全双工的通信，因此收发双方都各有一个写缓存和读缓存。

- 第一次握手

  客户端打算关闭连接，此时会发送⼀个 TCP首部 FIN 标志位被置为 1 的报⽂，也即 FIN 报⽂，之后客户端进入FIN_WAIT_1 状态。

- 第二次握手

  服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。

- 第三次握手

  等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态

- 第四次握手

  服务器收到了 `ACK` 应答报文后，就进入了 `CLOSED` 状态，至此服务端已经完成连接的关闭。客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSED` 状态，至此客户端也完成连接的关闭。



## 为什么需要四次挥手？

我一直把TCP之间的通信看两条管道组成的全双工通信。我们来看这种抽象的比喻，如果要关闭这两条管道的通信要几个步骤？很明显是四个，首先A端告诉B端我要关了，B端收到后说好的。那么A到B端的就关掉了。然后B端告诉A端我这边也要关掉了，A端说好的，那么B到A的也就关掉了，你看，这也需要四次。

那么回到TCP中来，首先第一次客户端向服务器端发送FIN通知服务器端我这边要断掉了，不给你发数据了，这一次是必然的。还有最后一次，客户端给服务器端恢复一个ACK表示你关吧我知道了。这两次是必须的。那么第二次和第三次我们看一下。由于服务器端要处理一些数据然后发送给客户端，所以第二次和第三次是无法合并到一起的。所以当服务器端收到客户端的FIN报文段后，必须马上回一个ACK确认报文表示可以关，但此时可能服务器端有一些数据需要处理，所以说等处理完数据我再发一个FIN关闭报文给客户端告诉客户端我这边也要关闭了。



## TIME_WAIT状态

客户端收到了来自服务器的带有FIN、ACK的结束报文段后并没有直接关闭，而是进入了TIME_WAIT状态。

> 在这个状态中客户端只有等待2MSL(Maximum Segment Life，报文段最大生存时间)才能完全关闭。它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃，RFC文档的建议值是2分钟。为啥有这个，因为TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。MSL 与 TTL 的区别：MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

- **为什么 TIME_WAIT 等待的时间是 2MSL？以及为什么被动关闭以防不需要？**

  答：通信要解决的首要问题是同步，即双方处于信息对称的情况下。我们来看最后两次挥手，当服务器端发送FIN给客户端的时候，服务端是不能当方面释放掉连接的，因为他不知道客户端收没收到自己的FIN，所以服务器必须要等待客户端发送的ACK过来，才能安全的释放TCP连接所占用的内存资源，端口号。所以服务器作为被动关闭的一方，是无需任何TIME_WAIT状态的。服务器收到ACK就表明我已经知道客户端知道我要关闭连接了，放心关闭

  那么此时看客户端，他发送ACK给服务器端后，客户端并不知道服务端有没有收到这个报文，客户端会这么想：

  1. 服务器没收到ACK，我就等着超时重传
  2. 服务器收到自己的ACK了，也不会发消息

  可以发现，不管上面哪一种情况，客户端都必须要等带，而且要取最大值以应对最坏的情况发生，**这个最坏情况就是①客户端发送ACK到服务器端的报文最大存活时间+②服务器端从新发送FIN到客户端的报文最大存活时间即2MSL。**

- **为什么需要TIME_WAIT？如果没有TIME_WAIT或者TIME_WAIT很短怎么办？**

  首先要明白，只有主动发起关闭的一方才有TIME_WAIT状态。

  - 防止具有相同「四元组」的「旧」数据包被收到

    假如在客户端向服务端发送FIN即第一次挥手之前，服务器端发送了一个报文给客户端，但因为网络原因这个报文延迟到达了，那么如果TIME_WAIT没有或者太短，由于这个报文具有相同的四元组的旧报文，可能会和新TCP连接的新报文起冲突。

  - 保证连接正确关闭

    即为什么需要2MSL的原因，上面有不再说了。

- **TIME_WAIT过多有什么危害？**

  - 占用内存资源

  - 占用端口的资源

    由于客户端使用系统自动分配的临时端口号来建立连接，所以一般不用考虑这个问题。但是服务器可能要考虑，因为服务器的端口号一般是固定的。

- **如何优化TIME_WAIT？**

  - Linux内核中有一个默认值18000，当系统中的TIME_WAIT一旦超过这个值，系统就会将后面TIME_WAIT连接状态重置。
  
- **服务端出现大量TIME_WAIT的原因**

  先来说一说长连接和短连接，在HTTP1.1协议中，有个 Connection 头，Connection有两个值，close和keep-alive，这个头就相当于客户端告诉服务端，服务端你执行完成请求之后，是关闭连接还是保持连接。如果服务器使用的短连接，那么每次客户端请求后，服务器都会主动发送FIN关闭连接。最后进入time_wait状态。可想而知，对于访问量大的Web Server，会存在大量的TIME_WAIT状态。让服务器能够快速回收和重用那些TIME_WAIT的资源，可以修改内核参数。

- **解决办法**
  1. 客户端：HTTP 请求的头部，connection 设置为 keep-alive，保持存活一段时间：现在的浏览器，一般都这么进行了
  2. 服务端：允许 time_wait 状态的 socket 被重用， 缩减 time_wait 时间，设置为 1 MSL（即，2 mins）

  





## 建立连接但是客户端出现故障怎么办？

**TCP的保活机制：**当在某个时间段内没有任何连接相关的活动，该机制就会每隔一个时间间隔发送一个探测报文，该报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前连接已经死亡，内核会通知应用程序然后中断连接

Linux的默认值如下：

1.  net.ipv4.tcp_keepalive_time=7200	//保活时间
2. net.ipv4.tcp_keepalive_intvl=75 	//每次检测间隔时间
3. net.ipv4.tcp_keepalive_probes=9		//探测次数，9此后中断连接

有三种情况需要注意一下：

1. 对端程序是正常⼯作的。当 TCP 保活的探测报⽂发送给对端, 对端会正常响应，这样 **TCP** **保活时间会被**

   **重置**，等待下⼀个 TCP 保活时间的到来。

2. 对端程序崩溃并重启。当 TCP 保活的探测报⽂发送给对端后，对端是可以响应的，但由于没有该连接的

   有效信息，**会产生⼀个** **RST** **报⽂**，这样很快就会发现 TCP 连接已经被重置

3. 对端程序崩溃没有重启，或者报文不可达，达到保活探测的最大次数之后会报告该连接已经死亡。



## TCP 黏包问题

原因：

1. 本质原因：由于TCP是面向字节流传输的，因此数据没有确切的边界，会出现前后两个数据包黏在一起的情况。
2. 发送方。TCP默认使用nagle算法，为了减少网络中报文段的数量。主要有两步，首先上一个分组得到确认后才能发送下一个分组。其次，收集多个小分组然后一起发送。
3. 接收方。当接收方收到数据后不会马上交到应用层去处理，因为发送方和接收方各有两个缓冲空间。接收方收到数据后会将数据放到接收方的读缓存中。这样如果读取的速度小于接收的速度，应用程序可能会读到多个首尾相连的包。

解决方案：

1. 发送方。关闭nagle算法就行+
1. 接收方。没办法交给应用层
3. 应用层。粘包的原因是不确定消息的边界。所以只要能识别消息边界就行。比如加入特殊标志，头标志消息尾标志这样，或者加入每段消息的长度



## TCP 协议保证可靠传输的手段

- 三次握手，建立可信的传输信道

- 校验和，接收端可以检测出来数据是否异常。

- [流量控制](#TCP流量控制)

- [拥塞控制](#TCP拥塞控制)

- 停止等待ARQ协议

  它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。

- 重传机制

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203211141026.png" alt="image" style="zoom:67%;float:left" />



## 重传机制

### 超时重传

超时重传指的是发送数据包在一定的时间周期内没有收到相应的ACK，等待一定的时间，超时之后就认为这个数据包丢失，就会重新发送。这个等待时间被称为RTO.  

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202202282307594.png" alt="image-20220228230707468" style="zoom: 67%; float: left;" />

检测丢失segment的方法从概念上讲还是比较简单的，每一次开始发送一个TCP segment的时候，就启动重传定时器，定时器的时间一开始是一个预设的值（Linux 规定为1s），随着通讯的变化以及时间的推移，这个定时器的溢出值是不断的在变化的，有相关算法计算RTO，如果在ACK收到之前，定时器到期，协议栈就会认为这个片段被丢失，重新传送数据。

TCP在实现重传机制的时候，需要保证能够在同一时刻有效的处理多个没有被确认的ACK，也保证在合适的时候对每一个片段进行重传，有这样几点原则：

1.  这些被发送的片段放在一个窗口中，等待被确认，没有确认不会从窗口中移走，定时器在重传时间到期内，每个片段的位置不变，这个地方其实在滑动窗口的时候也有提到过
2. 只有等到ACK收到的时候，变成发送并ACK的片段，才会被从窗口中移走。
3. 如果定时器到期没有收到对应ACK， 就重传这个TCP segment

超时时间应该率大于报文往返RTT的值，RTT即网络从一段传送到另一端所需的时间。由于网络是在时常变换，因此RTT的值也经常波动。如果超时重发的数据又再次超时的时候，又需要重传，那么这个超时时间间隔加倍。当两次超时时，就说明网络环境不行，不适合频繁反复发送数据。超时重传的问题是超时时期可能比较长，有没有更快的方式呢？有的，就是下面的快速重传，用来解决超时重发的时间等待问题。



### 快速重传

看一张图你就明白了什么叫做快速重传。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203010948839.png" alt="image-20220301094802223" style="zoom:67%;float:left" />

当seq1发送后被接收方收到，接收方会返回一个ACK2和一个同步报文段。但是seq2没有到达接收方，则后面不论接收方收到了那个数据都是回ACk2，当发送方连续收到了三个ACK2就表明seq2没有被接收方收到，就会重发。但是问题在于通过重复确认机制，我们每次只能传送一个包，如果有多个包丢失，在传送过程中可能会造成timeout，造成带宽利用率下降

### SACK

SACK是一个TCP的选项，来允许TCP单独确认非连续的片段，用于告知真正丢失的包，只重传丢失的片段。

**超时重传和快速重传的困境：**快速重传和超时重传都会面临到一个重传什么包的问题，因为发送端也不清楚丢失包后面传送的数据是否有成功的送到。主要原因还是对于TCP的确认系统，不是特别的好处理这种不连续确认的状况了，只有低于ACK number的片段都被收到才有进行ACK，out-of-order的片段只能是等待，同时，这个时间窗口是无法向右移动的。

> 举个例子： 服务器发送4个片段给客户端，seg1(seq=1,len=80),seg2(seq=81,len=120), seg3(seq=201,len=160),seg4(seq=361,len=140)。服务器收到seg1和seg2的ACK = 201，所以此时seg1 seg2变成发送并已经确认范畴的数据包，被移除滑动窗口，此时服务器又可以多发80+120 byte数据。 假设seg3由于某些原因丢失，这个时候服务器仍然可以像客户端发送数据，但是服务器会等待seg3的ACK，否则窗口无法滑动，卡主了。seg3丢失了，即使后面的seg4收到了，客户端也无法告知服务器已经收到了seg4，试想一下，如果窗口也够大，服务器可以继续持续发送更多的片段，那么这些片段被客户端接收，只能存放到队列中，无法进行确认。
>
> 在这种情况下如果丢失了一个包那还好，只传一个丢失的包。但是如果丢失了很多包，就需要一个一个等待，浪费时间。

还有一个实现重传机制的方式就是sack（选择性确认）。如果开启sack，每一个sack段记录的是已经收到的连续的包，sack段与sack段之间断片的，也就是还没收到的（可能已经丢失，也可能是reorder）。通过sack段便可以知道多个可能已经丢失的包，这样便可以一次性的重传，而不是一个一个重传，避免因等待时间长造成的timeout问题。

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203011009627.png" style="zoom:80%;float:left" />

要注意的是开启sack选项，也是有弊端的，因为丢包意味着网络很可能已经拥塞，这时如果一次重传多个包，很可能会造成网络更加拥塞。



## 滑动窗口

最开始TCP是每发送一个数据就要进行一次确认应答，当上一个数据包收到了应答，再发送下一个。这种模式就像是面对面聊天，效率比较低下。因此引入窗口的概念：

既然引入了窗口那么必然有窗口大小这个概念，窗口大小就是无需等待确认应答，可以继续发送数据的最大值。窗口的实现实际上是操作系统开辟了一个缓存空间，发送方主机在确认应答返回之前必须在缓冲区中保留发送的数据，如果收到确认应答就可以抹去缓存的数据。

总结：滑动窗口机制是TCP的一种流量控制方法，该机制允许发送方在停止并等待确认前连续发送多个分组，而不必每发送一个分组就停下来等待确认，从而增加数据传输的速率提高应用的吞吐量。

- 发送窗口

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203022252110.png" alt="image-20220302225203971" style="float: left;" />

  其中2和3部分是需要重点关注的。有两个指针和一个位偏移量来控制着窗口的大小。

  1. 第一个指针指向已发送但未收到确认的第一个字节的序列号
  2. 第二个指针指向未发送但是可以发送的第一个字节的序列号
  3. 第三个是偏移量，是第一个指针+发送窗口大小

- 接收窗口（接收方的）

  <img src="C:\Users\ACER\AppData\Roaming\Typora\typora-user-images\image-20220302225829034.png" alt="image" style="float: left;" />

因为滑动窗⼝并不是⼀成不变的。⽐如，当接收⽅的应⽤进程读取数据的速度⾮常快的话，这样的话接收窗⼝可以很快的就空缺出来。那么新的接收窗⼝⼤⼩，是通过 TCP 报⽂中的 Windows 字段来告诉发送⽅。那么这个传输过程是存在时延的，所以接收窗⼝和发送窗⼝是约等于的关系。



## TCP流量控制

TCP不能无脑发，如果接收方处理能差，发送方还无脑发送时候，就会触发重发机制，使得网络拥塞，因此TCP提供了一种机制让发送方根据接收方的实际接受能力控制发送的数据量。

这种机制如何工作？

接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把缓存区的剩余大小称之为接收窗口大小，用变量win来表示接收窗口的大小。发送方收到之后，便会调整自己的发送速率，也就是调整自己发送窗口的大小，当发送方收到接收窗口的大小为0时，发送方就会停止发送数据，防止出现大量丢包情况的发生。

当发送方停止发送数据后，该怎样才能知道自己可以继续发送数据？有两个方案：

1. 当接收方处理好数据，接受窗口 win > 0 时，接收方发个通知报文去通知发送方，告诉他可以继续发送数据了。当发送方收到窗口大于0的报文时，就继续发送数据。

   问题：假如接收方发送的通知报文，由于某种网络原因，这个报文丢失了，这时候就会引发一个问题：接收方发了通知报文后，继续等待发送方发送数据，而发送方则在等待接收方的通知报文，此时双方会陷入一种僵局（死锁）。

2. 当发送方收到接受窗口 win = 0 时，这时发送方停止发送报文，并且同时开启一个定时器，每隔一段时间就发个测试报文（窗口探测报文）去询问接收方，打听是否可以继续发送数据了，如果可以，接收方就告诉他此时接受窗口的大小；如果接受窗口大小还是为0，则发送方再次刷新启动定时器。

[详细查看此链接](https://www.cnblogs.com/kubidemanong/p/9987810.html)

+++



## TCP拥塞控制

> 流量控制是防止发送的报文无脑发送填满接收方的缓存，这其中发送方和接收方不知道网络环境是如何变化的，因此当网络出现拥塞的时候，可能会导致包的传输时延增加，丢包等问题，由于重传机制，会进入恶性循环。
>
> 因此当网络发生拥塞的时候，TCP就要牺牲自我。所以可以冲如何知道拥塞，怎么避免拥塞两个方向入手。
>
> 拥塞控制最直接的目的就是避免发送方的数据填满整个网络



为了能够达到发送方随时调节发送数据量的问题，定义了一个叫做拥塞窗口的概念。拥塞窗口(CWND)是发送方维护的一个状态变量，根据网络阻塞情况实时的变化。当加入拥塞窗口的概念后，发送窗口=min(接收窗口，拥塞窗口)。拥塞窗口的变化规则也非常的简单：网络中没有出现拥塞，CNWD就会增大；网络中出现拥塞，CNWD就会检查少。



**那么问题就来了：如何定义网络拥塞？**

答：只要发送方没有在规定时间内收到ACK确认报文，也就是发生了超时重传，就认为网络出现了拥塞。



拥塞控制主要由四部分组成：

1. 慢启动
2. 拥塞避免
3. 拥塞发生
4. 快速恢复

如下图所示：

<img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203022325749.png" alt="image-20220302232524645" style="float: left;" />

- **慢启动**

  TCP在刚建立连接后，就会一点一点的提高发送数据包的速率，规则是：**当发送方每收到一个ACK确认报文，就会将拥塞窗口CWND的大小+1。**如图所示：

  <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202203041150919.png" alt="image-20220304115053693" style="zoom:50%;float:left" />

  CNWD也不是无限增长的，总有一个门限阈值，记作ssthresh。当cnwd小于这个阈值的时候就用慢启动算法，当大于等于这个阈值的时候就是用拥塞避免算法。

- **拥塞避免**

  当慢启动的cnwd窗口大于阈值，就会启动拥塞避免算法。

  拥塞避免的规则是：**每收到一个ACK时，cnwd增加1/cnwd**，就变成了线性增长，在图上就是线性的。

  从原先的指数增长变成了线性增长，增长速度变得缓慢了。

  最开始只有慢启动和拥塞避免两个算法，因为有时个别报文会在网络中丢失导致超时重传并误认为网络中发生拥塞，这个时候发送发错误的启动慢开始算法，并重新把拥塞窗口的值设置为1，降低了传输效率。如下图所示：

  <img src="C:\Users\ACER\AppData\Roaming\Typora\typora-user-images\image-20220322103501953.png" alt="image" style="zoom:67%;float:left" />

  这样看，是不是有点傻逼呢？因此又引入了快重传和快恢复这种情况。

- **快重传**

  由于TCP有两种重传机制，即超时重传和快速重传，因此这两种重传机制引起的拥塞发生算法不同。

  当发生超时重传时，ssthresh即阈值设为cnwd/2，然后cnwd=1，接着重新开始慢启动。

  但是这种方式太激进，一下子就会回到解放前，就是我之前上面说的，拥塞控制只有这两种方案。

  但是TCP还是有更好的方式，即快速重传算法。快重传就是要求接受方赶紧进行重传，不要等待计时器到时后再重传。当接收方发现中丢包时，就会发送同一个ACK三次，发送端就需要快速重传，不必等待超时重传。这种情况下TCP机制认为网络阻塞不是很严重，因为大部分都收到了，只有一小部分没有收到。

- **快速恢复**

  快速恢复有很多算法

  快速重传机制和快速恢复机制一般都是同时使用的，机制如下：

  1. 门限阈值设置为cnwd/2。
  1. 拥塞窗口cnwd=阈值ssthresh+3（3是因为收到三个重复确认表示有三个报文段离开网络，这三个报文在接收方缓存中而不再网络中）
  2. 重传丢失的数据包
  3. 如果收到了重复的ACK，则cnwd+1
  4. 如果收到新的ACK后，窗口值设为ssthresh，退出



+++



## tcp内核参数—优化

   [参考链接](https://mp.weixin.qq.com/s/fjnChU3MKNc_x-Wk7evLhg)



## tcpdump

**命令：**

支持命令行格式，常在Linux服务器中抓取和分析网络报

```shell
tcpdump –i eth0 ’port 1111‘ -X -c 3
```

`-i`：指定监听的网络接口；

`-c`：在收到指定的包的数目后，tcpdump就会停止；

`-X`：告诉tcpdump命令，需要把协议头和包内容都原原本本的显示出来（tcpdump会以16进制和ASCII的形式显示），这在进行协议分析时是绝对的利器。

```
[root@linux ~]# tcpdump -i lo -nn
 1 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
 2 listening on lo, link-type EN10MB (Ethernet), capture size 96 bytes
 3 11:02:54.253777 IP 127.0.0.1.32936 > 127.0.0.1.22: S 933696132:933696132(0) win 32767 
 4 11:02:54.253831 IP 127.0.0.1.22 > 127.0.0.1.32936: S 920046702:920046702(0) ack 933696133 win 32767 
 5 11:02:54.253871 IP 127.0.0.1.32936 > 127.0.0.1.22: . ack 1 win 8192 
 6 11:02:54.272124 IP 127.0.0.1.22 > 127.0.0.1.32936: P 1:23(22) ack 1 win 8192 
 7 11:02:54.272375 IP 127.0.0.1.32936 > 127.0.0.1.22: . ack 23 win 8192

```

**能抓那些包？**

TCP，UDP

抓取 HTTP GET和 HTTP POST 请求流量

抓取 ICMP 数据包：`tcpdump -n icmp`

抓取 DHCP 报文: `tcpdump -v -n port 67 or 68`

**wireshark：**除了可以抓包，可以提供可视化的网络报分析同行



## tcp延迟确认与nagle算法

tcp报文传输的数据很小，甚至小于头部20字节的时候，由于报文有效占比很低，有两种策略来减少小报文的传输：Nagle算法和延迟确认。

- Nagle算法

  Nagle算法主要是避免发送小的数据包，要求TCP连接上最多只能有一个未被确认的小分组，在该分组的确认到达之前不能发送其他的小分组。

  当发送缓冲中有多个这样的小分组的话，就收集这些小分组，组成一个大的tcp报文发送出去

  这个算法是默认打开的，如果一些小数据包交互的场景比如ssh这种，则需要关掉

- 延迟确认

  由于ACK确认报文没有携带数据，却有20字节的tcp头部和20字节的IP头部，因此传输的时候效率是很低的。

  延迟确认如下：

  1. 当有响应数据需要发送的时候，ack会随着响应数据一起发送
  2. 当没有响应数据时，ACK将会延迟一段时间，以等待是否有数据然后一起发送
  3. 如果在第二步延迟确认等待期间第二个数据报文有到达了，就会立刻发送ACK



## TCP 四种定时器

- 重传计时器：Retransmission Timer

  重传定时器：为了控制丢失的报文段或丢弃的报文段，也就是对报文段确认的等待时间。当TCP发送报文段时，就创建这个特定报文段的重传计时器，可能发生两种情况：若在计时器超时之前收到对报文段的确认，则撤销计时器；若在收到对特定报文段的确认之前计时器超时，则重传该报文，并把计时器复位；

- 坚持计时器：Persistent Timer

  当发送端收到零窗口的确认时，就启动坚持计时器，当坚持计时器截止期到时，发送端TCP就发送一个特殊的报文段，叫探测报文段，这个报文段只有一个字节的数据。探测报文段有序号，但序号永远不需要确认，甚至在计算对其他部分数据的确认时这个序号也被忽略。探测报文段提醒接收端TCP，确认已丢失，必须重传。

  坚持计时器的截止期设置为重传时间的值，但若没有收到从接收端来的响应，则发送另一个探测报文段，并将坚持计时器的值加倍和并复位，发送端继续发送探测报文段，将坚持计时器的值加倍和复位，知道这个值增大到阈值为止（通常为60秒）。之后，发送端每隔60s就发送一个报文段，直到窗口重新打开为止；

- 保活计时器：Keeplive Timer

  每当服务器收到客户的信息，就将keeplive timer复位，超时通常设置2小时，若服务器超过2小时还没有收到来自客户的信息，就发送探测报文段，若发送了10个探测报文段（没75秒发送一个）还没收到响应，则终止连接。

- 时间等待计时器：Time_Wait Timer。

  在连接终止期使用，当TCP关闭连接时，并不认为这个连接就真正关闭了，在时间等待期间，连接还处于一种中间过度状态。这样就可以时重复的fin报文段在到达终点后被丢弃，这个计时器的值通常设置为一格报文段寿命期望值的两倍。



## 服务器bind后没有调用listen监听socket连接会发生什么？

首先服务器会报错，肯定是连接不上

**那么在TCP这里是表现为客户端对服务器发送SYN同步报文之后，服务端回复了RST报文。**

分析：由于没用调用listen，因此找不到监听该端口的socket，因此函数找不到socket后会跳转到函数`no_tcp_socket`这个错误处理函数中，然后错误处理函数有好几种if语句，会检验豹纹的校验和，报文校验和没问题就会调用函数`tcp_send_reset`函数，发送RST报文终止连接。



## 如何正确关闭TCP连接？

[参考](https://blog.csdn.net/weixin_43919932/article/details/121428759)

[参考](https://ysw1912.github.io/post/network/how_to_close_tcp_connection_correctly/)



## 服务端主动关闭连接，客户端会发生什么？

如果是服务端主动发起关闭，此时四次挥手的顺序会颠倒。那么此时客户端再向服务端发送数据时，根据TCP协议的规定，认为它是一个异常终止连接，客户端将会收到一个**RST复位**响应(而不是ACK响应)，如果客户端再次向服务端发送数据，系统将会发送一个**SIGPIPE信号**给客户端进程，告诉客户端进程该连接已关闭，不要再写了。系统给SIGPIPE信号的默认处理是直接终止收到该信号的进程，所以此时客户端进程会被极不情愿地终止。





+++

+++



# 网络层

## IP协议

IP协议（Internet Protocol，互联网协议），是TCP/IP协议栈中最核心的协议之一，通过IP地址，保证了联网设备的唯一性，实现了网络通信的面向无连接和不可靠的传输功能。

![img](https://img-blog.csdn.net/20170301092349308)

**版本**：IP协议的版本，目前的IP协议版本号为4，下一代IP协议版本号为6。

**首部长度**：IP报头的长度。固定部分的长度（20字节）和可变部分的长度之和。共占4位。最大为1111，即10[进制](https://so.csdn.net/so/search?q=进制&spm=1001.2101.3001.7020)的15，代表IP报头的最大长度可以为15个32bits（4字节），也就是最长可为15*4=60字节，除去固定部分的长度20字节，可变部分的长度最大为40字节。

**服务类型**：Type Of Service。

**总长度**：IP报文的总长度。报头的长度和数据部分的长度之和。

**标识**：唯一的标识主机发送的每一分数据报。通常每发送一个报文，它的值加一。当IP报文长度超过传输网络的MTU（最大传输单元）时必须分片，这个标识字段的值被复制到所有数据分片的标识字段中，使得这些分片在达到最终目的地时可以依照标识字段的内容重新组成原先的数据。

**标志**：共3位。R、DF、MF三位。目前只有后两位有效，DF位：为1表示不分片，为0表示分片。MF：为1表示“更多的片”，为0表示这是最后一片。

**片位移**：本分片在原先数据报文中相对首位的偏移位。（需要再乘以8）

**生存时间**：IP报文所允许通过的路由器的最大数量。每经过一个路由器，TTL减1，当为0时，路由器将该数据报丢弃。TTL 字段是由发送端初始设置一个 8 bit字段.推荐的初始值由分配数字 RFC 指定，当前值为 64。发送 ICMP 回显应答时经常把 TTL 设为最大值 255。

**协议**：指出IP报文携带的数据使用的是那种协议，以便目的主机的IP层能知道要将数据报上交到哪个进程（不同的协议有专门不同的进程处理）。和端口号类似，此处采用协议号，TCP的协议号为6，UDP的协议号为17。ICMP的协议号为1，IGMP的协议号为2.

**首部校验和**：计算IP头部的校验和，检查IP报头的完整性。

**源IP地址**：标识IP数据报的源端设备。

**目的IP地址**：标识IP数据报的目的地址

## **网关是什么呢？**

## 什么是ARP欺骗

## 为什么IP地址和MAC地址缺一不可？

首先要充分了解网络分层的作用。网络层使用Ip协议将不同数据链路类型（以太网，3g，LAN）的数据报文统一成相同的形式在网络层中可以互相传播，达到任意具有IP地址的主机。但是数据传输总要经过底层，经过线路传输。这时候就是数据链路层起到了作用，不同链路类型所使用的协议方案都不尽相同，但是在链路层不能使用IP地址了，这时候要找到相对应的主机我就需要MAC地址的作用。

第二若是只使用MAC进行通信，那么一个路由表就要维护差不多2的48次方数据，大约256TB的内存，这样存储和通信效率严重降低。

## ICMP协议

确认网络是否正常以及遇到异常进行异常诊断的协议。其主要功能包括：

1）确认IP包是否成功送达目标地址。

2）返回在发送过程中IP包被废弃的真正原因。

3）改善网络设置

## ARP协议

主要解决MAC和IP地址之间的问题。确定了IP地址之后可以向对应IP地址的主机发送数据报，但是在底层数据要通过数据链路进行传输，必须知道每个IP地址对应的MAC地址才行。

## RARP协议

将ARP反过来，从MAC地址定位到IP地址的协议。主要用于无法获取IP地址的设备，比如嵌入式设备。

## DHCP协议

逐一为每台设备设置IP地址是一件非常繁琐的事情，因此为了实现IP自动分配而生的协议，即插即用。

## NAT协议

为了解决IP地址日益不足的问题，出现了一种技术。不要求为每一台设备分配一个固定的IP，而是在必要的时候为一定数量的设备分配唯一的IP（路由器）。若是设备没有联网，只要保证IP地址在相应网络内部是唯一的即可。所以出现了全局IP和私有IP的问题，下面是私有地址：

> ```
> 10.0.0.0-10.255.255.255         A类
> 172.16.0.0—172.31.255.255 		B类
> 192.168.0.0-192.168.255.255 	C类
> ```
>

全局IP要在整个互联网范围内唯一，但是私有地址不需要。NAT就是将私有地址在链接互联网时转换成全局IP是使用的技术。但是实际上nat本质上除了私有地址公有地址转换这一种用处之外最重要的就是将处于内网中的机器进行统一的管理和维护。



# 数据链路层

## 集线器、网桥、交换机、路由器

- 历史—更好理解

  以太网最早出现的时候是一种非常松散的设计思路，当时的网络设计者希望只用一根线，就能让所有连在这根线上的计算机都能够互联。所以最早的以太网是采用同轴电缆，而所有的计算机在这根电缆上通过变压器耦合（可以理解为搭线）在同一根电缆上收发数据。这样就出现了一个问题：一次在这根线上只能有一对收发，否则就会造成干扰。

  所以这样的局域网采用了一种叫做载波侦听/冲突重发的机制：就是如果一个计算机打算向连在这条线上的另一台计算机发送数据，它首先要侦听一下这条线上有没有数据已经在传送，如果没有，就可以发，如果有就再等一段时间后再去侦听一下，直到它可以拿到这根电缆的收发权限。

  这样就造成一个问题：同一时刻只能有一对计算机通信，其他人都要等着。

  假设一个场景，一楼101、102、103和二楼201、202、203连在一根电缆上。假设一楼101和103收发数据很频繁，这样就造成二楼基本没法通信了。怎么办？办法之一就是一楼一根电缆连101、102、103、二楼一根电缆连201、202、203，大家各发各的互不干扰。但是如果，比如201要给102发数据怎么办，这时候就需要一个设备把两根电缆连起来，变成一根电缆。平时一楼和二楼连根电缆是隔离的，只有两个楼层有数据交换才把线连起来，干这个事情的设备就叫网桥。后来交换机出现了，这个问题就不存在了，交换机（理论上）允许任意两个计算机通信互不干扰

- 集线器

  **hub**，以太网设计之初就是想要一个网络接口和多台电脑相连。因此hub就是最简单的连接多台电脑的方式，本质上就是一个信号放大器，这样的话一台电脑发出去的信号就可以被连接到hub上的其他电脑接收到，也就可以通信。一个口发送到的信号原封不动的发送大其他口，只是简单的转发，工作在物理层。

- 网桥

  工作在数据链路层，因此跟其相关的就是mac地址。与hub无差别的转发相比，网桥会过滤mac，只有目的地址mac被匹配了才会发送到出口。（这样可以减少碰撞，冲突）一个网桥就是指的1个输入到1个输出。通俗 说网桥就是把两边设备桥起来，但不是所有流量都放行，而是放行相应mac匹配的。

- 交换机

  随着设备越来越多，如果用网桥来隔离冲突域链接不同网段比较繁琐，因此就出现了交换机。交换机的基本功能与网桥一样，具有帧转发、帧过滤和生成树算法功能。

  但是交换机是多个网桥功能的集合。即网桥一般分有两个端口，而交换机具有高密度的端口。由于交换机能够支持多个端口，因此可以把网络系统划分成为更多的物理网段，这样使得整个网络系统具有更高的带宽。而网桥仅仅支持两个端口，所以，网桥划分的物理网段是相当有限的。

  **网桥和交换机，mac不匹配就flood（泛洪）**，因此泛洪是一种数据链路层的说法。

- 路由器

  路由器工作在网络层，处理IP头部，查路由表，作三层转发。连接在路由器不同端口的设备属于不同的IP子网。

  基于IP地址做转发。

## ping的原理，ping的时候到底发生了什么

- **是什么、有什么用**

  ping在潜水中主要是指收到的声呐脉冲，看看多少米深。在计算机网络中的ping是一个工具，用这个工具来检测网络的连通情况和查看网络的连接速度。

  具体就是用ping命令向想要测试的网络发送测试数据报，以此来查看对方网络是否有响应以及响应速度，达到测试的目的

  ping命令本身使用的的是网络层的ICMP协议，因此ping的本质就是ICMP协议，ICMP又需要通过IP协议进行发送，发送的数据包有一定长度，如果对方网络地址存在并且网络畅通无阻，就会收到同样大小的数据包，当然也有可能超时。因此ping本质就是IMCP协议，通过IP协议发送给对方主机。

  > ping的流程：主机A ping 主机B  ----> 构建ICMP数据包 ----> 构建IP数据包 ----> IP分组 ----> 解析硬件地址封装成帧 ----> 物理层 ---->  网络层传输 ----> 到达主机B ----> 提取IP数据包交给IP层协议 ----> 提取ICMP数据包信息，构建ICMP应答包 ----> 发送给主机A

- **原理（ICMP的解析）**

  **ICMP： Internet Control Message Protocol   互联网控制报文协议**

  **ICMP主要功能：确认发送的IP包是否到达对方主机，报告发送过程中IP包被丢弃的原因**

  > ICMP报文格式如图所示：
  >
  > <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20211207161151.png" alt="ICMP 报文" style="zoom: 50%;" />

  

  > 其中注意ICMP的**类型**字段，可以分为两大类：**查询报文类型和差错报文类型**，如图所示：
  >
  > <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20211207161829.png" alt="常见的 ICMP 类型" style="zoom:50%;" />
  >
  > - 查询报文类型
  >
  >   可以看到查询报文类型主要由两个，0和8，是回送消息。回送消息主要用于相互通信的主机和路由器之间，判断所发送的数据包是否已经成功抵达对端，ping就是用这个消息实现的。
  >
  >   因此发送端会发送一个**ICMP回送请求(类型 8)**给对端主机，对端主机如果可以通信会发送**ICMP回送响应(类型 0)**
  >
  > - 差错报文类型
  >
  >   - 目标不可达消息 —— 类型 为 `3`
  >
  >     当路由器无法将IP数据包发送给对端主机的时候，路由器会返回一个目标不可达的ICMP消息给发起ping命令的主机，这个时候类型字段是类型`8`，代码字段是具体不可到达的愿意，有以下几个：
  >
  >     1. 网络不可达代码为 `0`  —— 当IP地址区分主机号和网络号的时候，由于路由器中的路由表匹配不到对方的网络号
  >     2. 主机不可达代码为 `1`  —— 对端主机没有连接上网络
  >     3. 协议不可达代码为 `2`  —— 当主机以TCP协议访问对端主机的时候，找到对端主机，但是防火墙进制TCP协议访问
  >     4. 端口不可达代码为 `3`  —— 找到对端主机，防火墙也没限制，但是没有进程监听相应端口
  >     5. 需要进行分片但设置了不分片位代码为 `4`  —— 发送端主机发送IP数据包的时候，将IP首部的分片禁止标志位设置为1，由于不进行分片，当途中路由器遇到超过MTU大小的数据包时就直接扔掉，然后报告发送端主机
  >
  >   - 原点抑制消息 —— 类型 `4`
  >
  >     在低速线路中会遇到网络拥堵问题，这个消息就是为了缓和这个拥堵。具体做法是当路由器向低速线路发送数据的时候，其发送队列的缓存变为0而无法发送出去，这个时候路由器向IP源地址即发送端发送一个ICMP原点抑制消息。收到该消息的主机端知道了某个线路发生了拥堵，从而增大IP包的传输间隔，减少网络拥堵。
  >
  >     一般不被使用，因为可能会引起网络不公现象。
  >
  >   - 重定向消息 —— 类型 `5`
  >
  >     如果路由器发送数据报不是从最优路径发送数据的话，会返回一个ICMP重定向消息给发送主机。这个消息中包含了最合适的路由信息和源数据。
  >
  >   - 超时消息 —— 类型 `11`
  >
  >     IP包中有一个叫做TTL(time to live)的东西，他的值每经过一次路由器就会减1，当为0的时候该包就会被丢弃。丢弃的时候路由器就会发送一个ICMP超时消息给发送端主机，通知其该包已经被丢弃了。
  >
  >     设置TTL的目的就是为了防止路由器发送循环状况，避免IP包无休止的在网络上转发。
  >
  > 

- **ping具体发送过程**

  - 在主机A执行ping命令向主机B通信的时候

    主机A会构建一个**ICMP回送请求消息数据报**，这个数据报最重要的字段是**类型和序号**。回送消息请求的类型是8，序号的作用是为了区分连续ping的时候发出的多个数据包。因此每发送一个请求数据包，序号就会自动加1，同时为了计算往返时间RTT，还在报文的数据部分插入发送时间，因此报文如下图：

    <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20211207164700.png" alt="主机 A 的 ICMP 回送请求报文" style="zoom:67%;" />

  - 协议栈所做的事情

    ICMP报文和目的地址一同交给IP层进行封装，构建一个IP数据包：

    <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20211207164804.png" alt="主机 A 的 IP 层数据包" style="zoom:67%;" />

    为了在数据链路层进行传输，加入MAC头：

    <img src="https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/20211207164945.png" alt="主机 A 的 MAC 层数据包" style="zoom:67%;" />

  - 在物理线路中传输

  - 主机B收到数据包

    首先检查MAC地址然后和本机MAC地址进行比对，如果相同则接受，不同则丢弃

    接收后提取IP数据包交给本机IP层协议栈处理，抽出IP后然后抽出ICMP检查

    接着主机B会构建一个**ICMP回送响应消息**数据包，类型是0，序号为接受请求数据包中的序号，然后和上面一样的流程发送给主机A

    在规定时间内如果收到，则减去该数据包最初的时间得到延迟

  - 通过以上可以看出，ping命令使用的是ICMP协议中类型字段**ECHO REQUEST（类型为 8 ） 和 ECHO REPLY （类型为 0）**

- **traceroute** 

  traceroute的命令如下：`traceroute 192.168.1.100`

  主要作用有如下：

  1. **故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。**

     原理：它的原理就是利用 IP 包的生存期限 从 1 开始按照顺序递增的同时发送 UDP 包，强制接收 ICMP 超时消息的一种方法。比如，将 TTL 设置 为 1，则遇到第一个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是时间超时。接下来将 TTL 设置为 2，第一个路由器过了，遇到第二个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，直到到达目的主机。这样的过程，traceroute 就可以拿到了所有的路由器 IP。

     > **发送方如何知道发出的 UDP 包是否到达了目的主机呢？**
     >
     > 答：traceroute 在发送 UDP 包时，会填入一个不可能的端口号值作为 UDP 目标端口号（大于 3000 ）。当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「端口不可达」。所以，当差错报文类型是端口不可达时，说明发送方发出的 UDP 包到达了目的主机。

2.   **故意设置不分片，从而确定路径的 MTU**

   原理：首先在发送端主机发送 IP 数据报时，将 IP 包首部的分片禁止标志位设置为 1。根据这个标志位，途中的路由器不会对大数据包进行分片，而是将包丢弃。随后，通过一个 ICMP 的不可达消息将数据链路上 MTU 的值一起给发送主机，不可达消息的类型为「需要进行分片但设置了不分片位」。发送主机端每次收到 ICMP 差错报文时就减少包的大小，以此来定位一个合适的 MTU 值，以便能到达目标主机。

## 产生信道争用问题，解决办法？

共享介质性网络（多个设备共享一个通信介质），基本采用半双工通信

非共享介质网络（计算机之间不互相链接，而是都与交换机直接相连

**CSMA/CD（载波侦听多路访问/冲突检测）**

工作原理：发送数据前 先侦听信道是否空闲 ,若空闲，则立即发送数据。若信道忙碌，则等待一段时间至信道中的信息传输结束后再发送数据；若在上一段信息发送结束后，同时有两个或两个以上的节点都提出发送请求，则判定为冲突。若侦听到冲突,则立即停止发送数据，等待一段随机时间,再重新尝试。总结：先听后发，边发边听，冲突停发，随机延迟后重发。


# **电脑开机的时候系统做了什么？**

1）加载BIOS

​	    因为ROM的发明，开机程序会被刷入ROM中。当计算机通电的时候，首先读取ROM。

​		ROM里面的程序叫做**基本输入输出系统（Basic Input Output System BIOS）**

​		BIOS首先“硬件自检”，查看硬件是否能够工作。完成后BIOS把权限交给启动程序，用来对启动设备进行排序，依次启动。基本就是对主板上的键盘、鼠标、外部接口、频率、电源、磁盘驱动器等方面进行

2）读取MBR

​		BIOS首先把控制权交给存储设备。系统会读取该设备的最前面512字节，如果最后两个字节分别是0x55和0xAA则表示可以启动，然后把控制权交给下一个设备

​		存储设备最前面的512个叫做**主引导记录（MBR）**，由三部分组成：

​				①1-446字节，调用操作系统的机器码

​				②447-510字节，分区表（选择在那个分区启动，以前是把不同操作系统放在两个硬盘）

​				③511-512字节，主引导记录签名（0x55和0xAA）

3）Bootloader

​		 Boot Loader 就是在操作系统内核运行之前运行的一段小程序。通过这段小程序，我们可以初始化硬件设备、建立内存空间的映射图，从而将系统的软硬件环境带到一个合适的状态，以便为最终调用操作系统内核做好一切准备。Boot Loader有若干种，其中Grub、Lilo和spfdisk是常见的Loader。Linux环境中，目前最流行的启动管理器是 Grub。

4）加载内核

​		内核加载后，接开始操作系统初始化，根据进程的优先级启动进程，这时候linux操作系统已经可以运行了

5）Loading Kernel image 和 initial RAM disk

6）用户层init依据inittab文件来设定运行等级

​		<img src="https://s2.loli.net/2022/01/18/Fg8kXYQtSjJ6uVx.png" alt="img" style="zoom: 80%;" />

> - BIOS和UEFI（Unified Extensible Firmware Interface）则是取代传统BIOS的，相比传统BIOS来说，它更易实现，容错和纠错特性也更强。
> - **MBR与GPT：**MBR是传统的分区表类型，当一台电脑启动时，它会先启动主板上的BIOS系统，BIOS再从硬盘上读取MBR主引导记录，硬盘上的MBR运行后，就会启动操作系统，但最大的缺点则是不支持容量大于2T的硬盘。而GPT是另一种更先进的磁盘系统分区方式，它的出现弥补了MBR这个缺点，最大支持`18EB`的硬盘，是基于`UEFI`使用的磁盘分区架构。
>
> 



# 都有那些编程范式？

- 面向过程（Process Oriented Programming，POP）

  最原始，也是我们最熟悉的一种编程语言。他的编程思维源自于计算机指令的顺序排列。

  步骤：首先将待解决的问题抽象为一系列概念化的步骤。然后一步一步的按照顺序实现所有步骤。

  优点：流程化使得编程任务明确，在开发之前基本考虑了实现方式和最终结果，具体步骤清楚，便于节点分析。效率高，面向过程强调代码的短小精悍，善于结合数据结构来开发高效率的程序。

  缺点：需要深入的思考，耗费精力，代码重用性低，扩展能力差，后期维护难度比较大。

- 面向对象（Object Oriented Pr

- ogramming，OOP）

  所有事物都是对象。易于维护，扩展和复用

  优点:结构清晰，程序是模块化和结构化，更加符合人类的思维方式；易扩展，代码重用率高，可继承，可覆盖，可以设计出低耦合的系统；易维护，系统低耦合的特点有利于减少程序的后期维护工作量。

  缺点：开销大，当要修改对象内部时，对象的属性不允许外部直接存取，所以要增加许多没有其他意义、只负责读或写的行为。这会为编程工作增加负担，增加运行开销，并且使程序显得臃肿。

  性能低，由于面向更高的逻辑抽象层，使得面向对象在实现的时候，不得不做出性能上面的牺牲，计算时间和空间存储大小都开销很大。

  > 举个例子：下五子棋
  >
  > 面向过程：开始游戏（）；
  > 黑子先走（）；
  > 绘制画面（）；
  > 判断输赢（）；
  > 轮到白子（）；
  > 绘制画面（）；
  > 判断输赢（）；
  > 返回到 黑子先走（）；
  > 输出最后结果；
  >
  > 面向对象：黑白双方，这两方的行为是一样的。棋盘系统，负责绘制画面。规则系统，负责判定犯规、输赢等。

- 事件驱动编程

  主要是用在图形用户界面，比如C#这种

  功能都是提前写好的，就等着触发

- 面向接口（Interface Oriented Programming， IOP）

- 面向切面（Aspect Oriented Programming，AOP）

- 函数式（Funtional Programming，FP）

- 响应式（Reactive Programming，RP）

- 数响应式（Functional Reactive Programming，FRP）

  



# 软件开发模型

## 瀑布模型

瀑布模型（Waterfall Model） 是一个软件生命周期模型，开发过程是通过设计一系列阶段顺序展开的，从系统需求分析开始直到产品发布和维护，项目开发进程从一个阶段“流动”到下一个阶段，这也是瀑布模型名称的由来。

瀑布模型核心思想是按工序将问题化简，将功能的实现与设计分开，便于分工协作，即采用结构化的分析与设计方法将逻辑实现与物理实现分开。将软件生命周期划分为制定计划、需求分析、软件设计、程序编写、软件测试和运行维护等六个基本活动，并且规定了它们自上而下、相互衔接的固定次序，如同瀑布流水，逐级下落。

现在的互联网项目已经不再像传统的瀑布模型的项目，有明确的需求。现在项目迭代的速度和需求的变更都非常的迅速。在软件开发的编码之前我们不可能事先了解所有的需求，软件设计肯定会有考虑不周到不全面的地方；而且随着项目需求的不断变更，很有可能原来的代码设计结构已经不能满足当前的需求。

**优点：**

每个阶段交出的所有产品都必须经过质量保证小组的仔细验证。

**缺点：**

瀑布模型是由文档驱动，在可运行的软件产品交付给用户之前，用户只能通过文档来了解产品是什么样的。瀑布模型几乎完全依赖于书面的规格说明，很可能导致最终开发出的软件产品不能真正满足用户的需要。也不适合需求模糊的系统。



## **迭代开发**

迭代增量式开发，也越来越接近现代的开发流程。

在迭代式开发中，整个开发工作被组织 为一系列短小的、固定长度的小项目，每次选代都包括需求分析、设计、实现与测试。采用迭代式开发时， 工作可以在需求被完整地确定之前启动， 并在一次选代中完成系统的一部分功能 或业务，再通过客户的反馈来细化需求，并开始新一轮的迭代。

## 敏捷开发模型

敏捷开发（Agile）是一种以人为核心、迭代、循序渐进的开发方法。在敏捷开发中，软件项目的构建被切分成多个子项目，各个子项目的成果都经过测试，具备集成和可运行的特征。简单地来说，敏捷开发并不追求前期完美的设计、完美编码，而是力求在很短的周期内开发出产品的核心功能，尽早发布出可用的版本。然后在后续的生产周期内，按照新需求不断迭代升级，完善产品。

首要任务是尽早地、持续地交付可评价的软件，以使客户满意。

频繁交付可使用的软件，交付的间隔越短越好，可以从几个月缩减到几个星期。

在整个项目开发期间，业务人员和开发人员必须朝夕工作在一起。

围绕那些有推动力的人们来构建项目，给予他们所需的环境和支持，并且相信他们能够把工作做好。

## scrum开发模型

scrum的团队不需要那么大，十几个人即可。

> **下面先给出scrum的模型：**
>
> <img src="http://image.woshipm.com/wp-files/2017/09/z7yrIA5t0m3jjwEYlJll.png" alt="img" style="zoom:80%;float:left" />



**scrum所包含的角色**

1. PO：Product Owner，产品负责人，确定「大家要做什么」。互联网公司的 PO 一般由相关的产品经理担任；如果是为客户做项目，PO 就是客户负责人。
2. Scrum Master：Scrum的推动者，掌控大节奏的人。
3. Scrum Team ：Developer，开发的主力。

三种角色有各自的责任，但三者间并没有上司和下属的关系。这正是 Scrum 区别于传统开发流程的精华：

- 传统的开发流程，是由领导拍板的中央集权制；
- Scurm 是人人平等的民主制，每个人的能力都被信任，更加自主，能发挥出更高的效率。



**scrum的一些名词**

1. Sprint：周期指的是一次迭代，而一次迭代的周期一般是2-4周，也就是我们要把一次迭代的开发内容以最快的速度完成它，这个过程我们称它为Sprint。
2. Backlog ：待办工作事项的集合。
3. Product Backlog ：PO将产品待办事项列表放入，是量化的用户需求，条目化地表达实际需要开发的需求。一般来说这个是以sprint来计算
4.  Sprint Backlog：任务列表。是一次迭代中需要完成的任务，也是开发过程用得最多的Backlog，非常细化。一般来说以天来计算。



**如何进行Scrum开发？**

1. 我们首先需要确定一个Product Backlog（按优先顺序排列的一个产品需求列表），这个是由Product Owner 负责的；
2. Scrum Team根据Product Backlog列表，做工作量的预估和安排；
3. 有了Product Backlog列表，我们需要通过 Sprint Planning Meeting（Sprint计划会议） 来从中挑选出一个Story作为本次迭代完成的目标，这个目标的时间周期是1~4个星期（intel我们组是2周），然后把这个Story进行细化，形成一个Sprint Backlog；
4. Sprint Backlog是由Scrum Team去完成的，每个成员根据Sprint Backlog再细化成更小的任务（细到每个任务的工作量在2天内能完成）；
5. 在Scrum Team完成计划会议上选出的Sprint Backlog过程中，需要进行 Daily Scrum Meeting（每日站立会议），每次会议控制在15分钟左右，每个人都必须发言，并且要向所有成员当面汇报你昨天完成了什么，并且向所有成员承诺你今天要完成什么，同时遇到不能解决的问题也可以提出，每个人回答完成后，要走到黑板前更新自己的 Sprint burn down（Sprint燃尽图）；
6. 做到每日集成，也就是每天都要有一个可以成功编译、并且可以演示的版本；很多人可能还没有用过自动化的每日集成，其实TFS就有这个功能，它可以支持每次有成员进行签入操作的时候，在服务器上自动获取最新版本，然后在服务器中编译，如果通过则马上再执行单元测试代码，如果也全部通过，则将该版本发布，这时一次正式的签入操作才保存到TFS中，中间有任何失败，都会用邮件通知项目管理人员；
7. 当一个Story完成，也就是Sprint Backlog被完成，也就表示一次Sprint完成，这时，我们要进行 Srpint Review Meeting（演示会议），也称为评审会议，产品负责人和客户都要参加（最好本公司老板也参加），每一个Scrum Team的成员都要向他们演示自己完成的软件产品（这个会议非常重要，一定不能取消）；
8. 最后就是 Sprint Retrospective Meeting（回顾会议），也称为总结会议，以轮流发言方式进行，每个人都要发言，总结并讨论改进的地方，放入下一轮Sprint的产品需求中；

# C++和C的区别

**面向对象和面向过程语言的区别**

首要要知道这两个都是一种编程思想

**面向过程**就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了。

**面向对象**是把构成问题事务分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个事物在整个解决问题的步骤中的行为。

**举一个例子：**

例如五子棋，面向过程的设计思路就是首先分析问题的步骤：1、开始游戏，2、黑子先走，3、绘制画面，4、判断输赢，5、轮到白子，6、绘制画面，7、判断输赢，8、返回步骤2，9、输出最后结果。把上面每个步骤用分别的函数来实现，问题就解决了。

而面向对象的设计则是从另外的思路来解决问题。整个五子棋可以分为 1、黑白双方，这两方的行为是一模一样的，2、棋盘系统，负责绘制画面，3、规则系统，负责判定诸如犯规、输赢等。第一类对象（玩家对象）负责接受用户输入，并告知第二类对象（棋盘对象）棋子布局的变化，棋盘对象接收到了棋子的i变化就要负责在屏幕上面显示出这种变化，同时利用第三类对象（规则系统）来对棋局进行判定。

可以明显地看出，面向对象是以功能来划分问题，而不是步骤。同样是绘制棋局，这样的行为在面向过程的设计中分散在了总多步骤中，很可能出现不同的绘制版本，因为通常设计人员会考虑到实际情况进行各种各样的简化。而面向对象的设计中，绘图只可能在棋盘对象中出现，从而保证了绘图的统一。功能上的统一保证了面向对象设计的可扩展性。

**面向过程**

优点：性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;比如单片机、嵌入式开发、 Linux/Unix等一般采用面向过程开发，性能是最重要的因素。

缺点：没有面向对象易维护、易复用、易扩展

**面向对象**

优点：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统 更加灵活、更加易于维护

缺点：性能比面向过程低

# C++和java的区别

**指针：**java语言在程序员层面屏蔽了指针，让程序员没办法根据指针找到内存，所以没有指针这一概念。但是java有内存的自动管理功能，从而能够避免c++那种内存泄露的事务。

**多重继承：**c++支持多重继承，但是java好像不支持，但是java有接口（抽象类，是一系列方法的声明，是一些方法特征的集合，一个接口只有方法的特征没有方法的实现），一个类可以继承多个接口。c++多重继承的问题。c++多重继承有虚继承来解决问题。

**数据类型和类：**java是一门完全面向对象的语言，因此所有的函数和变量必须是类的一部分，除了基本数据类型之外，其余都是作为类对象而存在的，对象将数据和方法结合起来把其封装在类中。

**struct和union：**java取消了struct和union，我的理解是struct本来就是类的始祖，用起来不方便，而且java一切皆对象，没必要使用struct。

**操作符重载：**java不支持操作符重载，这是c++突出特性之一。

**预处理机制：**c/c++都在编译前有一个预处理阶段，该阶段主要有源文件替换，宏替换，去掉注释等功能。java没有，但是提供了import（*import* 关键字. 为了能够使用某一个包的成员，我们需要在*Java* 程序中明确导入该包。）。

**自动内存管理：**java在堆上建立内存无需手动释放，java无用内存回收是用现成的方式在后台运行，利用空闲时间删除。





# c++为什么不加入垃圾回收机制

[参考链接](https://mp.weixin.qq.com/s/Tyhq8mr3-6g1mDwnKQF4mw)

作为支持指针的编程语言，C++将动态管理存储器资源的便利性交给了程序员。在使用指针形式的对象时(请注意，由于引用在初始化后不能更改引用目标的语言机制的限制，多态性应用大多数情况下依赖于指针进行)，程序员必须自己完成存储器的分配、使用和释放，语言本身在此过程中不能提供任何帮助，也许除了按照你的要求正确的和操作系统亲密合作，完成实际的存储器管理。

C++的设计者Bjarne Stroustrup关于问题给了一段说法：我很害怕那种严重的空间和时间开销，也害怕由于实现和移植垃圾回收系统而带来的复杂性。还有，垃圾回收将使C++不适合做许多底层的工作，而这却正是它的一个设计目标。但我喜欢垃圾回收的思想，它是一种机制，能够简化设计、排除掉许多产生错误的根源。

需要垃圾回收的基本理由是很容易理解的：用户的使用方便以及比用户提供的存储管理模式更可靠。而反对垃圾回收的理由也有很多，但都不是最根本的，而是关于实现和效率方面的。

我的结论是，从原则上和可行性上说，垃圾回收都是需要的。但是对今天的用户以及普遍的使用和硬件而言，我们还无法承受将C++的语义和它的基本库定义在垃圾回收系统之上的负担。”



# 原码反码和补码

## 机器数和真值

在学习原码, 反码和补码之前, 需要先了解机器数和真值的概念.

**机器数**

一个数在计算机中的二进制表示形式, 叫做这个数的机器数。机器数是带符号的，在计算机用一个数的最高位存放符号, 正数为0, 负数为1.

比如，十进制中的数 +3 ，计算机字长为8位，转换成二进制就是00000011。如果是 -3 ，就是 10000011 。

那么，这里的 00000011 和 10000011 就是机器数。

**真值**

因为第一位是符号位，所以机器数的值就不等于真正的数值。例如上面的有符号数 10000011，其最高位1代表负，其真正数值是 -3 而不是形式值131（10000011转换成十进制等于131）。所以，为区别起见，将带符号位的机器数对应的真正数值称为机器数的真值。

对于一个数, 计算机要使用一定的编码方式进行存储. 原码, 反码, 补码是机器存储一个具体数字的编码方式.

## 原码

原码是人脑最容易理解和计算的表示方式.

原码就是符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值. 比如如果是8位二进制:

[+1]原 = 0000 0001

[-1]原 = 1000 0001

## 反码

正数的反码是其本身

负数的反码是在其原码的基础上, 符号位不变，其余各个位取反.

[+1] = [00000001]原 = [00000001]反

[-1] = [10000001]原 = [11111110]反

可见如果一个反码表示的是负数, 人脑无法直观的看出来它的数值. 通常要将其转换成原码再计算.

## 补码

正数的补码就是其本身

负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1)

[+1] = [00000001]原 = [00000001]反 = [00000001]补

[-1] = [10000001]原 = [11111110]反 = [11111111]补

负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值.

## 有了原码为什么还要有补码？

现在我们知道了计算机可以有三种编码方式表示一个数. 对于正数因为三种编码方式的结果都相同:

> [+1] = [00000001]原 = [00000001]反 = [00000001]补

所以不需要过多解释. 但是对于负数:

> [-1] = [10000001]原 = [11111110]反 = [11111111]补

可见原码, 反码和补码是完全不同的. 既然原码才是被人脑直接识别并用于计算表示方式, 为何还会有反码和补码呢?

首先, 因为人脑可以知道第一位是符号位, 在计算的时候我们会根据符号位, 选择对真值区域的加减. (真值的概念在本文最开头). 但是对于计算机, 加减乘数已经是最基础的运算, 要设计的尽量简单. 计算机辨别"符号位"显然会让计算机的基础电路设计变得十分复杂! 于是人们想出了将符号位也参与运算的方法. 我们知道, 根据运算法则减去一个正数等于加上一个负数, 即: 1-1 = 1 + (-1) = 0 , 所以机器可以只有加法而没有减法, 这样计算机运算的设计就更简单了。于是人们开始探索 **将符号位参与运算, 并且只保留加法的方法**. 首先来看原码:

计算十进制的表达式: 1-1=0

> 1 - 1 = 1 + (-1) = [00000001]原 + [10000001]原 = [10000010]原 = -2

如果用原码表示, 让符号位也参与计算, 显然对于减法来说, 结果是不正确的.这也就是为何计算机内部不使用原码表示一个数.

为了解决原码做减法的问题, 出现了反码:

计算十进制的表达式: 1-1=0

> 1 - 1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原= [0000 0001]反 + [1111 1110]反 = [1111 1111]反 = [1000 0000]原 = -0

发现用反码计算减法, 结果的真值部分是正确的. 而唯一的问题其实就出现在"0"这个特殊的数值上. 虽然人们理解上+0和-0是一样的, 但是0带符号是没有任何意义的. 而且会有[0000 0000]原和[1000 0000]原两个编码表示0.

于是补码的出现, 解决了0的符号以及两个编码的问题:

> 1-1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原 = [0000 0001]补 + [1111 1111]补 = [0000 0000]补=[0000 0000]原

使用补码, 不仅仅修复了0的符号以及存在两个编码的问题, 而且还能够多表示一个最低数. 这就是为什么8位二进制, 使用原码或反码表示的范围为[-127, +127], 而使用补码表示的范围为[-128, 127].

因为机器使用补码, 所以对于编程中常用到的32位int类型, 可以表示范围是: [-231, 231-1] 因为第一位表示的是符号位.而使用补码表示时又可以多保存一个最小值.

# Linux系统各个目录的一般作用

<img src="https://www.rurichan.com/upload/2021/08/d9995847888d6fd086d100078b505090-4778411dd3d54b428a6dc5a78e40d78d.png" alt="d9995847888d6fd086d100078b505090.png" style="zoom:150%;" />

| 目录        | 说明                                                         |
| ----------- | ------------------------------------------------------------ |
| /bin        | 存放二进制可执行文件(ls,cat,mkdir等)，常用命令一般都在这里。 |
| /home       | 存放所有用户文件的根目录，是用户主目录的基点，比如用户user的主目录就是/home/user，可以用~user表示 |
| /usr        | 用于存放系统应用程序，比较重要的目录 /usr/local 本地系统管理员软件安装目录（安装系统级的应用）。这是最庞大的目录，要用到的应用程序和文件几乎都在这个目录。 /usr/x11r6 存放x window的目录 /usr/bin 众多的应用程序 /usr/sbin 超级用户的一些管理程序 /usr/doc linux文档 /usr/include linux下开发和编译应用程序所需要的头文件 /usr/lib 常用的动态链接库和软件包的配置文件 /usr/man 帮助文档 /usr/src 源代码，linux内核的源代码就放在/usr/src/linux里 /usr/local/bin 本地增加的命令 /usr/local/lib 本地增加的库 |
| /opt        | 额外安装的可选应用程序包所放置的位置。一般情况下，我们可以把tomcat等都安装到这里。 |
| /proc       | 虚拟文件系统目录，是系统内存的映射。可直接访问这个目录来获取系统信息。 |
| /root       | 超级用户（系统管理员）的主目录（特权阶级^o^）                |
| /sbin       | 存放二进制可执行文件，只有root才能访问。这里存放的是系统管理员使用的系统级别的管理命令和程序。如ifconfig等。 |
| /dev        | 用于存放设备文件。                                           |
| /mnt        | 系统管理员安装临时文件系统的安装点，系统提供这个目录是让用户临时挂载其他的文件系统。 |
| /boot       | 存放用于系统引导时使用的各种文件                             |
| /lib        | 存放跟文件系统中的程序运行所需要的共享库及内核模块。共享库又叫动态链接共享库，作用类似windows里的.dll文件，存放了根文件系统程序运行所需的共享文件。 |
| /tmp        | 用于存放各种临时文件，是公用的临时文件存储点。               |
| /var        | 用于存放运行时需要改变数据的文件，也是某些大文件的溢出区，比方说各种服务的日志文件（系统启动日志等。）等。 |
| /lost+found | 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里 |





# 谷歌C++编程规范

## 命名约定

**通用规则**

函数命名，变量命名、文件命名要有描述性，少用缩写

**文件命名**

文件名要全部小写，用下划线(_)连起来，c++文件要以.cc结尾，头文件以.h结尾，专门插入文本的文件以.inc结尾

**类命名**

类的每个单词首字母均大写，不包含下划线，比如：MyExcitingClass

**变量命名**

变量名一律小写，单词之间用下划线连接

类的成员变量以下划线结尾

结构体成员变量和类一样

**常量命名**

在全局或类里的常量名称前加 k: `kDaysInAWeek`. 且除去开头的 k 之外每个单词开头字母均大写。

所有编译时常量, 无论是局部的, 全局的还是类中的, 和其他变量稍微区别一下. k 后接大写字母开头的单词:

```c++
const int kDaysInAWeek = 7;
```

**函数命名**

常规函数使用大小写混合，如MyExcitingFunction()

如果您的某函数出错时就要直接 crash, 那么就在函数名加上 OrDie. 

取值（Accessors）和设值（Mutators）函数要与存取的变量名匹配，用小写：int num_entries() const { return num_entries_; }

**函数参数**

跟变量命名一样

**宏命名**

全部大写，像这样命名: MY_MACRO_THAT_SCARES_SMALL_CHILDREN

**总结**

Google 的命名约定很高明，比如写了简单的类QueryResult, 接着又可以直接定义一个变量query_result, 区分度很好；再次，类内变量以下划线结尾，那么就可以直接传入同名的形参，比如 TextQuery::TextQuery(std::string word) : word_(word) {} , 其中 word_ 自然是类内私有成员。





# 海量数据处理题问题

**第一题**

问题：海量日志数据，提取出某日访问百度次数最多的IP。

答案：假设内存无穷大，我们可以用常规的HashMap(ip，value)来统计ip出现的频率，统计完后利用排序算法得到次数最多的IP，这里的排序算法一般是堆排序或快速排序。但考虑实际情况，我们的内存是有限的，所以无法将海量日志数据一次性塞进内存里，那应该如何处理呢？很简单，分而治之！即将这些IP数据通过Hash映射算法划分为多个小文件，比如模1000，把整个大文件映射为1000个小文件，再找出每个小文件中出现频率最大的IP，最后在这1000个最大的IP中，找出那个频率最大的IP，即为所求（是不是很像Map Reduce的思想？）。

这里再多说一句：Hash取模是一种等价映射算法，不会存在同一个元素分散到不同小文件中的情况，这保证了我们分别在小文件统计IP出现频率的正确性。我们对IP进行模1000的时候，相同的IP在Hash取模后，只可能落在同一个小文件中，不可能被分散的。因为如果两个IP相等，那么经过Hash(IP)之后的哈希值是相同的，将此哈希值取模（如模1000），必定仍然相等。

总结一下，该类题型的解决方法分三步走：

1. 分而治之、hash映射；
2. HashMap（或前缀树）统计频率；
3. 应用排序算法（堆排序或快速排序）。

**第二题**

问：搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询长度不超过 255 字节。假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门），请你统计最热门的10个查询串，要求使用的内存不能超过1G。

答：我们首先分析题意：一千万个记录，除去重复后，实际上只有300万个不同的记录，每个记录假定为最大长度255Byte，则最多占用内存为：3M*1K/4=0.75G<1G，完全可以将所以查询记录存放在内存中进行处理。相较于第一道题目，这题还更简单了，直接HashMap（或前缀树）+堆排序即可。

具体做法如下：

1. 遍历一遍左右的Query串，利用HashMap（或前缀树）统计频率，时间复杂度为O(N)，N=1000万；
2. 建立并维护一个大小为10的最小堆，然后遍历300万Query的频率，分别和根元素（最小值）进行对比，最后找到Top K，时间复杂度为N‘logK，N‘=300万，K=10。

**第三题**

问：有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。

答：经过前两道题的训练，第三道题相信大家已经游刃有余了，这类题型都有相同的特点：文件size很大，内存有限，解决方法还是经典三步走：分而治之 + hash统计 + 堆/快速排序。

具体做法如下：

1. 分而治之、hash映射：遍历一遍文件，对于每个词x，取hash(x)并模5000，这样可以将文件里的所有词分别存到5000个小文件中，如果哈希函数设计得合理的话，每个文件大概是200k左右。就算其中有些文件超过了1M大小，还可以按照同样的方法继续往下分，直到分解得到的小文件的大小都不超过1M；
2. HashMap（或前缀树）统计频率：对于每个小文件，利用HashMap（或前缀树）统计词频；
3. 堆排序：构建最小堆，堆的大小为100，找到频率最高的100个词。

**第四题**

问：给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？

答：每个url是64字节，50亿*64=5G×64=320G，内存限制为4G，所以不能直接放入内存中。怎么办？分而治之！

具体做法如下：

1. 遍历文件a中的url，对url进行hash(url)%1000，将50亿的url分到1000个文件中存储（a0，a1，a2.......），每个文件大约300多M，对文件b进行同样的操作，因为hash函数相同，所以相同的url必然会落到对应的文件中，比如文件a中的url1与文件b中的url2相同，那么它们经过hash(url)%1000也是相同的。即url1落入第n个文件中，url2也会落入到第n个文件中。
2. 遍历a0中的url，存入HashSet中，同时遍历b0中的url，查看是否在HashSet中存在，如果存在则保存到单独的文件中。然后以此遍历剩余的小文件即可。

**总结**

这几道题都有一个共性， **那就是要求在海量数据中找出重复次数最多的一个/前N个数据**，我们的解决方法也很朴实： 分而治之/Hash映射 + HashMap/前缀树统计频率 + 堆/快速/归并排序，具体来说就是先做hash，然后求模映射为小文件，求出每个小文件中重复次数最多的一个，并记录重复次数，最后利用堆这个数据结构高效地取出前N个出现次数最多的数据。



# HelloWorld程序开始到打印到屏幕上的全过程

1. 用户告诉操作系统执行 HelloWorld 程序（通过键盘输⼊等）；

2. 操作系统找到 HelloWorld 程序，检查其类型是否是可执⾏⽂件；并通过程序首部信息，确定代码和数据在可执行文件中的位置并计算出对应的磁盘块地址；
3.  操作系统创建⼀个新进程，将 HelloWorld 可执行⽂件映射到该进程结构，表示由该进程执行HelloWorld 程序； 
4. 操作系统为 HelloWorld 程序设置 cpu 上下文环境，并跳到程序开始处；
5.  执行 HelloWorld 程序的第⼀条指令，发生缺页异常；然后分配⼀页物理内存，并将代码从磁盘读入内存，然后继续执行 HelloWorld 程序; 
6. HelloWorld 程序执行 puts 函数（系统调用），在显示器上写⼀字符串; 
7. 操作系统找到要将字符串送往的显示设备，通常设备是由⼀个进程控制的，所以操作系统将要写的字符串 送给该进程; 
8. 操作系统控制设备的进程告诉设备的窗口系统，它要显示该字符串，窗⼝系统确定这是⼀个合法的操作，然后将字符串转换成像素，将像素写⼊设备的存储映像区;
9.  视频硬件将像素转换成显示器可接收和⼀组控制数据信号; 
10. 显示器解释信号，激发液晶屏; OK，我们在屏幕上看到了 HelloWorld;





# 大整数运算和构造

[参考连接](https://frostime.github.io/2019/07/23/%E5%A4%A7%E6%95%B4%E6%95%B0%E8%BF%90%E7%AE%97/)

**构造**

可以用一个数组来存储数字的每一位来表示一个大整数。

使用一个类来包装，大整数类中有保存数据的数组，数位长度

**表示**

在构造一个大整数的时候，我们应该有两个步骤。

1. 把整个数组填充为 0
2. 大部分情况下我们需要构造的整数的各个数位逆序填入数组中

第 1 点比较好理解，因为我们要做加减乘除的时候，肯定需要进位借位，这时候把暂时没有用到的位数设置为 0 是非常合理的。

> 我们所做的大部分运算都是从低位往高位进行的，而且往往会涉及到进位。这时采用逆序保存的方法就会很方便进位操作，反之如果我们按照原始顺序进行保存，想要进位的话，还需要把整个数组往后移动。当然并不是说，任何情况下都需要用这种顺序来保存。但是在做题的时候，往往只会涉及到加法和乘法，偶尔还有减法，几乎不会涉及到除法。这种情况下采用逆序保存就很合适了。



# 字符编码笔记：ASCII，Unicode 和 UTF-8

## **ASCII 码**

计算机内部，所有信息最终都是一个二进制值。每一个二进制位（bit）有`0`和`1`两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态。60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这被称为 ASCII 码，一直沿用至今。ASCII 码一共规定了128个字符的编码

英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。 

## **Unicode**

是否有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是 Unicode，就像它的名字都表示的，这是一种所有符号的编码。Unicode 当然是一个很大的集合，现在的规模可以容纳100多万个符号。

但是Unicode 只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。

## **UTF-8**

互联网的普及，强烈要求出现一种统一的编码方式。UTF-8 就是在互联网上使用最广的一种 Unicode 的实现方式。

UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。

# 编译器优化

**O0：**编译器默认就是O0，该选项下不会开启优化，方便开发者调试。

**O1：**致力于在不需要过多的编译时间情况下，尽量减少代码大小和尽量提高程序运行速度，它开启了下面的优化标志：

```
-fauto-inc-dec 
-fbranch-count-reg 
-fcombine-stack-adjustments 
-fcompare-elim 
-fcprop-registers 
-fdce 
-fdefer-pop 
-fdelayed-branch 
-fdse 
-fforward-propagate 
-fguess-branch-probability 
-fif-conversion 
-fif-conversion2 
-finline-functions-called-once 
-fipa-modref 
-fipa-profile 
-fipa-pure-const 
-fipa-reference 
-fipa-reference-addressable 
-fmerge-constants 
-fmove-loop-invariants 
-fomit-frame-pointer 
-freorder-blocks 
-fshrink-wrap 
-fshrink-wrap-separate 
-fsplit-wide-types 
-fssa-backprop 
-fssa-phiopt 
-ftree-bit-ccp 
-ftree-ccp 
-ftree-ch 
-ftree-coalesce-vars 
-ftree-copy-prop 
-ftree-dce 
-ftree-dominator-opts 
-ftree-dse 
-ftree-forwprop 
-ftree-fre 
-ftree-phiprop 
-ftree-pta 
-ftree-scev-cprop 
-ftree-sink 
-ftree-slsr 
-ftree-sra 
-ftree-ter 
-funit-at-a-time
```



**O2：**常见的Release级别，该选项下几乎执行了所有支持的优化选项，它增加了编译时间，提高了程序的运行速度，又额外打开了以下优化标志：

```text
-falign-functions  -falign-jumps 
-falign-labels  -falign-loops 
-fcaller-saves 
-fcode-hoisting 
-fcrossjumping 
-fcse-follow-jumps  -fcse-skip-blocks 
-fdelete-null-pointer-checks 
-fdevirtualize  -fdevirtualize-speculatively 
-fexpensive-optimizations 
-ffinite-loops 
-fgcse  -fgcse-lm  
-fhoist-adjacent-loads 
-finline-functions 
-finline-small-functions 
-findirect-inlining 
-fipa-bit-cp  -fipa-cp  -fipa-icf 
-fipa-ra  -fipa-sra  -fipa-vrp 
-fisolate-erroneous-paths-dereference 
-flra-remat 
-foptimize-sibling-calls 
-foptimize-strlen 
-fpartial-inlining 
-fpeephole2 
-freorder-blocks-algorithm=stc 
-freorder-blocks-and-partition  -freorder-functions 
-frerun-cse-after-loop  
-fschedule-insns  -fschedule-insns2 
-fsched-interblock  -fsched-spec 
-fstore-merging 
-fstrict-aliasing 
-fthread-jumps 
-ftree-builtin-call-dce 
-ftree-pre 
-ftree-switch-conversion  -ftree-tail-merge 
-ftree-vrp
```

**Os：**打开了几乎所有的O2优化标志，除了那些经常会增加代码大小的优化标志：使编译器根据代码大小而不是程序运行速度进行优化，为了减少代码大小。

**O3：**较为激进的优化选项（对错误编码容忍度最低），在O2的基础上额外打开了十多个优化选项,在O2的基础上又打开了以下优化标志：

```
fgcse-after-reload 
-fipa-cp-clone
-floop-interchange 
-floop-unroll-and-jam 
-fpeel-loops 
-fpredictive-commoning 
-fsplit-loops 
-fsplit-paths 
-ftree-loop-distribution 
-ftree-loop-vectorize 
-ftree-partial-pre 
-ftree-slp-vectorize 
-funswitch-loops 
-fvect-cost-model 
-fvect-cost-model=dynamic 
-fversion-loops-for-strides
```



# Debug和Release版本的区别

Debug通常称为调试版本，通过一系列编译选项的配合，编译的结果通常包含调试信息，而且不做任何优化，以为开发 人员提供强大的应用程序调试能力。

Release通常称为发布版本，是为用户使用的，一般客户不允许在发布版本上进行调试。所以不保存调试信 息，同时，它往往进行了各种优化，以期达到代码最小和速度最优。为用户的使用提供便利。

有以下几个不同：

1. Debug模式下在内存分配上有所区别，在我们申请内存时，Debug模式会多申请一部分空间，分布在内存块的前后，用于存放调试信息。
2. 对于未初始化的变量，Debug模式下会默认对其进行初始化，而Release模式则不会，所以就有个常见的问题，局部变量未初始化时，Debug模式下可能运行正常，但Release模式下可能会返回错误结果
3. Debug模式下可以使用assert，运行过程中有异常现象会及时crash，Release模式下模式下不会编译assert，遇到不期望的情况不会及时crash，稀里糊涂继续运行，到后期可能会产生奇奇怪怪的错误，不易调试，殊不知其实在很早之前就出现了问题。编译器在Debug模式下定义_DEBUG宏，Release模式下定义NDEBUG宏，预处理器就是根据对应宏来判断是否开启assert的。
4. 数据溢出问题，在一个函数中，存在某些从未被使用的变量，且函数内存在数据溢出问题，在Debug模式下可能不会产生问题，因为不会对该变量进行优化，它在栈空间中还是占有几个字节，但是Release模式下可能会出问题，Release模式下可能会优化掉此变量，栈空间相应变小，数据溢出就会导致栈内存损坏，有可能会产生奇奇怪怪的错误。

> **问：有时候程序在Debug模式下运行的好好的，Release模式下就crash了，怎么办？**
>
> 答：看一下代码中是否有未初始化的变量，是否有数组越界问题，从这个思路入手。
>
> **问：有些时候程序在Debug模式下会崩溃，Release模式下却正常运行，怎么办？**
>
> 答：可以尝试着找一找代码中的assert，看一下是否是assert导致的两种模式下的差异，从这个思路入手。



# Intel CPU型号解读

Intel生产的CPU分为高中低端，最低端的G系列，然后是低端i3系列，中端i5系列，高端i7系列和至尊i9系列。

U：代表超低电压以15W和28为主

M：代表标准电压cpu

U：代表低电压节能的

H：是高电压的

X：代表高性能

Q：代表至高性能级别

Y：代表超低电压的

K：代表不锁倍频的处理器

“MX”：代表旗舰级，

“HQ”：封装方式FCBGA1364，并且部分支持Trusted Execution Technology和博锐技术，

“MQ”：版本封装方式FCBGA946。

# 在 4GB 物理内存的机器上，申请 8G 内存会怎么样？

这个问题要考虑三个前置条件：

- 操作系统是 32 位的，还是 64 位的？
- 申请完 8G 内存后会不会被使用？
- 操作系统有没有使用 Swap 机制？

首先，应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生缺页中断，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。缺页中断处理函数会看是否有空闲的物理内存：

1. 如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。
2. 如果没有空闲的物理内存，那么内核就会开始进行回收内存 (opens new window)的工作，如果回收内存工作结束后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了触发 OOM （Out of Memory）机制。

## 32还是64

另外，32 位操作系统和 64 位操作系统的虚拟地址空间大小是不同的，在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分：

1. `32` 位系统的内核空间占用 `1G`，位于最高处，剩下的 `3G` 是用户空间；
2. `64` 位系统的内核空间和用户空间都是 `128T`，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。

**32 位操作系统**

因为 32 位操作系统，进程最多只能申请 3 GB 大小的虚拟内存空间，所以进程申请 8GB 内存的话，在申请虚拟内存阶段就会失败

**64位操作系统**

64 位操作系统，进程可以使用 128 TB 大小的虚拟内存空间，所以进程申请 8GB 内存是没问题的，因为进程申请内存是申请虚拟内存，只要不读写这个虚拟内存，操作系统就不会分配物理内存。

## 有没有swap

> **什么是 Swap 机制？**
>
> 当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间会被临时保存到磁盘，等到那些程序要运行时，再从磁盘中恢复保存的数据到内存中。另外，当内存使用存在压力的时候，会开始触发内存回收行为，会把这些不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。
>
> 将内存数据换出磁盘，又从磁盘中恢复数据到内存的过程，就是 Swap 机制负责的。
>
> Swap 就是把一块磁盘空间或者本地文件，当成内存来使用，它包含换出和换入两个过程：
>
> 1. 换出（Swap Out） ，是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存；
> 2. 换入（Swap In），是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来；
>
> **Linux 中的 Swap 机制会在内存不足和内存闲置的场景下触发：**
>
> 1. 内存不足：当系统需要的内存超过了可用的物理内存时，内核会将内存中不常使用的内存页交换到磁盘上为当前进程让出内存，保证正在执行的进程的可用性，这个内存回收的过程是强制的直接内存回收（Direct Page Reclaim）。直接内存回收是同步的过程，会阻塞当前申请内存的进程。
> 2. 内存闲置：应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程（kSwapd），我们可以将这部分只使用一次的内存交换到磁盘上为其他内存的申请预留空间。kSwapd 是 Linux 负责页面置换（Page replacement）的守护进程，它也是负责交换闲置内存的主要进程，它会在[空闲内存低于一定水位 (opens new window)](https://xiaolincoding.com/os/3_memory/mem_reclaim.html#尽早触发-kSwapd-内核线程异步回收内存)时，回收内存页中的空闲内存保证系统中的其他进程可以尽快获得申请的内存。kSwapd 是后台进程，所以回收内存的过程是异步的，不会阻塞当前申请内存的进程。
>
> **Swap 换入换出的是什么类型的内存？**
>
> 内核缓存的文件数据，因为都有对应的磁盘文件，所以在回收文件数据的时候， 直接写回到对应的文件就可以了。但是像进程的堆、栈数据等，它们是没有实际载体，这部分内存被称为匿名页。而且这部分内存很可能还要再次被访问，所以不能直接释放内存，于是就需要有一个能保存匿名页的磁盘载体，这个载体就是 Swap 分区。
>
> **swap的优缺点**
>
> 使用 Swap 机制优点是，应用程序实际可以使用的内存空间将远远超过系统的物理内存。由于硬盘空间的价格远比内存要低，因此这种方式无疑是经济实惠的。当然，频繁地读写硬盘，会显著降低操作系统的运行速率，这也是 Swap 的弊端。

使用`free -m`命令查看有没有swap分区

**没有开启 Swap 机制**

当申请完，使用们memset函数访问的时候，超过了机器的物理内存（2GB），进程（test）被操作系统杀掉了。

通过`var/log/message`可以看到报错了 Out of memory，也就是发生 OOM（内存溢出错误）。

> 什么是 OOM?
>
> 内存溢出(Out Of Memory，简称OOM)是指应用系统中存在无法回收的内存或使用的内存过多，最终使得程序运行要用到的内存大于能提供的最大内存。此时程序就运行不了，系统会提示内存溢出。

**开启 Swap 机制**

在有 Swap 分区的情况下，即使笔记本物理内存是 8 GB，申请并使用 32 GB 内存是没问题，程序正常运行了，并没有发生 OOM。

但是磁盘 I/O 达到了一个峰值，非常高

> 有了 Swap 分区，是不是意味着进程可以使用的内存是无上限的？
>
> 当然不是，我把上面的代码改成了申请 64GB 内存后，当进程申请完 64GB 虚拟内存后，使用到 56 GB （这个不要理解为占用的物理内存，理解为已被访问的虚拟内存大小，也就是在物理内存呆过的内存大小）的时候，进程就被系统 kill 掉了，当系统多次尝试回收内存，还是无法满足所需使用的内存大小，进程就会被系统 kill 掉了，意味着发生了 OOM 



# CPU和GPU的区别

https://mp.weixin.qq.com/s/jPh5o5LXDWi7WogyN6AHvQ



# C++性能调优

https://www.cnblogs.com/wujianlundao/archive/2012/11/18/2776372.html

## **冗余的变量拷贝**

**参数**

相对C而言，写C++代码经常一不小心就会引入一些临时变量，比如函数实参、函数返回值。在临时变量之外，也会有其他一些情况会带来一些冗余的变量拷贝。

这个要看要不要修改参数，可能会修改，则需要用值传递无可避免

如果参数不会被函数给修改，那么引用传递可以

**返回值**

RVO(return value optimization)，这时候只能在函数返回一个未命名变量的时候进行优化。

## **字符数组的初始化**

写代码时，很多人为了省事或者说安全起见，每次申请一段内存之后都先全部初始化为0。

用了一些API，不了解底层实现，把申请的内存全部初始化为0了，比如char buf[1024]=""的方式，

上面提到两种内存初始化为0的情况，其实有些时候并不是必须的。比如把char型数组作为string使用的时候只需要初始化第一个元素为0即可，或者把char型数组作为一个buffer使用的大部分时候根本不需要初始化。

## **频繁的内存申请、释放操作**

https://bbs.csdn.net/topics/330179712

## **提前计算**

这里需要提到的有两类问题：

1. 局部的冗余计算：循环体内的计算提到循环体之前

2. 全局的冗余计算

问题1很简单，大部分人应该都接触到过。有人会问编译器不是对此有对应的优化措施么？对，公共子表达式优化是可以解决一些这个问题。不过实测发现**如果循环体内是调用的某个函数**，即使这个函数是没有side effect的，编译器也无法针对这种情况进行优化。（我是用gcc 3.4.5测试的，不排除更高版本的gcc或者其他编译器可以针对这种情况进行优化）

对于问题2，我遇到的情况是：服务代码中定义了一个const变量，假设叫做MAX_X，处理请求是，会计算一个pow(MAX_X)用作判断（y的x次方），而性能分析发现，这个pow操作占了整体系统CPU占用的10%左右。对于这个问题，我的优化方式很简单，直接计算定义一个MAX_X_POW变量用作过滤即可。代码修改2行，性能提升10%。

## **空间换时间**

哈希表的思想

## **内联频繁调用的短小函数**

小函数尽量内联，频繁调用会提高效率

## **位运算代替乘除法**

%2的次方可以用位运算代替，a%8=a&7（两倍多效率提升）

/2的次方可以用移位运算代替，a/8=a>>3（两倍多效率提升）

`*2`的次方可以用移位运算代替，a*8=a<<3（小数值测试效率不明显，大数值1.5倍效率）

整数次方不要用pow，`i*i`比pow(i,2)快8倍，`i*i*i`比pow快40倍

## C++为什么提供move函数？

我想说一下一个我的个人经历

有一段代码，作用是把数据库表保存到XML文件。这个转换的过程，有个中间容器，大概是这样：

```c++
std::map<string, std::vector<int>> mapTable;
```

可以理解为map的key是数据表的列名，std::vector是那列数据（一行一行的）。

我之前是这么填充的：

```c++
std::vector<std::variant> vecRow;
for(){
	vecRow.push_back(...);
}
mapTable["列名1"] = vecRow;
```

codereview的时候我的mentor就和我讲了这个事情，本质上上述代码，把vecRow中的所有元素都复制了以便然后放到mapTable中，白白的重新创建了一遍所有行数据，又把不再需要的vecRow释放掉了。这样就很蠢。

改进：当我们知道vecRow生命（作用域后），我们可以利用这个vecRow，在std::move之前，还是有办法的，创建vecRow 的时候就让它是mapTable里某列的引用，如下：

```c++
std::vector<std::variant> &vecRow = mapTable["列名1"];
for(){
	vecRow.push_back(...);
}
```

但是考虑到这样的话会改动别的代码，所哟用谁提的std::move是最好的

`mapTable["列名1"]= std::move(vecRow);`

就这么一点点改动，就能让vecRow里的东西放进mapTable里，又没避免大规模创建、析构对象。执行完上面的函数，应该会发现vecRow空了。

**总结**

其实编译器已经在力所能及的优化他能够优化的东西了，但是编译器的优化不是万能的。有时候某个变量的生命周期编译器不可预见，但是我们自己是可以知道的，因此对于这些生命周期很短的变量我们为了节省效率就可以使用move函数。举个例子：比如黄金交易，张三买了李四的黄金，就应该把黄金从李四家移动到张三家里。但如果黄金量很大，移动的成本就会非常高。另一种方式就是大家的黄金都存在银行里，张三买李四的黄金，无非就是账户里的黄金数发生个变化，实体黄金不移动，这样效率就高很多。至于"为什么管理机构（编译器）不优化全世界的黄金交易为纸上黄金交易？"，**那是因为真的有人需要搬黄金回家用啊**

#  c++单例模式

> 定义：单例模式是创建型设计模式，指的是在系统的生命周期中只能产生一个实例(对象)，确保该类的唯一性。
>
> 一般遇到的写进程池类、日志类、内存池（用来缓存数据的结构，在一处写多出读或者多处写多处读）的话都会用到单例模式

**实现方法：**全局只有一个实例也就意味着不能用new调用构造函数来创建对象，因此构造函数必须是虚有的。但是由于不能new出对象，所以类的内部必须提供一个函数来获取对象，而且由于不能外部构造对象，因此这个函数不能是通过对象调出来，换句话说这个函数应该是属于对象的，很自然我们就想到了用static。由于静态成员函数属于整个类，在类实例化对象之前就已经分配了空间，而类的非静态成员函数必须在类实例化后才能有内存空间。

单例模式的要点总结：

1. 全局只有一个实例，用static特性实现，构造函数设为私有
2. 通过公有接口获得实例
3. 线程安全
4. 禁止拷贝和赋值

单例模式可以**分为懒汉式和饿汉式**，两者之间的区别在于创建实例的时间不同：懒汉式指系统运行中，实例并不存在，只有当需要使用该实例时，才会去创建并使用实例(这种方式要考虑线程安全)。饿汉式指系统一运行，就初始化创建实例，当需要时，直接调用即可。（本身就线程安全，没有多线程的问题）

## 懒汉式

- 普通懒汉式会让线程不安全

  因为不加锁的话当线程并发时会产生多个实例，导致线程不安全

  ```c++
  ///  普通懒汉式实现 -- 线程不安全 //
  #include <iostream> // std::cout
  #include <mutex>    // std::mutex
  #include <pthread.h> // pthread_create
  
  class SingleInstance
  {
  public:
      // 获取单例对象
      static SingleInstance *GetInstance();
      // 释放单例，进程退出时调用
      static void deleteInstance();
  	// 打印单例地址
      void Print();
  private:
  	// 将其构造和析构成为私有的, 禁止外部构造和析构
      SingleInstance();
      ~SingleInstance();
      // 将其拷贝构造和赋值构造成为私有函数, 禁止外部拷贝和赋值
      SingleInstance(const SingleInstance &signal);
      const SingleInstance &operator=(const SingleInstance &signal);
  private:
      // 唯一单例对象指针
      static SingleInstance *m_SingleInstance;
  };
  
  //初始化静态成员变量
  SingleInstance *SingleInstance::m_SingleInstance = NULL;
  
  SingleInstance* SingleInstance::GetInstance()
  {
  	if (m_SingleInstance == NULL)
  	{
  		m_SingleInstance = new (std::nothrow) SingleInstance;  // 没有加锁是线程不安全的，当线程并发时会创建多个实例
  	}
      return m_SingleInstance;
  }
  
  void SingleInstance::deleteInstance()
  {
      if (m_SingleInstance)
      {
          delete m_SingleInstance;
          m_SingleInstance = NULL;
      }
  }
  
  void SingleInstance::Print()
  {
  	std::cout << "我的实例内存地址是:" << this << std::endl;
  }
  
  SingleInstance::SingleInstance()
  {
      std::cout << "构造函数" << std::endl;
  }
  
  SingleInstance::~SingleInstance()
  {
      std::cout << "析构函数" << std::endl;
  }
  ///  普通懒汉式实现 -- 线程不安全  //
  ```

- 线程安全、内存安全的懒汉式

  上述代码出现的问题：

  1. GetInstance()可能会引发竞态条件，第一个线程在if中判断 `m_instance_ptr`是空的，于是开始实例化单例;同时第2个线程也尝试获取单例，这个时候判断`m_instance_ptr`还是空的，于是也开始实例化单例;这样就会实例化出两个对象,这就是线程安全问题的由来

     解决办法：①加锁。②局部变量实例

  2. 类中只负责new出对象，却没有负责delete对象，因此只有构造函数被调用，析构函数却没有被调用;因此会导致内存泄漏。

     解决办法：使用共享指针

  > c++11标准中有一个特性：如果当变量在初始化的时候，并发同时进入声明语句，并发线程将会阻塞等待初始化结束。这样保证了并发线程在获取静态局部变量的时候一定是初始化过的，所以具有线程安全性。因此这种懒汉式是最推荐的，因为：
  >
  > 1. 通过局部静态变量的特性保证了线程安全 (C++11, GCC > 4.3, VS2015支持该特性);
  > 2. 不需要使用共享指针和锁
  > 3. get_instance()函数要返回引用而尽量不要返回指针，

  ```c++
  ///  内部静态变量的懒汉实现  //
  class Singleton
  {
  public:
      ~Singleton(){
          std::cout<<"destructor called!"<<std::endl;
      }
      //或者放到private中
      Singleton(const Singleton&)=delete;
      Singleton& operator=(const Singleton&)=delete;
      static Singleton& get_instance(){
          //关键点！
          static Singleton instance;
          return instance;
      }
      //不推荐，返回指针的方式
      /*static Singleton* get_instance(){
          static Singleton instance;
          return &instance;
  	}*/
  private:
      Singleton(){
          std::cout<<"constructor called!"<<std::endl;
      }
  };
  
  ```

  > 使用锁、共享指针实现的懒汉式单例模式
  >
  > - 基于 shared_ptr, 用了C++比较倡导的 RAII思想，用对象管理资源,当 shared_ptr 析构的时候，new 出来的对象也会被 delete掉。以此避免内存泄漏。
  > - 加了锁，使用互斥量来达到线程安全。这里使用了两个 if判断语句的技术称为**双检锁**；好处是，只有判断指针为空的时候才加锁，避免每次调用 get_instance的方法都加锁，锁的开销毕竟还是有点大的。
  >
  > 不足之处在于： 使用智能指针会要求用户也得使用智能指针，非必要不应该提出这种约束; 使用锁也有开销; 同时代码量也增多了，实现上我们希望越简单越好。

  ```c++
  #include <iostream>
  #include <memory> // shared_ptr
  #include <mutex>  // mutex
  
  // version 2:
  // with problems below fixed:
  // 1. thread is safe now
  // 2. memory doesn't leak
  
  class Singleton {
  public:
      typedef std::shared_ptr<Singleton> Ptr;
      ~Singleton() {
          std::cout << "destructor called!" << std::endl;
      }
      Singleton(Singleton&) = delete;
      Singleton& operator=(const Singleton&) = delete;
      static Ptr get_instance() {
  
          // "double checked lock"
          if (m_instance_ptr == nullptr) {
              std::lock_guard<std::mutex> lk(m_mutex);
              if (m_instance_ptr == nullptr) {
                  m_instance_ptr = std::shared_ptr<Singleton>(new Singleton);
              }
          }
          return m_instance_ptr;
      }
  
  
  private:
      Singleton() {
          std::cout << "constructor called!" << std::endl;
      }
      static Ptr m_instance_ptr;
      static std::mutex m_mutex;
  };
  
  // initialization static variables out of class
  Singleton::Ptr Singleton::m_instance_ptr = nullptr;
  std::mutex Singleton::m_mutex;
  ```

  

## 饿汉式

```c++

// 饿汉实现 /
class Singleton
{
    
public:
    // 获取单实例
    static Singleton* GetInstance();
    // 释放单实例，进程退出时调用
    static void deleteInstance();
    // 打印实例地址
    void Print();

private:
    // 将其构造和析构成为私有的, 禁止外部构造和析构
    Singleton();
    ~Singleton();

    // 将其拷贝构造和赋值构造成为私有函数, 禁止外部拷贝和赋值
    Singleton(const Singleton &signal);
    const Singleton &operator=(const Singleton &signal);

private:
    // 唯一单实例对象指针
    static Singleton *g_pSingleton;
};

// 代码一运行就初始化创建实例 ，本身就线程安全
Singleton* Singleton::g_pSingleton = new (std::nothrow) Singleton;

Singleton* Singleton::GetInstance()
{
    return g_pSingleton;
}

void Singleton::deleteInstance()
{
    if (g_pSingleton)
    {
    
        delete g_pSingleton;
        g_pSingleton = NULL;
    }
}

void Singleton::Print()
{
    std::cout << "我的实例内存地址是:" << this << std::endl;
}

Singleton::Singleton()
{
    std::cout << "构造函数" << std::endl;
}

Singleton::~Singleton()
{
    std::cout << "析构函数" << std::endl;
}
// 饿汉实现 /
```

## 面试题

- 懒汉模式和恶汉模式的实现（判空！！！加锁！！！），并且要能说明原因（为什么判空两次？）
- 构造函数的设计（为什么私有？除了私有还可以怎么实现（进阶）？）
- 对外接口的设计（为什么这么设计？）
- 单例对象的设计（为什么是static？如何初始化？如何销毁？（进阶））
- 对于C++编码者，需尤其注意C++11以后的单例模式的实现（为什么这么简化？怎么保证的（进阶））



# Observe模式

## 定义

又叫做观察者模式，被观察者叫做subjec，观察者叫做observer

**观察者模式(Observer Pattern)**： 定义对象间一种一对多的依赖关系，使得当每一个对象改变状态，则所有依赖于它的对象都会得到通知并自动更新。

观察者模式所做的工作其实就是在解耦，让耦合的双方都依赖于抽象而不是具体，从而使得各自的变化都不会影响另一边的变化。当一个对象的改变需要改变其他对象的时候，而且它不知道具体有多少对象有待改变的时候，应该考虑使用观察者模式。一旦观察目标的状态发生改变，所有的观察者都将得到通知。具体来说就是被观察者需要用一个容器比如vector存放所有观察者对象，以便状态发生变化时给观察着发通知。观察者内部需要实例化被观察者对象的实例（需要前向声明）

<img src="https://s2.loli.net/2022/07/09/mXhfzvFaTi6BApy.webp" alt="img" style="zoom:80%;float:left" />

**观察者模式中主要角色--2个接口,2个类**

1. 抽象主题（Subject）角色(接口)：主题角色将所有对观察者对象的引用保存在一个集合中，每个主题可以有任意多个观察者。 抽象主题提供了增加和删除观察者对象的接口。
2. 抽象观察者（Observer）角色(接口)：为所有的具体观察者定义一个接口，在观察的主题发生改变时更新自己。
3. 具体主题（ConcreteSubject）角色(1个)：存储相关状态到具体观察者对象，当具体主题的内部状态改变时，给所有登记过的观察者发出通知。具体主题角色通常用一个具体子类实现。
4. 具体观察者（ConcretedObserver）角色(多个)：存储一个具体主题对象，存储相关状态，实现抽象观察者角色所要求的更新接口，以使得其自身状态和主题的状态保持一致。

```java
//观察者
interface Observer {
    public void update();
}
//被观察者
abstract class Subject {
    private Vector<Observer> obs = new Vector();

    public void addObserver(Observer obs){
        this.obs.add(obs);
    }
    public void delObserver(Observer obs){
        this.obs.remove(obs);
    }
    protected void notifyObserver(){
        for(Observer o: obs){
            o.update();
        }
    }
    public abstract void doSomething();
}
//具体被观察者
class ConcreteObserver1 implements Observer {
    public void update() {
        System.out.println("观察者1收到信息，并进行处理");
    }
}
class ConcreteObserver2 implements Observer {
    public void update() {
        System.out.println("观察者2收到信息，并进行处理");
    }
}
//客户端
public class Client {
    public static void main(String[] args){
        Subject sub = new ConcreteSubject();
        sub.addObserver(new ConcreteObserver1()); //添加观察者1
        sub.addObserver(new ConcreteObserver2()); //添加观察者2
        sub.doSomething();
    }
}
//输出
被观察者事件发生改变
观察者1收到信息，并进行处理
观察者2收到信息，并进行处理
可以看到当被观察者发生改变过后，观察者都收到了通知
```

## 优点

- 观察者模式在被观察者和观察者之间建立一个抽象的耦合。被观察者角色所知道的只是一个具体观察者列表，每一个具体观察者都符合一个抽象观察者的接口。被观察者并不认识任何一个具体观察者，它只知道它们都有一个共同的接口。
- 观察者模式支持广播通讯。被观察者会向所有的登记过的观察者发出通知

## 缺点

- 当观察者对象很多的时候，通知的发布会产生很多时间，影响程序的效率。一个被观察者，多个观察者时，开发代码和调试会比较复杂，java中消息的通知是默认顺序执行的，若其中一个观察者卡壳，会影响到此观察者后面的观察者执行，影响整体的执行， 多级触发时的效率更让人担忧。
- 虽然观察者模式可以随时使观察者知道所观察的对象发生了变化，但是观察者模式没有相应的机制使观察者知道所观察的对象是怎么发生变化的。
- 如果在被观察者之间有循环依赖的话，被观察者会触发它们之间进行循环调用，导致系统崩溃。在使用观察者模式是要特别注意这一点。

# 工厂模式
https://blog.csdn.net/qq_55882840/article/details/139043332

## 1.工厂模式简介      
工厂模式的三种类型：
- 简单工厂模式
- 工厂方法模式
- 抽象工厂模式
工厂模式的作用是生产对象，可以简化代码、提高可维护性，并旦可以通过工厂类生产多种对象。简单工厂模式适用于创建简单的对象，工厂模式适用于创建复杂的对象，而抽象工厂模式适用于创建更复杂的对象。

## 2. 简单工厂模式
简单工厂模式是一种创建型设计模式，旨在通过一个工厂方法来创建对象，而无需直接暴露对象的实例化逻辑。简单工厂模式通常包括一个工厂类和多个产品类。工厂类负责根据客户端的请求，返回对应的产品类实例。就是用户申请一个产品，由工厂负责创建对象。而不是用户自己创建对象。在简单工厂模式中，客户端只需要通过调用工厂类的方法，并传入相应的参数，而无需直接实例化产品类。工厂类根据客户端传入的参数决定创建哪个产品类的实例，并将实例返回给客户端。

###  优点：
封装了实例化的细节，使得客户端与具体产品类解耦，增强了灵活性和可维护性。客户端只需要知道需要什么类型的产品，而无需关心具体的实现细节。同时，如果需要新增产品类时，只需修改工厂类即可，不需要修改客户端代码。      
### 缺点：
简单工厂模式也有一些限制。例如，当需要创建多种类型的产品实例时，工厂类的代码可能会变得复杂，并且随着产品类型的增加，工厂类的责任也会越来越大。因此，在一些复杂的场景下，可能需要使用其他更灵活的创建型设计模式，如工厂方法模式或抽象工厂模式。总的来说，简单工厂模式提供了一种简单而灵活的方式来创建对象，对于一些简单的对象创建场景是很有用的。

简单工厂模式
```c++
class Product {
public:
    virtual void operation() = 0;
};
class ConcreteProductA : public Product {
public:
    void operation() override {
        // 具体产品A的操作实现
    }
};
class ConcreteProductB : public Product {
public:
    void operation() override {
        // 具体产品B的操作实现
    }
};
```
简单工厂类
```c++
class SimpleFactory {
public:
    static Product* createProduct(const std::string& type) {
        if (type == "A") {
            return new ConcreteProductA();
        } else if (type == "B") {
            return new ConcreteProductB();
        } else {
            return nullptr; // 可以添加默认处理逻辑或抛出异常
        }
    }
};
```
客户端调用方式
```c++
int main() {
    Product* productA = SimpleFactory::createProduct("A");
    productA->operation(); // 调用具体产品A的操作
    Product* productB = SimpleFactory::createProduct("B");
    productB->operation(); // 调用具体产品B的操作
    delete productA;
    delete productB;
    return 0;
}
```

## 3. 工厂方法模式
工厂方法模式（Factory Method Pattern）是一种创建型设计模式，它定义了一个用于创建对象的接口，但将具体的对象创建过程交给子类来实现。工厂方法模式通过让子类决定实例化哪个具体类来实现对象的创建，从而实现了将对象的创建和使用解耦的目的。
工厂方法模式一般包括以下角色：
抽象产品（Product）：定义了产品的共同接口，具体的产品类必须实现这个接口。
具体产品（ConcreteProduct）：实现了抽象产品接口，是工厂方法模式中具体创建的对象。
抽象工厂（Factory）：定义了一个工厂的接口，包含一个创建产品的抽象方法，具体的工厂类必须实现这个接口。
具体工厂（ConcreteFactory）：实现了抽象工厂接口，负责实例化具体的产品对象。
        工厂方法模式的关键在于通过抽象工厂和具体工厂的组合，将对象的创建过程推迟到子类中实现。客户端通过使用抽象工厂来创建产品对象，而无需关心具体的产品类和实例化细节。
```c++
// 抽象产品
class Product {
public:
    virtual void operation() = 0;
};
// 具体产品 A
class ConcreteProductA : public Product {
public:
    void operation() override {
        // 具体产品 A 的操作实现
    }
};
// 具体产品 B
class ConcreteProductB : public Product {
public:
    void operation() override {
        // 具体产品 B 的操作实现
    }
};
// 抽象工厂
class Factory {
public:
    virtual Product* createProduct() = 0;
};
// 具体工厂 A
class ConcreteFactoryA : public Factory {
public:
    Product* createProduct() override {
        return new ConcreteProductA();
    }
};
// 具体工厂 B
class ConcreteFactoryB : public Factory {
public:
    Product* createProduct() override {
        return new ConcreteProductB();
    }
};
```
```c++
int main() {
    Factory* factoryA = new ConcreteFactoryA();
    Product* productA = factoryA->createProduct();
    productA->operation(); // 调用具体产品 A 的操作
    Factory* factoryB = new ConcreteFactoryB();
    Product* productB = factoryB->createProduct();
    productB->operation(); // 调用具体产品 B 的操作
    delete factoryA;
    delete productA;
    delete factoryB;
    delete productB;
    return 0;
}
```
### 4. 抽象工厂模式
抽象工厂模式（Abstract Factory Pattern）是一种创建型设计模式，它提供了一个接口，用于创建一系列相关或相互依赖的对象，而无需指定具体的类。抽象工厂模式通过将对象的创建和使用解耦，使得客户端代码与具体类的实现分离，从而实现了对象的变化和替换的灵活性。抽象工厂模式一般包括以下角色：

抽象工厂（Abstract Factory）：定义了创建一系列产品对象的接口，通常包含多个创建产品的抽象方法。
具体工厂（Concrete Factory）：实现了抽象工厂接口，负责创建具体的产品对象。
抽象产品（Abstract Product）：定义了产品的共同接口，具体的产品类必须实现这个接口。
具体产品（Concrete Product）：实现了抽象产品接口，是抽象工厂模式中具体创建的对象。
```c++
// 抽象产品 A
class AbstractProductA {
public:
    virtual void operationA() = 0;
};
// 具体产品 A1
class ConcreteProductA1 : public AbstractProductA {
public:
    void operationA() override {
        // 具体产品 A1 的操作实现
    }
};
// 具体产品 A2
class ConcreteProductA2 : public AbstractProductA {
public:
    void operationA() override {
        // 具体产品 A2 的操作实现
    }
};
// 抽象产品 B
class AbstractProductB {
public:
    virtual void operationB() = 0;
};
// 具体产品 B1
class ConcreteProductB1 : public AbstractProductB {
public:
    void operationB() override {
        // 具体产品 B1 的操作实现
    }
};
// 具体产品 B2
class ConcreteProductB2 : public AbstractProductB {
public:
    void operationB() override {
        // 具体产品 B2 的操作实现
    }
};
// 抽象工厂
class AbstractFactory {
public:
    virtual AbstractProductA* createProductA() = 0;
    virtual AbstractProductB* createProductB() = 0;
};
// 具体工厂 1
class ConcreteFactory1 : public AbstractFactory {
public:
    AbstractProductA* createProductA() override {
        return new ConcreteProductA1();
    }
    AbstractProductB* createProductB() override {
        return new ConcreteProductB1();
    }
};
// 具体工厂 2
class ConcreteFactory2 : public AbstractFactory {
public:
    AbstractProductA* createProductA() override {
        return new ConcreteProductA2();
    }
    AbstractProductB* createProductB() override {
        return new ConcreteProductB2();
    }
};
```
客户端
```c++
int main() {
    AbstractFactory* factory1 = new ConcreteFactory1();
    AbstractProductA* productA1 = factory1->createProductA();
    AbstractProductB* productB1 = factory1->createProductB();
    productA1->operationA(); // 调用具体产品 A1 的操作
    productB1->operationB(); // 调用具体产品 B1 的操作
    delete factory1;
    delete productA1;
    delete productB1;
    AbstractFactory* factory2 = new ConcreteFactory2();
    AbstractProductA* productA2 = factory2->createProductA();
    AbstractProductB* productB2 = factory2->createProductB();
    productA2->operationA(); // 调用具体产品 A2 的操作
    productB2->operationB(); // 调用具体产品 B2 的操作
    delete factory2;
    delete productA2;
    delete productB2;
    return 0;
}
```


# MVC模式

MVC 模式的目的是实现一种动态的程序设计，简化后续对程序的修改和扩展，并且使程序某一部分的重复利用成为可能。除此之外，MVC 模式通过对复杂度的简化，使程序的结构更加直观。软件系统在分离了自身的基本部分的同时，也赋予了各个基本部分应有的功能。专业人员可以通过自身的专长进行相关的分组：

软件系统分为三个基本部分：模型（Model）、视图（View）和控制器（Controller）。

- 模型（Model）：程序员编写程序应有的功能（实现算法等）、数据库专家进行数据管理和数据库设计（可以实现具体的功能）；
- 控制器（Controller）：负责转发请求，对请求进行处理；
- 视图（View）：界面设计人员进行图形界面设计。

## MVC模式的优点

**低耦合**

通过将视图层和业务层分离，允许更改视图层代码而不必重新编译模型和控制器代码，同样，一个应用的业务流程或者业务规则的改变，只需要改动 MVC 的模型层（及控制器）即可。因为模型与控制器和视图相分离，所以很容易改变应用程序的数据层和业务规则。

模型层是自包含的，并且与控制器和视图层相分离，所以很容易改变应用程序的数据层和业务规则。如果想把数据库从 MySQL 移植到 Oracle，或者改变基于 RDBMS 的数据源到 LDAP，只需改变模型层即可。一旦正确的实现了模型层，不管数据来自数据库或是 LDAP 服务器，视图层都将会正确的显示它们。由于运用 MVC 的应用程序的三个部件是相互独立，改变其中一个部件并不会影响其它两个，所以依据这种设计思想能构造出良好的松耦合的构件。

**重用性高**

随着技术的不断进步，当前需要使用越来越多的方式来访问应用程序了。MVC 模式允许使用各种不同样式的视图来访问同一个服务端的代码，这得益于多个视图（如 WEB（HTTP）浏览器或者无线浏览器（WAP））能共享一个模型。

比如，用户可以通过电脑或通过手机来订购某样产品，虽然订购的方式不一样，但处理订购产品的方式（流程）是一样的。由于模型返回的数据没有进行格式化，所以同样的构件能被不同的界面（视图）使用。例如，很多数据可能用 HTML 来表示，但是也有可能用 WAP 来表示，而这些表示的变化所需要的是仅仅是改变视图层的实现方式，而控制层和模型层无需做任何改变。

由于已经将数据和业务规则从表示层分开，所以可以最大化的进行代码重用了。另外，模型层也有状态管理和数据持久性处理的功能，所以，基于会话的购物车和电子商务过程，也能被 Flash 网站或者无线联网的应用程序所重用。

**生命周期成本低**

MVC 模式使开发和维护用户接口的技术含量降低。

**部署快**

使用 MVC 模式进行软件开发，使得软件开发时间得到相当大的缩减，它使后台程序员集中精力于业务逻辑，界面（前端）程序员集中精力于表现形式上。

**可维护性高**

分离视图层和业务逻辑层使得 WEB 应用更易于维护和修改。

**有利软件工程化管理**

由于不同的组件（层）各司其职，每一层不同的应用会具有某些相同的特征，这样就有利于通过工程化、工具化的方式管理程序代码。控制器同时还提供了一个好处，就是可以使用控制器来联接不同的模型和视图，来实现用户的需求，这样控制器可以为构造应用程序提供强有力的手段。给定一些**可重用的**模型和视图，控制器可以根据用户的需求选择模型进行处理，然后选择视图将处理结果显示给用户。
